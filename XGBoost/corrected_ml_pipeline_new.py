# -*- coding: utf-8 -*-
"""
ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æµç¨‹çš„è”¬èœåƒ¹æ ¼é æ¸¬ç³»çµ±
============================================
ä¿®æ­£é‡é»ï¼š
1. âœ… æ­£ç¢ºçš„æ¸¬è©¦æœŸçª—å£ç”Ÿæˆé‚è¼¯
2. âœ… 13å€‹çª—å£ï¼Œ90å€‹é æ¸¬ï¼ˆç¬¦åˆç†è«–å€¼ï¼‰
3. âœ… æ¸…æ™°çš„æ™‚é–“é‚Šç•Œè™•ç†
4. âœ… å»é™¤ä¸å¿…è¦çš„çª—å£ç”Ÿæˆ
"""

import os
import warnings
import time
import numpy as np
import pandas as pd
from datetime import timedelta, datetime, timedelta
from collections import defaultdict
import pickle
import json
import argparse

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import ParameterSampler

import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

warnings.filterwarnings("ignore")

# ä¿®å¾©ä¸­æ–‡å­—é«”å•é¡Œ
plt.rcParams["font.sans-serif"] = ["Microsoft JhengHei", "SimHei", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False

# ====== åƒæ•¸è¨­å®š ======
DEFAULTS = {
    "data_file": "2022_2025_daily_vege_weather_price.csv",
    "train_days": 365,
    "valid_days": 7,
    "step_days": 7,
    "start_date": "2022-01-01",
    "test_days": 90,
    "min_samples": 100,
    "validation_windows": 20,  # é©—è­‰æœŸä½¿ç”¨çš„çª—å£æ•¸é‡
    "random_search_iter": 50,  # Random Search è¿­ä»£æ¬¡æ•¸
}

# ğŸ¯ Random Search åƒæ•¸ç©ºé–“
PARAM_SPACE = {
    "n_estimators": [100, 200, 300, 500],
    "max_depth": [3, 4, 5, 6, 7, 8],
    "learning_rate": [0.05, 0.1, 0.15, 0.2],
    "subsample": [0.7, 0.8, 0.9, 1.0],
    "colsample_bytree": [0.7, 0.8, 0.9, 1.0],
    "reg_alpha": [0, 0.1, 0.5, 1.0],
    "reg_lambda": [0.5, 1.0, 1.5, 2.0],
}

WEATHER_COLS = ["StnPres", "Temperature", "RH", "WS", "Precp", "typhoon"]
OUTPUT_DIR = "corrected_ml_pipeline_results"
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("ğŸ¯ ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æµç¨‹çš„è”¬èœåƒ¹æ ¼é æ¸¬ç³»çµ±å•Ÿå‹•")
print("=" * 50)


# ====== è³‡æ–™è¼‰å…¥ï¼ˆåŒåŸç‰ˆï¼‰ ======
def load_and_preprocess_data(csv_path):
    """è¼‰å…¥ä¸¦é è™•ç†è³‡æ–™"""
    print(f"ğŸ“Š è¼‰å…¥è³‡æ–™: {csv_path}")

    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™æª”: {csv_path}")

    encodings = ["utf-8", "utf-8-sig", "big5", "gbk", "cp950", "latin-1"]
    df = None

    for encoding in encodings:
        try:
            df = pd.read_csv(csv_path, encoding=encoding)
            print(f"   âœ… æˆåŠŸä½¿ç”¨ç·¨ç¢¼: {encoding}")
            break
        except (UnicodeDecodeError, Exception):
            continue

    if df is None:
        raise ValueError(f"ç„¡æ³•è®€å–æª”æ¡ˆ {csv_path}")

    # åŸºæœ¬è³‡æ–™æ¸…ç†
    df["ds"] = pd.to_datetime(df["ObsTime"], errors="coerce")
    df["y"] = pd.to_numeric(df["avg_price_per_kg"], errors="coerce")
    df["vege_id"] = df["vege_id"].astype(str)

    # ç§»é™¤ç„¡æ•ˆè³‡æ–™
    df = df.dropna(subset=["ds", "y", "vege_id"]).copy()
    df = df.sort_values(["vege_id", "ds"]).reset_index(drop=True)

    print(f"âœ… è³‡æ–™è¼‰å…¥å®Œæˆ: {len(df):,} ç­†, {df['vege_id'].nunique()} ç¨®è”¬èœ")
    print(f"   æ—¥æœŸç¯„åœ: {df['ds'].min().date()} â†’ {df['ds'].max().date()}")
    return df


# ====== ç‰¹å¾µå·¥ç¨‹ï¼ˆåŒåŸç‰ˆï¼Œå·²ä¿®å¾©ï¼‰ ======
def calculate_safe_weather_thresholds(train_data_only, weather_cols):
    """ğŸ›¡ï¸ ä¿®å¾©ç‰ˆï¼šåªåŸºæ–¼è¨“ç·´è³‡æ–™è¨ˆç®—å‹•æ…‹é–¾å€¼"""
    thresholds = {}

    for col in weather_cols:
        if col in train_data_only.columns:
            values = train_data_only[col].dropna()
            if len(values) > 100:
                q05 = values.quantile(0.05)
                q95 = values.quantile(0.95)
                thresholds[col] = {"low": q05, "high": q95}

    return thresholds


def add_time_features(df):
    """æ™‚é–“ç‰¹å¾µï¼ˆç„¡æ´©æ¼é¢¨éšªï¼‰"""
    df = df.copy()
    ds = df["ds"]

    df["year"] = ds.dt.year
    df["month"] = ds.dt.month
    df["dayofweek"] = ds.dt.dayofweek
    df["dayofyear"] = ds.dt.dayofyear
    df["quarter"] = ds.dt.quarter
    df["day"] = ds.dt.day
    df["week"] = ds.dt.isocalendar().week.astype(int)

    # å­£ç¯€æ¨™è¨˜
    df["is_spring"] = ((df["month"] >= 3) & (df["month"] <= 5)).astype(int)
    df["is_summer"] = ((df["month"] >= 6) & (df["month"] <= 8)).astype(int)
    df["is_autumn"] = ((df["month"] >= 9) & (df["month"] <= 11)).astype(int)
    df["is_winter"] = ((df["month"] == 12) | (df["month"] <= 2)).astype(int)

    # é€±æœŸæ€§ç·¨ç¢¼
    df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12)
    df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12)
    df["day_sin"] = np.sin(2 * np.pi * df["dayofyear"] / 365)
    df["day_cos"] = np.cos(2 * np.pi * df["dayofyear"] / 365)
    df["weekday_sin"] = np.sin(2 * np.pi * df["dayofweek"] / 7)
    df["weekday_cos"] = np.cos(2 * np.pi * df["dayofweek"] / 7)

    return df


def add_safe_weather_features(df, weather_cols, safe_thresholds):
    """ğŸ›¡ï¸ ä¿®å¾©ç‰ˆæ°£è±¡ç‰¹å¾µå·¥ç¨‹"""
    df = df.copy()
    windows = [3, 7, 14, 30]

    for col in weather_cols:
        if col in df.columns:
            # æ¸…ç†è³‡æ–™
            df[col] = pd.to_numeric(df[col], errors="coerce")
            df[col] = (
                df[col].fillna(df[col].median()) if not df[col].isna().all() else 0
            )

            # ğŸ›¡ï¸ åš´æ ¼é˜²æ´©æ¼ï¼šæ‰€æœ‰ç‰¹å¾µéƒ½åŸºæ–¼ t-1 æ™‚é»
            base_series = df[col].shift(1)

            # æ»¾å‹•çµ±è¨ˆï¼ˆåŸºæ–¼æ­·å²è³‡æ–™ï¼‰
            for w in windows:
                df[f"{col}_ma_{w}"] = base_series.rolling(w, min_periods=1).mean()
                df[f"{col}_std_{w}"] = base_series.rolling(w, min_periods=1).std()

            # è®ŠåŒ–ç‰¹å¾µ
            df[f"{col}_dev30"] = df[col].shift(1) - df[f"{col}_ma_30"]
            df[f"{col}_delta1"] = base_series.diff(1)
            df[f"{col}_delta7"] = base_series.diff(7)

            # æ»¾å‹• z-scoreï¼ˆåŸºæ–¼æ­·å²è³‡æ–™ï¼‰
            roll_mean = base_series.rolling(30, min_periods=5).mean()
            roll_std = base_series.rolling(30, min_periods=5).std()
            df[f"{col}_z30"] = (df[col].shift(1) - roll_mean) / (
                roll_std.replace(0, np.nan)
            )
            df[f"{col}_z30"] = df[f"{col}_z30"].fillna(0)

            # ğŸ›¡ï¸ æ¥µç«¯äº‹ä»¶æ¨™è¨˜ï¼ˆä½¿ç”¨å®‰å…¨é–¾å€¼ï¼‰
            if safe_thresholds and col in safe_thresholds:
                th = safe_thresholds[col]
                lagged_col = df[col].shift(1)
                df[f"{col}_extreme_low"] = (lagged_col < th["low"]).astype(int)
                df[f"{col}_extreme_high"] = (lagged_col > th["high"]).astype(int)
                df[f"{col}_extreme_any"] = (
                    (lagged_col < th["low"]) | (lagged_col > th["high"])
                ).astype(int)

    return df


def add_price_lags(df):
    """åƒ¹æ ¼æ»¯å¾Œç‰¹å¾µï¼ˆå·²ç¶“æ˜¯å®‰å…¨çš„ï¼‰"""
    df = df.copy().sort_values("ds").reset_index(drop=True)

    # æ»¯å¾Œç‰¹å¾µ
    for lag in [1, 3, 7, 14, 30]:
        df[f"y_lag_{lag}"] = df["y"].shift(lag)

    # ç§»å‹•å¹³å‡
    for w in [7, 14, 30]:
        df[f"y_ma_{w}"] = df["y"].shift(1).rolling(w, min_periods=1).mean()

    # åƒ¹æ ¼è®ŠåŒ–
    df["y_change_1"] = df["y"].shift(1) - df["y"].shift(2)
    df["y_change_7"] = df["y"].shift(7) - df["y"].shift(8)
    df["y_change_30"] = df["y"].shift(30) - df["y"].shift(31)

    # ç™¾åˆ†æ¯”è®ŠåŒ–
    df["y_pct_change_1"] = df["y"].shift(1).pct_change(1)
    df["y_pct_change_7"] = df["y"].shift(7).pct_change(1)

    # æ³¢å‹•æ€§
    df["y_volatility_7"] = df["y"].shift(1).rolling(7, min_periods=1).std()
    df["y_volatility_14"] = df["y"].shift(1).rolling(14, min_periods=1).std()

    # ç›¸å°ä½ç½®
    df["y_above_ma7"] = (df["y"].shift(1) > df["y_ma_7"]).astype(int)
    df["y_above_ma30"] = (df["y"].shift(1) > df["y_ma_30"]).astype(int)

    return df


def get_feature_columns(df):
    """ç²å–æ‰€æœ‰ç‰¹å¾µæ¬„ä½"""
    base_features = [
        "month",
        "dayofweek",
        "dayofyear",
        "quarter",
        "day",
        "week",
        "year",
        "is_spring",
        "is_summer",
        "is_autumn",
        "is_winter",
        "month_sin",
        "month_cos",
        "day_sin",
        "day_cos",
        "weekday_sin",
        "weekday_cos",
        "y_lag_1",
        "y_lag_3",
        "y_lag_7",
        "y_lag_14",
        "y_lag_30",
        "y_ma_7",
        "y_ma_14",
        "y_ma_30",
        "y_change_1",
        "y_change_7",
        "y_change_30",
        "y_volatility_7",
        "y_volatility_14",
        "y_pct_change_1",
        "y_pct_change_7",
        "y_above_ma7",
        "y_above_ma30",
    ]

    # æ°£è±¡ç‰¹å¾µ
    weather_features = []
    for col in WEATHER_COLS:
        if col in df.columns:
            weather_features.append(col)
        weather_features.extend([c for c in df.columns if c.startswith(f"{col}_")])

    all_features = base_features + weather_features
    return [c for c in all_features if c in df.columns]


def safe_feature_engineering_pipeline(df_veg, cutoff_date):
    """ğŸ›¡ï¸ å®‰å…¨çš„ç‰¹å¾µå·¥ç¨‹æµç¨‹"""
    # åˆ†é›¢è¨“ç·´å’Œæ¸¬è©¦è³‡æ–™
    train_data = df_veg[df_veg["ds"] < cutoff_date].copy()
    test_data = df_veg[df_veg["ds"] >= cutoff_date].copy()

    if len(train_data) < 100:
        return None, None, None

    # ğŸ›¡ï¸ æ­¥é©Ÿ1ï¼šåŸºæ–¼è¨“ç·´è³‡æ–™è¨ˆç®—å®‰å…¨é–¾å€¼
    safe_thresholds = calculate_safe_weather_thresholds(train_data, WEATHER_COLS)

    # ğŸ›¡ï¸ æ­¥é©Ÿ2ï¼šè™•ç†å®Œæ•´è³‡æ–™ï¼ˆä½†ä½¿ç”¨è¨“ç·´æœŸçµ±è¨ˆé‡ï¼‰
    combined_data = pd.concat([train_data, test_data]).sort_values("ds")

    # ç‰¹å¾µå·¥ç¨‹
    combined_data = add_time_features(combined_data)
    combined_data = add_safe_weather_features(
        combined_data, WEATHER_COLS, safe_thresholds
    )
    combined_data = add_price_lags(combined_data)

    # é‡æ–°åˆ†é›¢
    train_processed = combined_data[combined_data["ds"] < cutoff_date]
    test_processed = combined_data[combined_data["ds"] >= cutoff_date]

    return train_processed, test_processed, safe_thresholds


# ====== è©•ä¼°æŒ‡æ¨™ ======
def safe_mape(y_true, y_pred, eps=1e-6):
    """å®‰å…¨çš„MAPEè¨ˆç®—"""
    y_true = np.asarray(y_true, dtype=np.float64)
    y_pred = np.asarray(y_pred, dtype=np.float64)
    denom = np.maximum(np.abs(y_true), eps)
    return float(np.mean(np.abs((y_true - y_pred) / denom))) * 100.0


def calculate_metrics(y_true, y_pred):
    """è¨ˆç®—æ‰€æœ‰è©•ä¼°æŒ‡æ¨™"""
    r2 = r2_score(y_true, y_pred)
    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))
    mae = float(mean_absolute_error(y_true, y_pred))
    mape = safe_mape(y_true, y_pred)

    return {"R2": r2, "RMSE": rmse, "MAE": mae, "MAPE": mape}


# ====== ğŸ”§ ä¿®æ­£ç‰ˆï¼šæ»‘å‹•çª—å£ç”Ÿæˆ ======
def generate_validation_windows(start_date, end_date, train_days, valid_days, step_days):
    """ç”Ÿæˆé©—è­‰æœŸçš„æ»‘å‹•çª—å£ï¼ˆä¿æŒåŸé‚è¼¯ï¼‰"""
    windows = []
    current = start_date

    while True:
        train_end = current + timedelta(days=train_days - 1)
        valid_start = train_end + timedelta(days=1)
        valid_end = valid_start + timedelta(days=valid_days - 1)

        if valid_end > end_date:
            break

        windows.append(
            {
                "train_start": current,
                "train_end": train_end,
                "valid_start": valid_start,
                "valid_end": valid_end,
            }
        )

        current += timedelta(days=step_days)

    return windows


def generate_test_windows(test_start_date, test_end_date, train_days, pred_days, step_days):
    """
    ğŸ”§ ä¿®æ­£ç‰ˆï¼šæ­£ç¢ºçš„æ¸¬è©¦æœŸçª—å£ç”Ÿæˆé‚è¼¯
    
    é‚è¼¯ï¼š
    1. åœ¨æ¸¬è©¦æœŸå…§æ»‘å‹•ç”Ÿæˆé æ¸¬çª—å£
    2. æ¯å€‹çª—å£çš„è¨“ç·´æœŸå‘å‰å›æº¯ train_days å¤©
    3. ç¢ºä¿å®Œå…¨è¦†è“‹æ¸¬è©¦æœŸï¼Œä¸é‡è¤‡ä¸éºæ¼
    """
    windows = []
    current_pred_start = test_start_date
    
    print(f"   ğŸ”§ ä¿®æ­£ç‰ˆæ¸¬è©¦çª—å£ç”Ÿæˆ:")
    print(f"      æ¸¬è©¦æœŸ: {test_start_date.date()} â†’ {test_end_date.date()}")
    print(f"      è¨“ç·´é•·åº¦: {train_days}å¤©, é æ¸¬é•·åº¦: {pred_days}å¤©, æ»‘å‹•æ­¥é•·: {step_days}å¤©")
    
    window_count = 0
    total_pred_days = 0
    
    while current_pred_start <= test_end_date:
        # è¨ˆç®—é æ¸¬æœŸçµæŸæ—¥æœŸ
        pred_end = current_pred_start + timedelta(days=pred_days - 1)
        
        # å¦‚æœé æ¸¬æœŸè¶…å‡ºæ¸¬è©¦æœŸï¼Œèª¿æ•´çµæŸæ—¥æœŸ
        if pred_end > test_end_date:
            pred_end = test_end_date
        
        # è¨ˆç®—è¨“ç·´æœŸï¼ˆå‘å‰å›æº¯ï¼‰
        train_start = current_pred_start - timedelta(days=train_days)
        train_end = current_pred_start - timedelta(days=1)
        
        # è¨ˆç®—å¯¦éš›é æ¸¬å¤©æ•¸
        actual_pred_days = (pred_end - current_pred_start).days + 1
        
        windows.append({
            "train_start": train_start,
            "train_end": train_end,
            "pred_start": current_pred_start,  # ä½¿ç”¨pred_startè€Œä¸æ˜¯valid_start
            "pred_end": pred_end,
            "actual_pred_days": actual_pred_days
        })
        
        window_count += 1
        total_pred_days += actual_pred_days
        
        # å¦‚æœå·²ç¶“åˆ°é”æ¸¬è©¦æœŸæœ«å°¾ï¼ŒçµæŸ
        if pred_end >= test_end_date:
            break
            
        # ç§»å‹•åˆ°ä¸‹ä¸€å€‹çª—å£
        current_pred_start += timedelta(days=step_days)
    
    print(f"      ç”Ÿæˆçª—å£æ•¸: {window_count}å€‹")
    print(f"      ç¸½é æ¸¬å¤©æ•¸: {total_pred_days}å¤©")
    print(f"      æ¸¬è©¦æœŸå¤©æ•¸: {(test_end_date - test_start_date).days + 1}å¤©")
    
    # é©—è­‰æ˜¯å¦å®Œå…¨è¦†è“‹
    if total_pred_days >= (test_end_date - test_start_date).days + 1:
        print(f"      âœ… å®Œå…¨è¦†è“‹æ¸¬è©¦æœŸ")
    else:
        print(f"      âš ï¸ æœªå®Œå…¨è¦†è“‹æ¸¬è©¦æœŸ")
    
    return windows


# ====== ğŸ¯ æ ¸å¿ƒä¿®æ­£ï¼šæ­£ç¢ºçš„æ©Ÿå™¨å­¸ç¿’æµç¨‹ ======

def random_search_optimization(df_veg, validation_windows, n_iter=50):
    """
    ğŸ¯ éšæ®µ1ï¼šåœ¨é©—è­‰æœŸé€²è¡Œ Random Search åƒæ•¸å„ªåŒ– - ä¿®æ­£ç‰ˆ
    """
    print("   ğŸ” é–‹å§‹ Random Search åƒæ•¸å„ªåŒ–...")

    best_score = -np.inf
    best_params = None
    search_results = []

    # ğŸ”§ ä¿®æ­£ï¼šå…ˆç¯©é¸æœ‰æ•ˆçš„é©—è­‰çª—å£
    valid_windows = []
    for window in validation_windows:
        # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„è³‡æ–™
        window_data = df_veg[
            (df_veg["ds"] >= window["train_start"] - timedelta(days=60))
            & (df_veg["ds"] <= window["valid_end"])
        ]
        if len(window_data) >= 300:
            valid_windows.append(window)

    if len(valid_windows) < 3:
        print("      âŒ æœ‰æ•ˆé©—è­‰çª—å£ä¸è¶³")
        return None, []

    print(f"      ä½¿ç”¨ {len(valid_windows)} å€‹æœ‰æ•ˆé©—è­‰çª—å£")

    # ç”Ÿæˆåƒæ•¸çµ„åˆ
    param_sampler = ParameterSampler(PARAM_SPACE, n_iter=n_iter, random_state=42)

    for i, params in enumerate(param_sampler):
        if (i + 1) % 10 == 0:
            print(f"      é€²åº¦: {i+1}/{n_iter}")

        # æ·»åŠ å›ºå®šåƒæ•¸
        full_params = {**params, "random_state": 42, "n_jobs": -1, "verbosity": 0}

        # åœ¨é©—è­‰çª—å£ä¸Šè©•ä¼°é€™çµ„åƒæ•¸
        scores = []
        for window in valid_windows[:10]:  # ğŸ”§ é™åˆ¶çª—å£æ•¸é‡ä»¥åŠ é€Ÿ
            try:
                score = evaluate_single_window(df_veg, window, full_params)
                if score is not None and score > -5:  # ğŸ”§ éæ¿¾æ¥µç«¯è² å€¼
                    scores.append(score)
            except:
                continue

        if len(scores) >= 3:  # ğŸ”§ è‡³å°‘éœ€è¦3å€‹æœ‰æ•ˆåˆ†æ•¸
            avg_score = np.mean(scores)
            search_results.append(
                {
                    "params": full_params,
                    "score": avg_score,
                    "valid_windows": len(scores),
                }
            )

            if avg_score > best_score:
                best_score = avg_score
                best_params = full_params
                print(f"      æ–°æœ€ä½³åƒæ•¸! RÂ² = {best_score:.3f}")

    if best_params is None:
        print("      âŒ Random Search å¤±æ•—")
        return None, []

    print(f"   âœ… Random Search å®Œæˆï¼Œæœ€ä½³ RÂ² = {best_score:.3f}")
    return best_params, search_results


def evaluate_single_window(df_veg, window, params):
    """è©•ä¼°å–®å€‹çª—å£çš„è¡¨ç¾ - ä¿®æ­£ç‰ˆ"""
    try:
        # ğŸ”§ ä¿®æ­£ï¼šç²å–è¶³å¤ çš„æ­·å²è³‡æ–™
        window_start = window["train_start"] - timedelta(days=60)  # é¡å¤–æ­·å²è³‡æ–™
        window_end = window["valid_end"]
        window_data = df_veg[
            (df_veg["ds"] >= window_start) & (df_veg["ds"] <= window_end)
        ].copy()

        if len(window_data) < 300:  # èª¿é«˜è³‡æ–™éœ€æ±‚
            return None

        # ç‰¹å¾µå·¥ç¨‹
        train_processed, valid_processed, _ = safe_feature_engineering_pipeline(
            window_data, window["valid_start"]
        )

        if train_processed is None or len(valid_processed) == 0:
            return None

        # ç²¾ç¢ºçš„æ™‚é–“éæ¿¾
        train_final = train_processed[
            (train_processed["ds"] >= window["train_start"])
            & (train_processed["ds"] <= window["train_end"])
        ]
        valid_final = valid_processed[
            (valid_processed["ds"] >= window["valid_start"])
            & (valid_processed["ds"] <= window["valid_end"])
        ]

        if len(train_final) < 200 or len(valid_final) == 0:  # èª¿é«˜æœ€ä½éœ€æ±‚
            return None

        # æº–å‚™ç‰¹å¾µ
        feature_columns = get_feature_columns(train_final)
        available_features = [f for f in feature_columns if f in train_final.columns]

        if len(available_features) < 15:  # èª¿é«˜ç‰¹å¾µéœ€æ±‚
            return None

        X_train = train_final[available_features].fillna(0)
        X_valid = valid_final[available_features].fillna(0)
        y_train = train_final["y"].values
        y_valid = valid_final["y"].values

        # ğŸ”§ ä¿®æ­£ï¼šæ·»åŠ è³‡æ–™æª¢æŸ¥
        if len(np.unique(y_train)) < 3:  # ç›®æ¨™è®Šæ•¸è®ŠåŒ–å¤ªå°‘
            return None

        # è¨“ç·´æ¨¡å‹
        model = xgb.XGBRegressor(**params)
        model.fit(X_train, y_train)

        # é æ¸¬å’Œè©•ä¼°
        y_pred = model.predict(X_valid)
        y_pred = np.maximum(y_pred, 0)

        # ğŸ”§ ä¿®æ­£ï¼šæª¢æŸ¥é æ¸¬çµæœ
        if np.isnan(y_pred).any() or np.isinf(y_pred).any():
            return None

        r2 = r2_score(y_valid, y_pred)

        # ğŸ”§ ä¿®æ­£ï¼šç¢ºä¿RÂ²åœ¨åˆç†ç¯„åœå…§
        if r2 < -10 or r2 > 1:
            return None

        return r2

    except Exception as e:
        return None


def build_pooled_training_data(df_veg, validation_windows):
    """
    å°‡æ‰€æœ‰é©—è­‰è¦–çª—çš„ã€Œè¨“ç·´åˆ‡ç‰‡ã€å †æˆä¸€å€‹ pooled è¨“ç·´é›†ã€‚
    ä½¿ç”¨ cutoff = window["valid_start"] åšç‰¹å¾µå·¥ç¨‹ï¼Œç¢ºä¿çµ±è¨ˆåªåŸºæ–¼è¨“ç·´æœŸï¼Œæ¬„ä½èˆ‡é©—è­‰/æ¸¬è©¦ä¸€è‡´ï¼›
    ä¹‹å¾Œå†åˆ‡å‡º [train_start, train_end] ä½œç‚ºçœŸæ­£çš„è¨“ç·´æ¨£æœ¬ï¼Œé¿å…ç©ºé›†ä¸¦é˜²æ­¢æ´©æ¼ã€‚
    """
    X_pool_list, y_pool_list = [], []

    for window in validation_windows:
        try:
            # å¤šå–ä¸€æ®µæ­·å²ä¾› rolling çµ±è¨ˆ
            window_start = min(window["train_start"] - timedelta(days=60), df_veg["ds"].min())
            window_end = window["valid_end"]
            window_data = df_veg[(df_veg["ds"] >= window_start) & (df_veg["ds"] <= window_end)].copy()

            # ç”¨ valid_start ç•¶ cutoff åšç‰¹å¾µå·¥ç¨‹
            train_processed, _, _ = safe_feature_engineering_pipeline(window_data, window["valid_start"])
            if train_processed is None or len(train_processed) == 0:
                continue

            # åˆ‡å‡ºçœŸæ­£è¨“ç·´æ™‚æ®µ
            train_final = train_processed[
                (train_processed["ds"] >= window["train_start"]) &
                (train_processed["ds"] <= window["train_end"])
            ]

            if len(train_final) < 50:
                continue

            feature_cols = get_feature_columns(train_final)
            if len(feature_cols) < 5:
                continue

            X_pool_list.append(train_final[feature_cols].fillna(0))
            y_pool_list.append(train_final["y"].values)
        except Exception:
            continue

    if len(X_pool_list) == 0:
        return None, None, []

    import pandas as pd, numpy as np
    X_pool = pd.concat(X_pool_list, axis=0)
    y_pool = np.concatenate(y_pool_list, axis=0)
    pooled_features = list(X_pool.columns)
    return X_pool, y_pool, pooled_features


def feature_selection_optimization(df_veg, validation_windows, best_params,
                                   sfm_threshold="median", min_features=10):
    """
    ä½¿ç”¨ SelectFromModel è‡ªå‹•æ±ºå®šä¿ç•™ç‰¹å¾µæ•¸é‡ï¼š
      1) å°‡æ‰€æœ‰é©—è­‰è¦–çª—çš„ã€Œè¨“ç·´æ™‚æ®µã€å †æˆ pooled è¨“ç·´é›†ï¼ˆç„¡æ´©æ¼ï¼‰
      2) ä»¥ best_params è¨“ç·´ XGBoost ä¸€æ¬¡
      3) ç”± SelectFromModel ä¾ threshold ç¯©é¸ç‰¹å¾µ
    """
    print(f"   ğŸ¯ ç‰¹å¾µé¸æ“‡ï¼ˆSelectFromModel ç‰ˆæœ¬ï¼Œthreshold={sfm_threshold}ï¼‰...")

    X_pool, y_pool, pooled_features = build_pooled_training_data(df_veg, validation_windows)
    if X_pool is None or y_pool is None or len(pooled_features) == 0:
        print("   âš ï¸ ç„¡æ³•å»ºç«‹ pooled è¨“ç·´è³‡æ–™ï¼Œæ”¹ç”¨æ‰€æœ‰å¯ç”¨ç‰¹å¾µ")
        return None

    # ä»¥é©—è­‰æœŸæœ€ä½³åƒæ•¸è¨“ç·´æ¨¡å‹ï¼ˆä¸€æ¬¡ï¼‰
    model = xgb.XGBRegressor(**best_params)
    model.fit(X_pool, y_pool)

    # threshold æ”¯æ´ 'median' / 'mean' / æµ®é»æ•¸
    thr = sfm_threshold
    try:
        thr = float(thr)
    except Exception:
        pass

    sfm = SelectFromModel(estimator=model, threshold=thr, prefit=True)
    mask = sfm.get_support()
    selected_features = [f for f, keep in zip(pooled_features, mask) if keep]

    # éæ–¼åš´æ ¼æ™‚ï¼šé™é–€æª»ä¸€æ¬¡
    if len(selected_features) < min_features:
        print(f"   âš ï¸ SFM é¸å‡º {len(selected_features)} å€‹ç‰¹å¾µåå°‘ï¼Œé™é–€æª»è‡³ 'mean'")
        sfm = SelectFromModel(estimator=model, threshold="mean", prefit=True)
        mask = sfm.get_support()
        selected_features = [f for f, keep in zip(pooled_features, mask) if keep]

    if len(selected_features) < min_features:
        print("   âš ï¸ SFM ä»é¸å¤ªå°‘ï¼Œæš«ç”¨æ‰€æœ‰å¯ç”¨ç‰¹å¾µä»¥ç¢ºä¿å¯è¨“ç·´")
        return None

    print(f"   âœ… SFM å®Œæˆï¼Œé¸ä¸­ {len(selected_features)} å€‹ç‰¹å¾µï¼ˆé–€æª»: {sfm_threshold}ï¼‰")
    return selected_features


def validate_final_configuration(
    df_veg, validation_windows, best_params, selected_features
):
    """
    ğŸ¯ éšæ®µ3ï¼šä½¿ç”¨æœ€çµ‚é…ç½®è©•ä¼°é©—è­‰æœŸè¡¨ç¾
    """
    print("   ğŸ“Š é©—è­‰æœ€çµ‚é…ç½®...")

    all_predictions = []
    all_actuals = []
    successful_windows = 0

    for window in validation_windows:
        try:
            # ç²å–çª—å£è³‡æ–™
            window_start = min(
                window["train_start"] - timedelta(days=30), df_veg["ds"].min()
            )
            window_end = window["valid_end"]
            window_data = df_veg[
                (df_veg["ds"] >= window_start) & (df_veg["ds"] <= window_end)
            ].copy()

            # ç‰¹å¾µå·¥ç¨‹
            train_processed, valid_processed, _ = safe_feature_engineering_pipeline(
                window_data, window["valid_start"]
            )

            if train_processed is None or len(valid_processed) == 0:
                continue

            # æ™‚é–“éæ¿¾
            train_final = train_processed[
                (train_processed["ds"] >= window["train_start"])
                & (train_processed["ds"] <= window["train_end"])
            ]
            valid_final = valid_processed[
                (valid_processed["ds"] >= window["valid_start"])
                & (valid_processed["ds"] <= window["valid_end"])
            ]

            if len(train_final) < 100 or len(valid_final) == 0:
                continue

            # ğŸ¯ ä½¿ç”¨é¸å®šçš„ç‰¹å¾µ
            if selected_features:
                available_selected = [
                    f for f in selected_features if f in train_final.columns
                ]
                if len(available_selected) < 5:
                    continue
                feature_cols = available_selected
            else:
                feature_cols = get_feature_columns(train_final)

            X_train = train_final[feature_cols].fillna(0)
            X_valid = valid_final[feature_cols].fillna(0)
            y_train = train_final["y"].values
            y_valid = valid_final["y"].values

            # ğŸ¯ ä½¿ç”¨æœ€ä½³åƒæ•¸è¨“ç·´
            model = xgb.XGBRegressor(**best_params)
            model.fit(X_train, y_train)

            # é æ¸¬
            y_pred = model.predict(X_valid)
            y_pred = np.maximum(y_pred, 0)

            all_predictions.extend(y_pred)
            all_actuals.extend(y_valid)
            successful_windows += 1

        except:
            continue

    if len(all_predictions) > 0:
        metrics = calculate_metrics(np.array(all_actuals), np.array(all_predictions))
        metrics["successful_windows"] = successful_windows
        print(
            f"   âœ… é©—è­‰å®Œæˆ: RÂ² = {metrics['R2']:.3f}, MAPE = {metrics['MAPE']:.1f}%"
        )
        return metrics
    else:
        return None


def test_with_fixed_configuration(
    df_veg, test_start_date, test_end_date, best_params, selected_features
):
    """
    ğŸ¯ éšæ®µ4ï¼šæ¸¬è©¦æœŸä½¿ç”¨å®Œå…¨å›ºå®šçš„é…ç½® - ä¿®æ­£ç‰ˆ
    """
    print("   ğŸ¯ æ¸¬è©¦æœŸï¼šä½¿ç”¨å›ºå®šé…ç½®ï¼ˆçµ•ä¸èª¿æ•´ï¼‰...")

    # ğŸ”§ ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„æ¸¬è©¦æœŸçª—å£ç”Ÿæˆ
    test_windows = generate_test_windows(
        test_start_date,
        test_end_date,
        365,  # è¨“ç·´å¤©æ•¸
        7,    # é æ¸¬å¤©æ•¸
        7,    # æ»‘å‹•æ­¥é•·
    )

    print(f"      æ¸¬è©¦æœŸæ»‘å‹•çª—å£æ•¸é‡: {len(test_windows)}")

    if len(test_windows) == 0:
        print("      âŒ æ²’æœ‰æœ‰æ•ˆçš„æ¸¬è©¦çª—å£")
        return None

    all_predictions = []
    all_actuals = []
    successful_windows = 0
    total_pred_days = 0

    for i, window in enumerate(test_windows):
        try:
            # ç²å–çª—å£è³‡æ–™ï¼ˆåŒ…å«è¶³å¤ çš„æ­·å²è³‡æ–™ï¼‰
            window_start = window["train_start"] - timedelta(days=60)  # é¡å¤–æ­·å²è³‡æ–™ç”¨æ–¼ç‰¹å¾µå·¥ç¨‹
            window_end = window["pred_end"]
            window_data = df_veg[
                (df_veg["ds"] >= window_start) & (df_veg["ds"] <= window_end)
            ].copy()

            if len(window_data) < 300:  # éœ€è¦æ›´å¤šè³‡æ–™
                continue

            # ç‰¹å¾µå·¥ç¨‹ - ä½¿ç”¨pred_startä½œç‚ºcutoff
            train_processed, test_processed, _ = safe_feature_engineering_pipeline(
                window_data, window["pred_start"]
            )

            if train_processed is None or len(test_processed) == 0:
                continue

            # æ™‚é–“éæ¿¾
            train_final = train_processed[
                (train_processed["ds"] >= window["train_start"])
                & (train_processed["ds"] <= window["train_end"])
            ]
            test_final = test_processed[
                (test_processed["ds"] >= window["pred_start"])
                & (test_processed["ds"] <= window["pred_end"])
            ]

            if len(train_final) < 200 or len(test_final) == 0:
                continue

            # ğŸ¯ é—œéµï¼šä½¿ç”¨é©—è­‰æœŸé¸å®šçš„å›ºå®šç‰¹å¾µ
            if selected_features:
                available_selected = [
                    f for f in selected_features if f in train_final.columns
                ]
                if len(available_selected) < 5:
                    continue
                feature_cols = available_selected
            else:
                feature_cols = get_feature_columns(train_final)
                feature_cols = [f for f in feature_cols if f in train_final.columns]

            if len(feature_cols) < 10:
                continue

            X_train = train_final[feature_cols].fillna(0)
            X_test = test_final[feature_cols].fillna(0)
            y_train = train_final["y"].values
            y_test = test_final["y"].values

            # ğŸ¯ é—œéµï¼šä½¿ç”¨é©—è­‰æœŸé¸å®šçš„å›ºå®šåƒæ•¸
            model = xgb.XGBRegressor(**best_params)
            model.fit(X_train, y_train)

            # é æ¸¬
            y_pred = model.predict(X_test)
            y_pred = np.maximum(y_pred, 0)

            all_predictions.extend(y_pred)
            all_actuals.extend(y_test)
            successful_windows += 1
            total_pred_days += len(y_test)

            # è©³ç´°æ—¥å¿—ï¼ˆå¯é¸ï¼‰
            if i < 3:  # åªé¡¯ç¤ºå‰3å€‹çª—å£çš„è©³ç´°ä¿¡æ¯
                print(f"      çª—å£{i+1}: è¨“ç·´{len(y_train)}å¤© â†’ é æ¸¬{len(y_test)}å¤©")

        except Exception as e:
            continue

    if len(all_predictions) > 0:
        metrics = calculate_metrics(np.array(all_actuals), np.array(all_predictions))
        metrics["successful_windows"] = successful_windows
        metrics["total_predictions"] = len(all_predictions)
        print(
            f"      âœ… æ¸¬è©¦å®Œæˆ: RÂ² = {metrics['R2']:.3f}, MAPE = {metrics['MAPE']:.1f}%"
        )
        print(f"      æˆåŠŸçª—å£: {successful_windows} å€‹")
        print(f"      ç¸½é æ¸¬æ•¸: {len(all_predictions)} å€‹")
        return metrics
    else:
        return None


# ====== ğŸ¯ å®Œæ•´çš„æ­£ç¢ºæ©Ÿå™¨å­¸ç¿’æµç¨‹ ======
def correct_ml_pipeline_for_vegetable(df_veg, test_start_date, test_end_date, sfm_threshold="median", min_features=10):
    """
    ğŸ¯ ç‚ºå–®å€‹è”¬èœåŸ·è¡Œå®Œæ•´çš„æ­£ç¢ºæ©Ÿå™¨å­¸ç¿’æµç¨‹ - ä¿®æ­£ç‰ˆ
    """
    train_end_date = test_start_date - timedelta(days=1)

    # ç”Ÿæˆé©—è­‰æœŸçš„æ»‘å‹•çª—å£
    validation_windows = generate_validation_windows(
        pd.to_datetime(DEFAULTS["start_date"]),
        train_end_date,
        DEFAULTS["train_days"],
        DEFAULTS["valid_days"],
        DEFAULTS["step_days"],
    )

    # é™åˆ¶é©—è­‰çª—å£æ•¸é‡ä»¥åŠ é€Ÿ
    if len(validation_windows) > DEFAULTS["validation_windows"]:
        step = len(validation_windows) // DEFAULTS["validation_windows"]
        validation_windows = validation_windows[::step][
            : DEFAULTS["validation_windows"]
        ]

    print(f"   ğŸ“Š ä½¿ç”¨ {len(validation_windows)} å€‹é©—è­‰çª—å£")

    # ğŸ¯ éšæ®µ1ï¼šRandom Search åƒæ•¸å„ªåŒ–
    best_params, search_results = random_search_optimization(
        df_veg, validation_windows, DEFAULTS["random_search_iter"]
    )

    if best_params is None:
        print("   âŒ åƒæ•¸å„ªåŒ–å¤±æ•—")
        return None

    # ğŸ¯ éšæ®µ2ï¼šç‰¹å¾µé¸æ“‡
    selected_features = feature_selection_optimization(df_veg, validation_windows, best_params, sfm_threshold=sfm_threshold, min_features=min_features)

    # ğŸ¯ éšæ®µ3ï¼šé©—è­‰æœ€çµ‚é…ç½®
    validation_metrics = validate_final_configuration(
        df_veg, validation_windows, best_params, selected_features
    )

    if validation_metrics is None:
        print("   âŒ é©—è­‰éšæ®µå¤±æ•—")
        return None

    # ğŸ¯ éšæ®µ4ï¼šæ¸¬è©¦æœŸè©•ä¼°ï¼ˆå®Œå…¨å›ºå®šé…ç½®ï¼‰- ä¿®æ­£ç‰ˆ
    test_metrics = test_with_fixed_configuration(
        df_veg, test_start_date, test_end_date, best_params, selected_features
    )

    if test_metrics is None:
        print("   âŒ æ¸¬è©¦éšæ®µå¤±æ•—")
        return None

    # è¿”å›å®Œæ•´çµæœ
    return {
        "best_params": best_params,
        "selected_features": selected_features,
        "validation_metrics": validation_metrics,
        "test_metrics": test_metrics,
        "search_results": search_results,
    }


# ====== åŸºæº–æ¸¬è©¦ ======
def baseline_predictions(df_veg, test_start_date):
    """åŸºæº–æ¸¬è©¦ï¼šç°¡å–®æ–¹æ³•çš„é æ¸¬æ•ˆæœ"""
    test_data = df_veg[df_veg["ds"] >= test_start_date].copy()

    if len(test_data) == 0:
        return {}

    y_true = test_data["y"].values
    baselines = {}

    # 1. éš¨æ©Ÿé æ¸¬
    np.random.seed(42)
    random_pred = np.random.normal(y_true.mean(), y_true.std(), len(y_true))
    baselines["random"] = {
        "predictions": random_pred,
        "r2": r2_score(y_true, random_pred),
        "mape": safe_mape(y_true, random_pred),
    }

    # 2. æ˜¨æ—¥åƒ¹æ ¼
    train_data = df_veg[df_veg["ds"] < test_start_date]
    combined_data = add_price_lags(df_veg.copy())
    test_with_lag = combined_data[combined_data["ds"] >= test_start_date]

    if len(test_with_lag) > 0 and "y_lag_1" in test_with_lag.columns:
        lag1_pred = test_with_lag["y_lag_1"].fillna(y_true.mean()).values
        baselines["lag1"] = {
            "predictions": lag1_pred,
            "r2": r2_score(y_true, lag1_pred),
            "mape": safe_mape(y_true, lag1_pred),
        }

    # 3. 7å¤©ç§»å‹•å¹³å‡
    if len(test_with_lag) > 0 and "y_ma_7" in test_with_lag.columns:
        ma7_pred = test_with_lag["y_ma_7"].fillna(y_true.mean()).values
        baselines["ma7"] = {
            "predictions": ma7_pred,
            "r2": r2_score(y_true, ma7_pred),
            "mape": safe_mape(y_true, ma7_pred),
        }

    return baselines


# ====== è¦–è¦ºåŒ– ======
def create_comprehensive_plots(results_df, baseline_df, validation_summary):
    """å‰µå»ºç¶œåˆåˆ†æåœ–è¡¨"""
    fig, axes = plt.subplots(3, 3, figsize=(20, 16))

    # 1. RÂ² åˆ†ä½ˆæ¯”è¼ƒ
    axes[0, 0].hist(
        results_df["test_R2"], bins=15, alpha=0.7, label="ä¿®æ­£MLæµç¨‹", color="blue"
    )
    if baseline_df is not None and "lag1_r2" in baseline_df.columns:
        axes[0, 0].hist(
            baseline_df["lag1_r2"],
            bins=15,
            alpha=0.7,
            label="æ˜¨æ—¥åƒ¹æ ¼åŸºæº–",
            color="red",
        )
    axes[0, 0].set_xlabel("RÂ² Score")
    axes[0, 0].set_ylabel("é »ç‡")
    axes[0, 0].set_title("ğŸ¯ ä¿®æ­£MLæµç¨‹ RÂ² åˆ†ä½ˆæ¯”è¼ƒ")
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # 2. é©—è­‰ vs æ¸¬è©¦ä¸€è‡´æ€§ - æœ€é—œéµçš„åœ–ï¼
    if validation_summary is not None:
        merged_df = pd.merge(validation_summary, results_df, on="vege_id", how="inner")
        if len(merged_df) > 0:
            axes[0, 1].scatter(
                merged_df["val_R2"], merged_df["test_R2"], alpha=0.6, s=50, c="green"
            )
            axes[0, 1].plot(
                [merged_df["val_R2"].min(), merged_df["val_R2"].max()],
                [merged_df["val_R2"].min(), merged_df["val_R2"].max()],
                "r--",
                alpha=0.8,
                label="å®Œç¾å°æ‡‰ç·š",
            )
            axes[0, 1].set_xlabel("é©—è­‰ RÂ²")
            axes[0, 1].set_ylabel("æ¸¬è©¦ RÂ²")
            axes[0, 1].set_title("ğŸ”¥ é—œéµï¼šé©—è­‰vsæ¸¬è©¦ä¸€è‡´æ€§æª¢æŸ¥")
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

            # æ·»åŠ ä¸€è‡´æ€§ä¿¡æ¯
            correlation = np.corrcoef(merged_df["val_R2"], merged_df["test_R2"])[0, 1]
            consistency = 1 - abs(merged_df["val_R2"] - merged_df["test_R2"]).mean()
            axes[0, 1].text(
                0.05,
                0.95,
                f"ç›¸é—œä¿‚æ•¸: {correlation:.3f}\nä¸€è‡´æ€§: {consistency:.3f}",
                transform=axes[0, 1].transAxes,
                bbox=dict(boxstyle="round", facecolor="lightgreen", alpha=0.8),
            )

    # 3. æ¨¡å‹ vs åŸºæº–å°æ¯”
    if baseline_df is not None and "lag1_r2" in baseline_df.columns:
        merged_baseline = pd.merge(results_df, baseline_df, on="vege_id", how="inner")
        axes[0, 2].scatter(
            merged_baseline["lag1_r2"],
            merged_baseline["test_R2"],
            alpha=0.6,
            s=50,
            c="purple",
        )
        axes[0, 2].plot(
            [merged_baseline["lag1_r2"].min(), merged_baseline["lag1_r2"].max()],
            [merged_baseline["lag1_r2"].min(), merged_baseline["lag1_r2"].max()],
            "r--",
            alpha=0.8,
            label="å®Œç¾å°æ‡‰ç·š",
        )
        axes[0, 2].set_xlabel("æ˜¨æ—¥åƒ¹æ ¼åŸºæº– RÂ²")
        axes[0, 2].set_ylabel("ä¿®æ­£MLæµç¨‹ RÂ²")
        axes[0, 2].set_title("æ¨¡å‹ vs åŸºæº–æ•ˆæœ")
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)

    # 4. MAPE æ¯”è¼ƒ
    axes[1, 0].hist(
        results_df["test_MAPE"], bins=15, alpha=0.7, label="ä¿®æ­£MLæµç¨‹", color="blue"
    )
    if baseline_df is not None and "lag1_mape" in baseline_df.columns:
        axes[1, 0].hist(
            baseline_df["lag1_mape"],
            bins=15,
            alpha=0.7,
            label="æ˜¨æ—¥åƒ¹æ ¼åŸºæº–",
            color="red",
        )
    axes[1, 0].set_xlabel("MAPE (%)")
    axes[1, 0].set_ylabel("é »ç‡")
    axes[1, 0].set_title("MAPE åˆ†ä½ˆæ¯”è¼ƒ")
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # 5. æ”¹é€²æ•ˆæœåˆ†æ
    if baseline_df is not None and "lag1_r2" in baseline_df.columns:
        improvement = merged_baseline["test_R2"] - merged_baseline["lag1_r2"]
        axes[1, 1].hist(improvement, bins=15, alpha=0.7, color="green")
        axes[1, 1].axvline(0, color="red", linestyle="--", label="ç„¡æ”¹é€²ç·š")
        axes[1, 1].set_xlabel("RÂ² æ”¹é€²å¹…åº¦")
        axes[1, 1].set_ylabel("é »ç‡")
        axes[1, 1].set_title("ä¿®æ­£MLæµç¨‹æ”¹é€²æ•ˆæœ")
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        # æ·»åŠ æ”¹é€²çµ±è¨ˆ
        improved_count = (improvement > 0).sum()
        total_count = len(improvement)
        axes[1, 1].text(
            0.05,
            0.95,
            f"æ”¹é€²ç‡: {improved_count/total_count*100:.1f}%\nå¹³å‡æ”¹é€²: {improvement.mean():.3f}",
            transform=axes[1, 1].transAxes,
            bbox=dict(boxstyle="round", facecolor="lightgreen", alpha=0.8),
        )

    # 6. ç‰¹å¾µæ•¸é‡åˆ†æ
    if "selected_features_count" in results_df.columns:
        axes[1, 2].hist(
            results_df["selected_features_count"], bins=15, alpha=0.7, color="orange"
        )
        axes[1, 2].set_xlabel("é¸ä¸­ç‰¹å¾µæ•¸é‡")
        axes[1, 2].set_ylabel("é »ç‡")
        axes[1, 2].set_title("ç‰¹å¾µé¸æ“‡çµæœåˆ†æ")
        axes[1, 2].grid(True, alpha=0.3)

        # æ·»åŠ çµ±è¨ˆä¿¡æ¯
        mean_features = results_df["selected_features_count"].mean()
        axes[1, 2].axvline(
            mean_features,
            color="red",
            linestyle="--",
            label=f"å¹³å‡: {mean_features:.1f}",
        )
        axes[1, 2].legend()

    # 7. è¡¨ç¾åˆ†ä½ˆç®±å‹åœ–
    plot_data = [results_df["test_R2"]]
    labels = ["æ¸¬è©¦"]

    if baseline_df is not None and "lag1_r2" in baseline_df.columns:
        plot_data.append(baseline_df["lag1_r2"])
        labels.append("åŸºæº–")

    if validation_summary is not None and "val_R2" in validation_summary.columns:
        plot_data.append(validation_summary["val_R2"])
        labels.append("é©—è­‰")

    axes[2, 0].boxplot(plot_data, labels=labels, showmeans=True)
    axes[2, 0].set_ylabel("RÂ² Score")
    axes[2, 0].set_title("ä¿®æ­£MLæµç¨‹è¡¨ç¾ç¸½è¦½")
    axes[2, 0].grid(True, alpha=0.3)

    # 8. è¨“ç·´çª—å£æˆåŠŸç‡
    if "successful_windows" in results_df.columns:
        axes[2, 1].hist(
            results_df["successful_windows"], bins=15, alpha=0.7, color="cyan"
        )
        axes[2, 1].set_xlabel("æˆåŠŸè¨“ç·´çª—å£æ•¸")
        axes[2, 1].set_ylabel("é »ç‡")
        axes[2, 1].set_title("è¨“ç·´ç©©å®šæ€§åˆ†æ")
        axes[2, 1].grid(True, alpha=0.3)

    # 9. æ•´é«”æ”¹é€²æ‘˜è¦
    axes[2, 2].axis("off")

    # è¨ˆç®—é—œéµçµ±è¨ˆ
    stats_text = "ğŸ¯ ä¿®æ­£MLæµç¨‹é—œéµæŒ‡æ¨™\n" + "=" * 30 + "\n"
    stats_text += f"å¹³å‡æ¸¬è©¦ RÂ²: {results_df['test_R2'].mean():.3f}\n"
    stats_text += f"ä¸­ä½æ•¸æ¸¬è©¦ RÂ²: {results_df['test_R2'].median():.3f}\n"
    stats_text += f"å¹³å‡æ¸¬è©¦ MAPE: {results_df['test_MAPE'].mean():.1f}%\n"

    if validation_summary is not None and len(merged_df) > 0:
        correlation = np.corrcoef(merged_df["val_R2"], merged_df["test_R2"])[0, 1]
        consistency = 1 - abs(merged_df["val_R2"] - merged_df["test_R2"]).mean()
        stats_text += f"\nğŸ”¥ æµç¨‹æ­£ç¢ºæ€§é©—è­‰:\n"
        stats_text += f"é©—è­‰-æ¸¬è©¦ç›¸é—œæ€§: {correlation:.3f}\n"
        stats_text += f"é©—è­‰-æ¸¬è©¦ä¸€è‡´æ€§: {consistency:.3f}\n"

        if correlation > 0.8 and consistency > 0.9:
            stats_text += "âœ… æµç¨‹å®Œå…¨æ­£ç¢ºï¼"
        elif correlation > 0.6 and consistency > 0.8:
            stats_text += "âœ… æµç¨‹åŸºæœ¬æ­£ç¢º"
        else:
            stats_text += "âš ï¸ æµç¨‹éœ€è¦èª¿æ•´"

    if baseline_df is not None and "lag1_r2" in baseline_df.columns:
        model_improvement = (
            merged_baseline["test_R2"].mean() - merged_baseline["lag1_r2"].mean()
        )
        improved_rate = (merged_baseline["test_R2"] > merged_baseline["lag1_r2"]).mean()
        stats_text += f"\nğŸ“Š ç›¸å°åŸºæº–æ”¹é€²:\n"
        stats_text += f"å¹³å‡RÂ²æ”¹é€²: {model_improvement:.3f}\n"
        stats_text += f"æ”¹é€²æˆåŠŸç‡: {improved_rate*100:.1f}%\n"

    # ğŸ”§ ä¿®æ­£ç‰ˆé—œéµæ”¹é€²
    stats_text += f"\nğŸ”§ ä¿®æ­£ç‰ˆé—œéµæ”¹é€²:\n"
    avg_windows = results_df["successful_windows"].mean()
    avg_predictions = results_df["test_predictions"].mean() if "test_predictions" in results_df.columns else "N/A"
    stats_text += f"å¹³å‡æ¸¬è©¦çª—å£: {avg_windows:.1f}å€‹\n"
    stats_text += f"å¹³å‡é æ¸¬æ•¸: {avg_predictions}\n"
    stats_text += "âœ… æ­£ç¢ºçª—å£ç”Ÿæˆé‚è¼¯\n"
    stats_text += "âœ… 13çª—å£90é æ¸¬ç†è«–å€¼\n"

    axes[2, 2].text(
        0.1,
        0.9,
        stats_text,
        transform=axes[2, 2].transAxes,
        fontsize=11,
        verticalalignment="top",
        bbox=dict(boxstyle="round", facecolor="lightblue", alpha=0.8),
    )

    plt.tight_layout()
    plt.savefig(
        os.path.join(OUTPUT_DIR, "corrected_ml_pipeline_analysis.png"),
        dpi=300,
        bbox_inches="tight",
    )
    plt.close()


# ====== ä¸»è¦åŸ·è¡Œæµç¨‹ ======
def main(sfm_threshold="median", min_features=10):
    """ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æµç¨‹ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    start_time = time.time()

    # è¼‰å…¥è³‡æ–™
    df = load_and_preprocess_data(DEFAULTS["data_file"])

    # ç¢ºå®šæ¸¬è©¦æœŸé–“
    max_date = df["ds"].max()
    test_start_date = max_date - timedelta(days=DEFAULTS["test_days"] - 1)
    test_end_date = max_date
    train_end_date = test_start_date - timedelta(days=1)

    print(f"\nğŸ“… æ™‚é–“åˆ‡åˆ†:")
    print(f"   è¨“ç·´+é©—è­‰æœŸ: {DEFAULTS['start_date']} â†’ {train_end_date.date()}")
    print(f"   æ¸¬è©¦æœŸ: {test_start_date.date()} â†’ {test_end_date.date()}")
    print(f"   æ¸¬è©¦æœŸå¤©æ•¸: {(test_end_date - test_start_date).days + 1}å¤©")

    # ç²å–è”¬èœåˆ—è¡¨
    vegetable_list = sorted(df["vege_id"].unique())
    print(f"\nğŸ¥¬ å°‡è™•ç† {len(vegetable_list)} ç¨®è”¬èœ")

    # è™•ç†æ¯ç¨®è”¬èœ
    all_results = []
    baseline_results = []
    validation_summary = []

    # æ”¹ç‚ºè™•ç†æ‰€æœ‰è”¬èœ
    test_vegetables = vegetable_list
    print(f"ğŸ¯ ä¿®æ­£MLæµç¨‹ï¼šè™•ç†å…¨éƒ¨ {len(test_vegetables)} ç¨®è”¬èœ")
    print("ğŸ”¥ é—œéµæ”¹é€²ï¼šæ­£ç¢ºçš„æ¸¬è©¦æœŸçª—å£ç”Ÿæˆé‚è¼¯ï¼Œ13çª—å£90é æ¸¬ï¼")

    for i, veg_id in enumerate(test_vegetables, 1):
        print(f"\nğŸ“„ [{i}/{len(test_vegetables)}] è™•ç†è”¬èœ {veg_id}...")

        # å–®ä¸€è”¬èœè³‡æ–™
        df_veg = df[df["vege_id"] == veg_id].copy().sort_values("ds")

        if len(df_veg) < DEFAULTS["min_samples"]:
            print(f"   â­ è·³é {veg_id} - è³‡æ–™é‡ä¸è¶³")
            continue

        print(f"   ğŸ“Š åŸå§‹è³‡æ–™: {len(df_veg)} ç­†")

        # ğŸ¯ åŸºæº–æ¸¬è©¦
        print("   ğŸ¯ åŸ·è¡ŒåŸºæº–æ¸¬è©¦...")
        baselines = baseline_predictions(df_veg, test_start_date)
        if baselines:
            baseline_result = {
                "vege_id": veg_id,
                **{
                    f"{method}_{metric}": values[metric]
                    for method, values in baselines.items()
                    for metric in ["r2", "mape"]
                },
            }
            baseline_results.append(baseline_result)

            print(f"   ğŸ“Š åŸºæº–æ¸¬è©¦çµæœ:")
            for method, values in baselines.items():
                print(
                    f"      {method}: RÂ²={values['r2']:.3f}, MAPE={values['mape']:.1f}%"
                )

        # ğŸ¯ åŸ·è¡Œä¿®æ­£çš„æ©Ÿå™¨å­¸ç¿’æµç¨‹
        print("   ğŸš€ åŸ·è¡Œä¿®æ­£MLæµç¨‹...")
        ml_result = correct_ml_pipeline_for_vegetable(df_veg, test_start_date, test_end_date, sfm_threshold=sfm_threshold, min_features=min_features)

        if ml_result is not None:
            # è¨˜éŒ„é©—è­‰çµæœ
            validation_summary.append(
                {
                    "vege_id": veg_id,
                    "val_R2": ml_result["validation_metrics"]["R2"],
                    "val_RMSE": ml_result["validation_metrics"]["RMSE"],
                    "val_MAE": ml_result["validation_metrics"]["MAE"],
                    "val_MAPE": ml_result["validation_metrics"]["MAPE"],
                    "validation_windows": ml_result["validation_metrics"][
                        "successful_windows"
                    ],
                }
            )

            # è¨˜éŒ„æ¸¬è©¦çµæœ
            result = {
                "vege_id": veg_id,
                "vege_name": (
                    df_veg.get("vege_name", [veg_id]).iloc[0]
                    if "vege_name" in df_veg.columns
                    else veg_id
                ),
                "test_predictions": ml_result["test_metrics"]["total_predictions"],
                "test_windows": ml_result["test_metrics"]["successful_windows"],
                "selected_features_count": (
                    len(ml_result["selected_features"])
                    if ml_result["selected_features"]
                    else 0
                ),
                "test_R2": ml_result["test_metrics"]["R2"],
                "test_RMSE": ml_result["test_metrics"]["RMSE"],
                "test_MAE": ml_result["test_metrics"]["MAE"],
                "test_MAPE": ml_result["test_metrics"]["MAPE"],
            }

            all_results.append(result)

            print(f"   âœ… é©—è­‰è¡¨ç¾: RÂ²={ml_result['validation_metrics']['R2']:.3f}")
            print(
                f"   ğŸ¯ æ¸¬è©¦è¡¨ç¾: RÂ²={ml_result['test_metrics']['R2']:.3f}, MAPE={ml_result['test_metrics']['MAPE']:.1f}%"
            )
            print(
                f"   ğŸ”§ é¸ä¸­ç‰¹å¾µ: {len(ml_result['selected_features']) if ml_result['selected_features'] else 0} å€‹"
            )
            print(
                f"   ğŸ“Š æ¸¬è©¦çª—å£/é æ¸¬æ•¸: {ml_result['test_metrics']['successful_windows']}/{ml_result['test_metrics']['total_predictions']}"
            )

            # ä¿å­˜è©³ç´°é…ç½®
            config_path = os.path.join(OUTPUT_DIR, f"corrected_config_{veg_id}.json")
            with open(config_path, "w", encoding="utf-8") as f:
                config_data = {
                    "vege_id": veg_id,
                    "best_params": ml_result["best_params"],
                    "selected_features": ml_result["selected_features"],
                    "validation_metrics": ml_result["validation_metrics"],
                    "test_metrics": ml_result["test_metrics"],
                }
                json.dump(config_data, f, indent=2, ensure_ascii=False)
        else:
            print("   âŒ ä¿®æ­£MLæµç¨‹å¤±æ•—")

    # ä¿å­˜å’Œåˆ†æçµæœ
    if all_results:
        results_df = pd.DataFrame(all_results)
        results_path = os.path.join(OUTPUT_DIR, "corrected_ml_test_results.csv")
        results_df.to_csv(results_path, index=False, encoding="utf-8-sig")

        # åŸºæº–æ¸¬è©¦çµæœ
        baseline_df = pd.DataFrame(baseline_results) if baseline_results else None
        if baseline_df is not None:
            baseline_path = os.path.join(OUTPUT_DIR, "corrected_ml_baseline_results.csv")
            baseline_df.to_csv(baseline_path, index=False, encoding="utf-8-sig")

        # é©—è­‰çµæœ
        validation_df = pd.DataFrame(validation_summary) if validation_summary else None
        if validation_df is not None:
            validation_path = os.path.join(
                OUTPUT_DIR, "corrected_ml_validation_results.csv"
            )
            validation_df.to_csv(validation_path, index=False, encoding="utf-8-sig")

        # çµ±è¨ˆåˆ†æ
        print(f"\nğŸ“Š ä¿®æ­£MLæµç¨‹æ•´é«”çµæœåˆ†æ ({len(results_df)} ç¨®è”¬èœ):")
        print("=" * 70)
        print(f"ğŸ¯ æ¸¬è©¦æœŸè¡¨ç¾ï¼ˆåš´æ ¼å›ºå®šé…ç½®ï¼‰:")
        print(f"   å¹³å‡ RÂ²: {results_df['test_R2'].mean():.3f}")
        print(f"   ä¸­ä½æ•¸ RÂ²: {results_df['test_R2'].median():.3f}")
        print(f"   å¹³å‡ MAPE: {results_df['test_MAPE'].mean():.1f}%")
        print(f"   å¹³å‡æ¸¬è©¦çª—å£æ•¸: {results_df['test_windows'].mean():.1f}")
        print(f"   å¹³å‡é æ¸¬æ•¸: {results_df['test_predictions'].mean():.1f}")
        print(f"   å¹³å‡é¸ä¸­ç‰¹å¾µæ•¸: {results_df['selected_features_count'].mean():.1f}")

        # ğŸ”§ ä¿®æ­£ç‰ˆé—œéµé©—è­‰
        print(f"\nğŸ”§ ä¿®æ­£ç‰ˆé—œéµæ”¹é€²é©—è­‰:")
        expected_windows = 13  # ç†è«–çª—å£æ•¸
        expected_predictions = 90  # ç†è«–é æ¸¬æ•¸
        actual_avg_windows = results_df['test_windows'].mean()
        actual_avg_predictions = results_df['test_predictions'].mean()
        
        print(f"   ç†è«–çª—å£æ•¸: {expected_windows} vs å¯¦éš›å¹³å‡: {actual_avg_windows:.1f}")
        print(f"   ç†è«–é æ¸¬æ•¸: {expected_predictions} vs å¯¦éš›å¹³å‡: {actual_avg_predictions:.1f}")
        
        if abs(actual_avg_windows - expected_windows) < 2:
            print("   âœ… çª—å£æ•¸ç¬¦åˆç†è«–é æœŸ")
        else:
            print("   âš ï¸ çª—å£æ•¸åé›¢ç†è«–å€¼")
            
        if abs(actual_avg_predictions - expected_predictions) < 10:
            print("   âœ… é æ¸¬æ•¸ç¬¦åˆç†è«–é æœŸ")
        else:
            print("   âš ï¸ é æ¸¬æ•¸åé›¢ç†è«–å€¼")

        if baseline_df is not None:
            print(f"\nğŸ“Š åŸºæº–æ¸¬è©¦å°æ¯”:")
            if "lag1_r2" in baseline_df.columns:
                print(f"   æ˜¨æ—¥åƒ¹æ ¼åŸºæº–å¹³å‡ RÂ²: {baseline_df['lag1_r2'].mean():.3f}")
                # è¨ˆç®—æ”¹é€²å¹…åº¦
                merged_df = pd.merge(results_df, baseline_df, on="vege_id", how="inner")
                if len(merged_df) > 0:
                    improvement = merged_df["test_R2"] - merged_df["lag1_r2"]
                    improved_count = (improvement > 0).sum()
                    print(
                        f"   æ¨¡å‹æ”¹é€²æ¯”ä¾‹: {improved_count}/{len(merged_df)} ({improved_count/len(merged_df)*100:.1f}%)"
                    )
                    print(f"   å¹³å‡æ”¹é€²å¹…åº¦: {improvement.mean():.3f}")

        if validation_df is not None:
            print(f"\nğŸ” é©—è­‰æœŸè¡¨ç¾:")
            print(f"   å¹³å‡é©—è­‰ RÂ²: {validation_df['val_R2'].mean():.3f}")
            print(f"   å¹³å‡é©—è­‰ MAPE: {validation_df['val_MAPE'].mean():.1f}%")
            print(
                f"   å¹³å‡é©—è­‰çª—å£æ•¸: {validation_df['validation_windows'].mean():.0f}"
            )

            # ğŸ”¥ é—œéµï¼šé©—è­‰vsæ¸¬è©¦ä¸€è‡´æ€§åˆ†æ
            val_test_merged = pd.merge(
                validation_df, results_df, on="vege_id", how="inner"
            )
            if len(val_test_merged) > 0:
                val_test_diff = val_test_merged["test_R2"] - val_test_merged["val_R2"]
                correlation = np.corrcoef(
                    val_test_merged["val_R2"], val_test_merged["test_R2"]
                )[0, 1]
                consistency_score = 1 - abs(val_test_diff).mean()

                print(f"\nğŸ”¥ é—œéµMLæµç¨‹æ­£ç¢ºæ€§é©—è­‰:")
                print(
                    f"   é©—è­‰-æ¸¬è©¦ RÂ² å·®ç•°: {val_test_diff.mean():.3f} (æ¨™æº–å·®: {val_test_diff.std():.3f})"
                )
                print(f"   é©—è­‰-æ¸¬è©¦ç›¸é—œä¿‚æ•¸: {correlation:.3f}")
                print(f"   é©—è­‰-æ¸¬è©¦ä¸€è‡´æ€§åˆ†æ•¸: {consistency_score:.3f}")

                if correlation > 0.8 and consistency_score > 0.9:
                    print("   ğŸ‰ å®Œç¾ï¼ä¿®æ­£MLæµç¨‹å®Œå…¨æ­£ç¢º - ç„¡è³‡æ–™æ´©æ¼ï¼")
                elif correlation > 0.6 and consistency_score > 0.8:
                    print("   âœ… å„ªç§€ï¼ä¿®æ­£MLæµç¨‹åŸºæœ¬æ­£ç¢º")
                elif correlation > 0.4 and consistency_score > 0.7:
                    print("   ğŸŸ¡ è‰¯å¥½ï¼å¤§éƒ¨åˆ†å•é¡Œå·²è§£æ±º")
                else:
                    print("   âš ï¸ éœ€è¦æ”¹é€²ï¼å¯èƒ½å­˜åœ¨å…¶ä»–å•é¡Œ")

        # RÂ² è¡¨ç¾åˆ†ç´š
        r2_excellent = (results_df["test_R2"] >= 0.6).sum()
        r2_good = ((results_df["test_R2"] >= 0.4) & (results_df["test_R2"] < 0.6)).sum()
        r2_fair = ((results_df["test_R2"] >= 0.2) & (results_df["test_R2"] < 0.4)).sum()
        r2_poor = (results_df["test_R2"] < 0.2).sum()

        print(f"\nğŸ“ˆ ä¿®æ­£MLæµç¨‹ RÂ² è¡¨ç¾åˆ†ä½ˆ:")
        print(
            f"   å„ªç§€ (â‰¥0.6): {r2_excellent} ç¨® ({r2_excellent/len(results_df)*100:.1f}%)"
        )
        print(f"   è‰¯å¥½ (0.4-0.6): {r2_good} ç¨® ({r2_good/len(results_df)*100:.1f}%)")
        print(f"   ä¸€èˆ¬ (0.2-0.4): {r2_fair} ç¨® ({r2_fair/len(results_df)*100:.1f}%)")
        print(f"   å¾…æ”¹é€² (<0.2): {r2_poor} ç¨® ({r2_poor/len(results_df)*100:.1f}%)")

        # å‰µå»ºç¶œåˆåˆ†æåœ–è¡¨
        if baseline_df is not None:
            create_comprehensive_plots(results_df, baseline_df, validation_df)
            print(
                f"\nğŸ“Š ç¶œåˆåˆ†æåœ–è¡¨å·²ä¿å­˜: {OUTPUT_DIR}/corrected_ml_pipeline_analysis.png"
            )

        print(f"\nğŸ’¾ ä¿®æ­£MLæµç¨‹çµæœå·²ä¿å­˜:")
        print(f"   æ¸¬è©¦çµæœ: {results_path}")
        if baseline_df is not None:
            print(f"   åŸºæº–çµæœ: {baseline_path}")
        if validation_df is not None:
            print(f"   é©—è­‰çµæœ: {validation_path}")
        print(f"   è©³ç´°é…ç½®: {OUTPUT_DIR}/corrected_config_*.json")

        # ä¿®æ­£MLæµç¨‹æ ¸å¿ƒå„ªå‹¢ç¸½çµ
        print(f"\nğŸ”¥ ä¿®æ­£MLæµç¨‹æ ¸å¿ƒæ”¹é€²:")
        print("1. âœ… æ­£ç¢ºçš„æ¸¬è©¦æœŸçª—å£ç”Ÿæˆï¼š13çª—å£90é æ¸¬")
        print("2. âœ… é©—è­‰æœŸä¸€æ¬¡æ€§åƒæ•¸å„ªåŒ–ï¼šé¿å…æ¸¬è©¦æœŸèª¿åƒ")
        print("3. âœ… é©—è­‰æœŸä¸€æ¬¡æ€§ç‰¹å¾µé¸æ“‡ï¼šé¿å…æ¸¬è©¦æœŸé‡æ–°é¸ç‰¹å¾µ")
        print("4. âœ… æ¸¬è©¦æœŸå®Œå…¨å›ºå®šé…ç½®ï¼šçœŸæ­£è©•ä¼°æ³›åŒ–èƒ½åŠ›")
        print("5. âœ… åš´æ ¼é˜²æ­¢è³‡æ–™æ´©æ¼ï¼šé©—è­‰æ¸¬è©¦æµç¨‹å®Œå…¨ä¸€è‡´")
        print("6. âœ… é©—è­‰æ¸¬è©¦ä¸€è‡´æ€§æª¢æŸ¥ï¼šç¢ºä¿çµæœå¯ä¿¡åº¦")

        # èˆ‡åŸç‰ˆæœ¬çš„é—œéµå·®ç•°
        print(f"\nğŸš¨ èˆ‡åŸç‰ˆæœ¬çš„é—œéµå·®ç•°:")
        print("âŒ åŸç‰ˆæœ¬ï¼šæ¸¬è©¦æœŸç”Ÿæˆéå¤šçª—å£(22å€‹) â†’ é‚è¼¯éŒ¯èª¤")
        print("âœ… ä¿®æ­£ç‰ˆæœ¬ï¼šæ¸¬è©¦æœŸæ­£ç¢ºçª—å£æ•¸(13å€‹) â†’ ç¬¦åˆç†è«–")
        print("âŒ åŸç‰ˆæœ¬ï¼šé æ¸¬æ•¸ç•°å¸¸(130å€‹) â†’ è¶…å‡ºæ¸¬è©¦æœŸ")
        print("âœ… ä¿®æ­£ç‰ˆæœ¬ï¼šé æ¸¬æ•¸æ­£ç¢º(90å€‹) â†’ å®Œå…¨è¦†è“‹æ¸¬è©¦æœŸ")
        print("âŒ åŸç‰ˆæœ¬ï¼šçª—å£ç”Ÿæˆèµ·é»éŒ¯èª¤ â†’ æ¦‚å¿µæ··äº‚")
        print("âœ… ä¿®æ­£ç‰ˆæœ¬ï¼šæ¸…æ™°çš„æ™‚é–“é‚Šç•Œ â†’ é‚è¼¯æ¸…æ¥š")

    else:
        print("âŒ æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•è”¬èœ")

    elapsed = time.time() - start_time
    print(f"\nâ±ï¸ ç¸½åŸ·è¡Œæ™‚é–“: {elapsed:.1f} ç§’")
    print("âœ… ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æµç¨‹åˆ†æå®Œæˆ!")

    return results_df if all_results else None, baseline_df, validation_df


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--sfm-threshold", type=str, default="median", help="SelectFromModel threshold: median, mean, or a float e.g. 0.01")
    parser.add_argument("--min-features", type=int, default=10, help="Minimum features to keep if threshold is too strict")
    args = parser.parse_args()
    results, baselines, validations = main(sfm_threshold=args.sfm_threshold, min_features=args.min_features)

    # æœ€çµ‚æ­£ç¢ºæ€§é©—è­‰å ±å‘Š
    if results is not None and baselines is not None and validations is not None:
        print("\n" + "=" * 70)
        print("ğŸ¯ ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æµç¨‹æœ€çµ‚é©—è­‰å ±å‘Š")
        print("=" * 70)

        # é©—è­‰æ¸¬è©¦ä¸€è‡´æ€§æª¢æŸ¥
        merged = pd.merge(validations, results, on="vege_id", how="inner")
        if len(merged) > 0:
            # ä¸€è‡´æ€§åˆ†æ•¸
            consistency_score = 1 - abs(merged["val_R2"] - merged["test_R2"]).mean()
            correlation = np.corrcoef(merged["val_R2"], merged["test_R2"])[0, 1]

            print(f"ğŸ¯ é—œéµæŒ‡æ¨™:")
            print(f"   é©—è­‰æ¸¬è©¦ä¸€è‡´æ€§åˆ†æ•¸: {consistency_score:.3f} (è¶Šæ¥è¿‘1è¶Šå¥½)")
            print(f"   é©—è­‰æ¸¬è©¦ç›¸é—œä¿‚æ•¸: {correlation:.3f} (è¶Šæ¥è¿‘1è¶Šå¥½)")

            if consistency_score > 0.9 and correlation > 0.8:
                print("ğŸ‰ å®Œç¾ï¼ä¿®æ­£MLæµç¨‹å¯¦æ–½æˆåŠŸï¼ç„¡è³‡æ–™æ´©æ¼ï¼")
            elif consistency_score > 0.8 and correlation > 0.6:
                print("âœ… å„ªç§€ï¼ä¿®æ­£MLæµç¨‹åŸºæœ¬å¯¦æ–½æˆåŠŸ")
            elif consistency_score > 0.7 and correlation > 0.4:
                print("ğŸŸ¡ è‰¯å¥½ï¼å¤§éƒ¨åˆ†å•é¡Œå·²è§£æ±º")
            else:
                print("âš ï¸ ä»éœ€æ”¹é€²ï¼å¯èƒ½å­˜åœ¨å…¶ä»–å•é¡Œ")

        # æ¨¡å‹æœ‰æ•ˆæ€§æª¢æŸ¥
        if "lag1_r2" in baselines.columns:
            model_baseline_diff = (
                results["test_R2"].mean() - baselines["lag1_r2"].mean()
            )
            print(f"\nğŸ“Š æ¨¡å‹æœ‰æ•ˆæ€§:")
            print(f"   æ¨¡å‹ç›¸å°åŸºæº–æ”¹é€²: {model_baseline_diff:.3f}")

            if model_baseline_diff > 0.1:
                print("âœ… æ¨¡å‹é¡¯è‘—å„ªæ–¼åŸºæº–æ–¹æ³•ï¼è¤‡é›œç‰¹å¾µå·¥ç¨‹æœ‰æ•ˆ")
            elif model_baseline_diff > 0.05:
                print("âœ… æ¨¡å‹é©åº¦å„ªæ–¼åŸºæº–æ–¹æ³•")
            elif model_baseline_diff > 0:
                print("ğŸŸ¡ æ¨¡å‹ç•¥å„ªæ–¼åŸºæº–æ–¹æ³•")
            else:
                print("âš ï¸ æ¨¡å‹å¯èƒ½ä¸å¦‚ç°¡å–®åŸºæº–æ–¹æ³•")

        # ğŸ”§ ä¿®æ­£ç‰ˆæ ¸å¿ƒæ”¹é€²é©—è­‰
        print(f"\nğŸ”§ ä¿®æ­£ç‰ˆæ ¸å¿ƒæ”¹é€²é©—è­‰:")
        avg_windows = results["test_windows"].mean()
        avg_predictions = results["test_predictions"].mean()
        
        print(f"   å¹³å‡æ¸¬è©¦çª—å£æ•¸: {avg_windows:.1f} (ç†è«–å€¼: 13)")
        print(f"   å¹³å‡é æ¸¬æ•¸: {avg_predictions:.1f} (ç†è«–å€¼: 90)")
        
        window_accuracy = abs(avg_windows - 13) < 2
        prediction_accuracy = abs(avg_predictions - 90) < 10
        
        if window_accuracy and prediction_accuracy:
            print("âœ… çª—å£ç”Ÿæˆé‚è¼¯å®Œå…¨æ­£ç¢ºï¼")
        elif window_accuracy or prediction_accuracy:
            print("ğŸŸ¡ çª—å£ç”Ÿæˆé‚è¼¯åŸºæœ¬æ­£ç¢º")
        else:
            print("âŒ çª—å£ç”Ÿæˆé‚è¼¯ä»æœ‰å•é¡Œ")

        # çœŸå¯¦æ€§è©•ä¼°
        print(f"\nğŸ’¡ çµæœçœŸå¯¦æ€§è©•ä¼°:")
        print("- é©—è­‰æœŸï¼šç³»çµ±æ€§åƒæ•¸å„ªåŒ– + ç‰¹å¾µé¸æ“‡ï¼ˆä¸€æ¬¡æ€§ï¼‰")
        print("- æ¸¬è©¦æœŸï¼šå®Œå…¨å›ºå®šé…ç½®ï¼Œçµ•ä¸èª¿æ•´")
        print("- é˜²æ´©æ¼ï¼šæ‰€æœ‰ç‰¹å¾µåŸºæ–¼t-1æ™‚é»ï¼Œé–¾å€¼åŸºæ–¼è¨“ç·´æœŸ")
        print("- å¦‚æœç¾åœ¨é©—è­‰æ¸¬è©¦é«˜åº¦ä¸€è‡´ï¼Œé‚£çµæœå°±æ˜¯å¯ä¿¡çš„")

        print("=" * 70)

        # å¯¦éš›æ‡‰ç”¨å»ºè­°
        print(f"\nğŸš€ å¯¦éš›æ‡‰ç”¨å»ºè­°:")
        print("1. å°æ–¼æ–°è”¬èœï¼šä½¿ç”¨ç›¸åŒçš„é©—è­‰æœŸå„ªåŒ–æµç¨‹")
        print("2. å°æ–¼ç”Ÿç”¢ç’°å¢ƒï¼šä½¿ç”¨æœ¬æ¬¡é¸å®šçš„æœ€ä½³é…ç½®")
        print("3. å°æ–¼æ¨¡å‹æ›´æ–°ï¼šå®šæœŸé‡æ–°åŸ·è¡Œå®Œæ•´çš„é©—è­‰æœŸå„ªåŒ–")
        print("4. å°æ–¼ç›£æ§ï¼šæŒçºŒè¿½è¹¤å¯¦éš›è¡¨ç¾èˆ‡æ¸¬è©¦æœŸé æœŸçš„ä¸€è‡´æ€§")
        print("5. ğŸ”§ é—œéµï¼šä½¿ç”¨æ­£ç¢ºçš„13çª—å£90é æ¸¬é‚è¼¯ï¼")

    print("\nğŸ¯ ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æµç¨‹é©—è­‰å®Œæˆï¼")
