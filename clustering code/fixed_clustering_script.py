#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®Œæ•´è”¬èœåƒ¹æ ¼DTWèšé¡åˆ†æç¨‹å¼åŒ… (2022-2024)
åŒ…å«åŸå§‹åˆ†æå’Œæ“´å¢åŠŸèƒ½çš„å®Œæ•´ç‰ˆæœ¬
åŒ…å«æ‰€æœ‰è¦–è¦ºåŒ–åŠŸèƒ½ï¼Œå»é™¤äº’å‹•å„€è¡¨æ¿
ä¿®æ”¹ç‰ˆæœ¬ï¼š2024å¹´è¶¨å‹¢èšé¡çš„ç¾¤èš2å’Œç¾¤èš3æ¨™ç±¤èª¿æ›
ä¿®æ­£ç‰ˆæœ¬ï¼šç§»é™¤é‡è¤‡çš„æ¨™ç±¤èª¿æ•´é‚è¼¯ï¼Œçµ±ä¸€æ¨™ç±¤è™•ç†
å¢å¼·ç‰ˆæœ¬ï¼šåŠ å…¥é¢±é¢¨æ¨™è¨»åŠŸèƒ½åˆ°ä¸‰å¹´åº¦è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–
é æ¸¬ç‰ˆæœ¬ï¼šæ–°å¢2025å¹´èšé¡é æ¸¬åŠŸèƒ½ (3ç¥¨2å‹åˆ¶)
"""

print("ğŸ¥¬ å®Œæ•´è”¬èœåƒ¹æ ¼DTWèšé¡åˆ†æç¨‹å¼åŒ… (2022-2024)")
print("ğŸŒªï¸ å¢å¼·ç‰ˆæœ¬ï¼šå«é¢±é¢¨æ¨™è¨»åŠŸèƒ½")
print("ğŸ”® é æ¸¬ç‰ˆæœ¬ï¼šå«2025å¹´èšé¡é æ¸¬")
print("=" * 80)

# å°å…¥å¿…è¦å¥—ä»¶
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from statsmodels.tsa.seasonal import seasonal_decompose
import os
import warnings
from datetime import datetime
from collections import defaultdict, Counter

print("âœ… åŸºæœ¬å¥—ä»¶å°å…¥å®Œæˆ")

# DTWå°å…¥
try:
    from fastdtw import fastdtw
    from scipy.spatial.distance import euclidean

    DTW_AVAILABLE = True
    print("âœ… FastDTWå·²å•Ÿç”¨")
except ImportError:
    DTW_AVAILABLE = False
    print("âš ï¸  ä½¿ç”¨æ­æ°è·é›¢æ›¿ä»£DTW")

# è¨­å®š
warnings.filterwarnings("ignore")
plt.rcParams["font.sans-serif"] = [
    "Microsoft JhengHei",
    "SimHei",
    "Arial Unicode MS",
    "DejaVu Sans",
]
plt.rcParams["axes.unicode_minus"] = False

# å›ºå®šèšé¡åƒæ•¸
SEASONAL_CLUSTERS = 2
TREND_CLUSTERS = 3

print(f"ğŸ¯ èšé¡åƒæ•¸: å­£ç¯€æ€§={SEASONAL_CLUSTERS}, è¶¨å‹¢={TREND_CLUSTERS}")


def predict_2025_clusters(comprehensive_df):
    """
    åŸºæ–¼2022-2024å¹´çš„èšé¡çµæœé æ¸¬2025å¹´çš„èšé¡æ­¸å±¬
    ä½¿ç”¨3ç¥¨2å‹åˆ¶ï¼šå¦‚æœæŸå€‹è”¬èœåœ¨3å¹´ä¸­æœ‰2å¹´æˆ–ä»¥ä¸Šå±¬æ–¼åŒä¸€èšé¡ï¼Œå‰‡é æ¸¬2025å¹´ä¹Ÿå±¬æ–¼è©²èšé¡
    """
    print("ğŸ”® é–‹å§‹é æ¸¬2025å¹´èšé¡çµæœ...")
    
    predictions = []
    trend_prediction_stats = {'confident': 0, 'uncertain': 0, 'insufficient_data': 0}
    seasonal_prediction_stats = {'confident': 0, 'uncertain': 0, 'insufficient_data': 0}
    
    for _, row in comprehensive_df.iterrows():
        vege_id = row['market_vege_id']
        vege_name = row['vege_name']
        
        # æ”¶é›†è¶¨å‹¢èšé¡æ­·å²
        trend_history = []
        for year in [2022, 2023, 2024]:
            if not pd.isna(row[f'trend_cluster_{year}']):
                trend_history.append(int(row[f'trend_cluster_{year}']))
        
        # æ”¶é›†å­£ç¯€æ€§èšé¡æ­·å²
        seasonal_history = []
        for year in [2022, 2023, 2024]:
            if not pd.isna(row[f'seasonal_cluster_{year}']):
                seasonal_history.append(int(row[f'seasonal_cluster_{year}']))
        
        # é æ¸¬è¶¨å‹¢èšé¡
        trend_prediction = None
        trend_confidence = 'insufficient_data'
        if len(trend_history) >= 2:
            trend_counter = Counter(trend_history)
            most_common = trend_counter.most_common(1)[0]
            if most_common[1] >= 2:  # è‡³å°‘å‡ºç¾2æ¬¡
                trend_prediction = most_common[0]
                trend_confidence = 'confident' if most_common[1] >= 2 else 'uncertain'
            else:
                # å¦‚æœæ²’æœ‰æ˜ç¢ºçš„å¤šæ•¸ï¼Œé¸æ“‡æœ€è¿‘å¹´ä»½çš„çµæœ
                trend_prediction = trend_history[-1]
                trend_confidence = 'uncertain'
        elif len(trend_history) == 1:
            trend_prediction = trend_history[0]
            trend_confidence = 'uncertain'
        
        # é æ¸¬å­£ç¯€æ€§èšé¡
        seasonal_prediction = None
        seasonal_confidence = 'insufficient_data'
        if len(seasonal_history) >= 2:
            seasonal_counter = Counter(seasonal_history)
            most_common = seasonal_counter.most_common(1)[0]
            if most_common[1] >= 2:  # è‡³å°‘å‡ºç¾2æ¬¡
                seasonal_prediction = most_common[0]
                seasonal_confidence = 'confident' if most_common[1] >= 2 else 'uncertain'
            else:
                # å¦‚æœæ²’æœ‰æ˜ç¢ºçš„å¤šæ•¸ï¼Œé¸æ“‡æœ€è¿‘å¹´ä»½çš„çµæœ
                seasonal_prediction = seasonal_history[-1]
                seasonal_confidence = 'uncertain'
        elif len(seasonal_history) == 1:
            seasonal_prediction = seasonal_history[0]
            seasonal_confidence = 'uncertain'
        
        # çµ±è¨ˆé æ¸¬ä¿¡å¿ƒ
        trend_prediction_stats[trend_confidence] += 1
        seasonal_prediction_stats[seasonal_confidence] += 1
        
        predictions.append({
            'market_vege_id': vege_id,
            'vege_name': vege_name,
            'trend_history': trend_history,
            'seasonal_history': seasonal_history,
            'predicted_trend_cluster_2025': trend_prediction,
            'predicted_seasonal_cluster_2025': seasonal_prediction,
            'trend_confidence': trend_confidence,
            'seasonal_confidence': seasonal_confidence
        })
    
    predictions_df = pd.DataFrame(predictions)
    
    print(f"   ğŸ“Š è¶¨å‹¢èšé¡é æ¸¬çµ±è¨ˆ:")
    print(f"      - é«˜ä¿¡å¿ƒé æ¸¬: {trend_prediction_stats['confident']} å€‹è”¬èœ")
    print(f"      - ä¸ç¢ºå®šé æ¸¬: {trend_prediction_stats['uncertain']} å€‹è”¬èœ")
    print(f"      - æ•¸æ“šä¸è¶³: {trend_prediction_stats['insufficient_data']} å€‹è”¬èœ")
    
    print(f"   ğŸ“Š å­£ç¯€æ€§èšé¡é æ¸¬çµ±è¨ˆ:")
    print(f"      - é«˜ä¿¡å¿ƒé æ¸¬: {seasonal_prediction_stats['confident']} å€‹è”¬èœ")
    print(f"      - ä¸ç¢ºå®šé æ¸¬: {seasonal_prediction_stats['uncertain']} å€‹è”¬èœ")
    print(f"      - æ•¸æ“šä¸è¶³: {seasonal_prediction_stats['insufficient_data']} å€‹è”¬èœ")
    
    return predictions_df, trend_prediction_stats, seasonal_prediction_stats


def create_enhanced_stability_heatmap_with_prediction(comprehensive_df, predictions_df, comparison_plots_dir, mapping_dict):
    """å‰µå»ºåŒ…å«2025å¹´é æ¸¬çš„å¢å¼·ç‰ˆèšé¡ç©©å®šæ€§ç†±åŠ›åœ–"""
    
    # æª¢æŸ¥predictions_dfæ˜¯å¦æœ‰å¿…è¦çš„æ¬„ä½
    required_cols = ['market_vege_id', 'predicted_trend_cluster_2025', 'predicted_seasonal_cluster_2025', 
                     'trend_confidence', 'seasonal_confidence']
    
    missing_cols = [col for col in required_cols if col not in predictions_df.columns]
    if missing_cols:
        print(f"   âš ï¸  é æ¸¬DataFrameç¼ºå°‘æ¬„ä½: {missing_cols}")
        print(f"   ğŸ’¡  å¯ç”¨æ¬„ä½: {list(predictions_df.columns)}")
        return None
    
    # åˆä½µæ­·å²æ•¸æ“šå’Œé æ¸¬æ•¸æ“š
    try:
        enhanced_df = comprehensive_df.merge(
            predictions_df[required_cols], 
            on='market_vege_id', how='left'
        )
    except Exception as e:
        print(f"   âŒ åˆä½µæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
    
    # æº–å‚™è¶¨å‹¢ç©©å®šæ€§æ•¸æ“šï¼ˆåŒ…å«2025é æ¸¬ï¼‰
    trend_data = []
    seasonal_data = []
    
    for _, row in enhanced_df.iterrows():
        vege_name = row['vege_name']
        
        # è¶¨å‹¢èšé¡æ•¸æ“šï¼ˆ2022-2024 + 2025é æ¸¬ï¼‰
        trend_row = []
        for year in [2022, 2023, 2024]:
            cluster_val = row.get(f'trend_cluster_{year}', np.nan)
            if pd.isna(cluster_val):
                trend_row.append(0)  # ç„¡æ•¸æ“šç”¨0è¡¨ç¤º
            else:
                trend_row.append(int(cluster_val))
        
        # æ·»åŠ 2025é æ¸¬
        pred_trend = row.get('predicted_trend_cluster_2025', np.nan)
        if pd.isna(pred_trend):
            trend_row.append(0)
        else:
            trend_row.append(int(pred_trend))
        
        trend_data.append([vege_name] + trend_row)
        
        # å­£ç¯€æ€§èšé¡æ•¸æ“šï¼ˆ2022-2024 + 2025é æ¸¬ï¼‰
        seasonal_row = []
        for year in [2022, 2023, 2024]:
            cluster_val = row.get(f'seasonal_cluster_{year}', np.nan)
            if pd.isna(cluster_val):
                seasonal_row.append(0)  # ç„¡æ•¸æ“šç”¨0è¡¨ç¤º
            else:
                seasonal_row.append(int(cluster_val))
        
        # æ·»åŠ 2025é æ¸¬
        pred_seasonal = row.get('predicted_seasonal_cluster_2025', np.nan)
        if pd.isna(pred_seasonal):
            seasonal_row.append(0)
        else:
            seasonal_row.append(int(pred_seasonal))
        
        seasonal_data.append([vege_name] + seasonal_row)

    # å‰µå»ºDataFrame
    trend_df = pd.DataFrame(trend_data, columns=['è”¬èœåç¨±', '2022', '2023', '2024', '2025é æ¸¬'])
    seasonal_df = pd.DataFrame(seasonal_data, columns=['è”¬èœåç¨±', '2022', '2023', '2024', '2025é æ¸¬'])
    
    # å‰µå»ºåœ–è¡¨
    fig, axes = plt.subplots(1, 2, figsize=(24, 15))
    fig.suptitle("è”¬èœèšé¡ç©©å®šæ€§åˆ†æç†±åŠ›åœ– (å«2025å¹´é æ¸¬)\n(2024å¹´è¶¨å‹¢èšé¡å·²èª¿æ•´ï¼Œ2025å¹´åŸºæ–¼3ç¥¨2å‹åˆ¶é æ¸¬)", fontsize=16, y=0.98)

    # è¶¨å‹¢èšé¡ç†±åŠ›åœ–
    trend_matrix = trend_df.set_index('è”¬èœåç¨±')[['2022', '2023', '2024', '2025é æ¸¬']].values
    im1 = axes[0].imshow(trend_matrix, cmap='viridis', aspect='auto', vmin=0, vmax=3)
    axes[0].set_title("è¶¨å‹¢èšé¡è®ŠåŒ– (0=ç„¡æ•¸æ“š, 1-3=èšé¡ç·¨è™Ÿ)\n2024å¹´ç¾¤èš2â†”ç¾¤èš3å·²èª¿æ›ï¼Œ2025å¹´ç‚ºé æ¸¬çµæœ", fontsize=14)
    axes[0].set_xlabel("å¹´ä»½")
    axes[0].set_ylabel("è”¬èœ")
    axes[0].set_xticks(range(4))
    axes[0].set_xticklabels(['2022', '2023', '2024', '2025é æ¸¬'])
    axes[0].set_yticks(range(len(trend_df)))
    axes[0].set_yticklabels(trend_df['è”¬èœåç¨±'], fontsize=8)
    
    # æ·»åŠ æ•¸å€¼æ¨™è¨»ï¼Œ2025é æ¸¬åˆ—ç‰¹æ®Šæ¨™ç¤º
    for i in range(len(trend_df)):
        for j in range(4):
            value = int(trend_matrix[i, j])
            color = "white" if value > 0 else "black"
            weight = 'bold' if j < 3 else 'normal'  # 2025é æ¸¬ç”¨æ™®é€šå­—é«”
            if j == 3 and value > 0:  # 2025é æ¸¬ä¸”æœ‰å€¼
                text = axes[0].text(j, i, f"{value}*", ha="center", va="center", 
                                  color=color, fontweight=weight, fontsize=9)
            else:
                text = axes[0].text(j, i, value, ha="center", va="center", 
                                  color=color, fontweight=weight)

    # å­£ç¯€æ€§èšé¡ç†±åŠ›åœ–
    seasonal_matrix = seasonal_df.set_index('è”¬èœåç¨±')[['2022', '2023', '2024', '2025é æ¸¬']].values
    im2 = axes[1].imshow(seasonal_matrix, cmap='plasma', aspect='auto', vmin=0, vmax=2)
    axes[1].set_title("å­£ç¯€æ€§èšé¡è®ŠåŒ– (0=ç„¡æ•¸æ“š, 1-2=èšé¡ç·¨è™Ÿ)\n2025å¹´ç‚ºé æ¸¬çµæœ", fontsize=14)
    axes[1].set_xlabel("å¹´ä»½")
    axes[1].set_ylabel("è”¬èœ")
    axes[1].set_xticks(range(4))
    axes[1].set_xticklabels(['2022', '2023', '2024', '2025é æ¸¬'])
    axes[1].set_yticks(range(len(seasonal_df)))
    axes[1].set_yticklabels(seasonal_df['è”¬èœåç¨±'], fontsize=8)
    
    # æ·»åŠ æ•¸å€¼æ¨™è¨»ï¼Œ2025é æ¸¬åˆ—ç‰¹æ®Šæ¨™ç¤º
    for i in range(len(seasonal_df)):
        for j in range(4):
            value = int(seasonal_matrix[i, j])
            color = "white" if value > 0 else "black"
            weight = 'bold' if j < 3 else 'normal'  # 2025é æ¸¬ç”¨æ™®é€šå­—é«”
            if j == 3 and value > 0:  # 2025é æ¸¬ä¸”æœ‰å€¼
                text = axes[1].text(j, i, f"{value}*", ha="center", va="center", 
                                  color=color, fontweight=weight, fontsize=9)
            else:
                text = axes[1].text(j, i, value, ha="center", va="center", 
                                  color=color, fontweight=weight)

    # æ·»åŠ é¡è‰²æ¢
    plt.colorbar(im1, ax=axes[0], shrink=0.8, label='è¶¨å‹¢èšé¡ç·¨è™Ÿ')
    plt.colorbar(im2, ax=axes[1], shrink=0.8, label='å­£ç¯€æ€§èšé¡ç·¨è™Ÿ')

    # æ·»åŠ èªªæ˜æ–‡å­—
    fig.text(0.5, 0.02, "è¨»ï¼š2025å¹´æ•¸æ“šæ¨™æœ‰ * è™Ÿè¡¨ç¤ºé æ¸¬å€¼ (åŸºæ–¼2022-2024å¹´æ­·å²æ•¸æ“šçš„3ç¥¨2å‹åˆ¶é æ¸¬)", 
             ha='center', fontsize=12, style='italic')

    plt.tight_layout(rect=[0, 0.05, 1, 0.96])
    
    heatmap_path = os.path.join(comparison_plots_dir, "èšé¡ç©©å®šæ€§ç†±åŠ›åœ–_å«2025é æ¸¬.png")
    plt.savefig(heatmap_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ å¢å¼·ç‰ˆèšé¡ç©©å®šæ€§ç†±åŠ›åœ–(å«2025é æ¸¬)å·²ä¿å­˜: èšé¡ç©©å®šæ€§ç†±åŠ›åœ–_å«2025é æ¸¬.png")
    return heatmap_path


def create_2025_prediction_analysis_charts(predictions_df, prediction_stats, comparison_plots_dir):
    """å‰µå»º2025å¹´é æ¸¬åˆ†æåœ–è¡¨"""
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•¸æ“š
    if len(predictions_df) == 0:
        print("   âš ï¸  æ²’æœ‰é æ¸¬æ•¸æ“šï¼Œè·³éé æ¸¬åˆ†æåœ–è¡¨")
        return None
    
    trend_stats, seasonal_stats = prediction_stats
    
    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 4, height_ratios=[1, 1, 1.2], hspace=0.3, wspace=0.3)
    fig.suptitle("2025å¹´è”¬èœèšé¡é æ¸¬åˆ†æ (åŸºæ–¼2022-2024å¹´3ç¥¨2å‹åˆ¶)", fontsize=16, y=0.98)

    # ç¬¬ä¸€è¡Œï¼šé æ¸¬ä¿¡å¿ƒåº¦åˆ†å¸ƒ
    # è¶¨å‹¢é æ¸¬ä¿¡å¿ƒåº¦
    ax1 = fig.add_subplot(gs[0, 0])
    confidence_labels = ['é«˜ä¿¡å¿ƒ', 'ä¸ç¢ºå®š', 'æ•¸æ“šä¸è¶³']
    trend_values = [trend_stats['confident'], trend_stats['uncertain'], trend_stats['insufficient_data']]
    colors = ['#2ecc71', '#f39c12', '#e74c3c']
    
    if sum(trend_values) > 0:
        wedges, texts, autotexts = ax1.pie(trend_values, labels=confidence_labels, autopct='%1.0f%%',
                                          colors=colors, startangle=90)
        ax1.set_title("è¶¨å‹¢èšé¡é æ¸¬ä¿¡å¿ƒåº¦", fontsize=12)
    else:
        ax1.text(0.5, 0.5, 'ç„¡è¶¨å‹¢é æ¸¬æ•¸æ“š', ha='center', va='center', transform=ax1.transAxes)
        ax1.set_title("è¶¨å‹¢èšé¡é æ¸¬ä¿¡å¿ƒåº¦", fontsize=12)

    # å­£ç¯€æ€§é æ¸¬ä¿¡å¿ƒåº¦
    ax2 = fig.add_subplot(gs[0, 1])
    seasonal_values = [seasonal_stats['confident'], seasonal_stats['uncertain'], seasonal_stats['insufficient_data']]
    
    if sum(seasonal_values) > 0:
        wedges, texts, autotexts = ax2.pie(seasonal_values, labels=confidence_labels, autopct='%1.0f%%',
                                          colors=colors, startangle=90)
        ax2.set_title("å­£ç¯€æ€§èšé¡é æ¸¬ä¿¡å¿ƒåº¦", fontsize=12)
    else:
        ax2.text(0.5, 0.5, 'ç„¡å­£ç¯€æ€§é æ¸¬æ•¸æ“š', ha='center', va='center', transform=ax2.transAxes)
        ax2.set_title("å­£ç¯€æ€§èšé¡é æ¸¬ä¿¡å¿ƒåº¦", fontsize=12)

    # 2025å¹´é æ¸¬èšé¡åˆ†å¸ƒ - è¶¨å‹¢
    ax3 = fig.add_subplot(gs[0, 2])
    trend_pred_counts = predictions_df['predicted_trend_cluster_2025'].value_counts().sort_index()
    if len(trend_pred_counts) > 0:
        ax3.bar(range(len(trend_pred_counts)), trend_pred_counts.values, 
               color=['#ff9999', '#66b3ff', '#99ff99'][:len(trend_pred_counts)])
        ax3.set_title("2025å¹´è¶¨å‹¢èšé¡é æ¸¬åˆ†å¸ƒ", fontsize=12)
        ax3.set_xlabel("èšé¡ç·¨è™Ÿ")
        ax3.set_ylabel("è”¬èœæ•¸é‡")
        ax3.set_xticks(range(len(trend_pred_counts)))
        ax3.set_xticklabels([f"è¶¨å‹¢ç¾¤{int(idx)}" for idx in trend_pred_counts.index])
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, v in enumerate(trend_pred_counts.values):
            ax3.text(i, v + 0.5, str(v), ha='center', va='bottom')
    else:
        ax3.text(0.5, 0.5, 'ç„¡è¶¨å‹¢é æ¸¬åˆ†å¸ƒ', ha='center', va='center', transform=ax3.transAxes)
        ax3.set_title("2025å¹´è¶¨å‹¢èšé¡é æ¸¬åˆ†å¸ƒ", fontsize=12)

    # 2025å¹´é æ¸¬èšé¡åˆ†å¸ƒ - å­£ç¯€æ€§
    ax4 = fig.add_subplot(gs[0, 3])
    seasonal_pred_counts = predictions_df['predicted_seasonal_cluster_2025'].value_counts().sort_index()
    if len(seasonal_pred_counts) > 0:
        ax4.bar(range(len(seasonal_pred_counts)), seasonal_pred_counts.values, 
               color=['#ffcc99', '#ff99cc'][:len(seasonal_pred_counts)])
        ax4.set_title("2025å¹´å­£ç¯€æ€§èšé¡é æ¸¬åˆ†å¸ƒ", fontsize=12)
        ax4.set_xlabel("èšé¡ç·¨è™Ÿ")
        ax4.set_ylabel("è”¬èœæ•¸é‡")
        ax4.set_xticks(range(len(seasonal_pred_counts)))
        ax4.set_xticklabels([f"å­£ç¯€ç¾¤{int(idx)}" for idx in seasonal_pred_counts.index])
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, v in enumerate(seasonal_pred_counts.values):
            ax4.text(i, v + 0.5, str(v), ha='center', va='bottom')
    else:
        ax4.text(0.5, 0.5, 'ç„¡å­£ç¯€æ€§é æ¸¬åˆ†å¸ƒ', ha='center', va='center', transform=ax4.transAxes)
        ax4.set_title("2025å¹´å­£ç¯€æ€§èšé¡é æ¸¬åˆ†å¸ƒ", fontsize=12)

    # ç¬¬äºŒè¡Œï¼šé æ¸¬ç©©å®šæ€§åˆ†æ
    # è¶¨å‹¢èšé¡ç©©å®šæ€§ï¼ˆ2022-2024ä¸€è‡´ä¸”2025é æ¸¬ç›¸åŒï¼‰
    ax5 = fig.add_subplot(gs[1, :2])
    
    stable_veges = []
    changing_veges = []
    
    for _, row in predictions_df.iterrows():
        if len(row.get('trend_history', [])) >= 3:  # æœ‰å®Œæ•´3å¹´æ•¸æ“š
            if len(set(row['trend_history'])) == 1:  # 3å¹´å®Œå…¨ä¸€è‡´
                if row.get('predicted_trend_cluster_2025') == row['trend_history'][0]:
                    stable_veges.append(f"{row['vege_name']} (ç¾¤{row['trend_history'][0]})")
                else:
                    pred_val = row.get('predicted_trend_cluster_2025', '?')
                    changing_veges.append(f"{row['vege_name']} ({row['trend_history'][0]}â†’{pred_val})")
    
    stability_data = ['å®Œå…¨ç©©å®š', 'é æ¸¬æ”¹è®Š']
    stability_counts = [len(stable_veges), len(changing_veges)]
    
    if sum(stability_counts) > 0:
        ax5.bar(stability_data, stability_counts, color=['#27ae60', '#e67e22'])
        ax5.set_title("è¶¨å‹¢èšé¡ç©©å®šæ€§é æ¸¬", fontsize=12)
        ax5.set_ylabel("è”¬èœæ•¸é‡")
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, v in enumerate(stability_counts):
            ax5.text(i, v + 0.5, str(v), ha='center', va='bottom', fontweight='bold')
    else:
        ax5.text(0.5, 0.5, 'ç„¡ç©©å®šæ€§æ•¸æ“š', ha='center', va='center', transform=ax5.transAxes)
        ax5.set_title("è¶¨å‹¢èšé¡ç©©å®šæ€§é æ¸¬", fontsize=12)

    # å­£ç¯€æ€§èšé¡ç©©å®šæ€§
    ax6 = fig.add_subplot(gs[1, 2:])
    
    seasonal_stable_veges = []
    seasonal_changing_veges = []
    
    for _, row in predictions_df.iterrows():
        if len(row.get('seasonal_history', [])) >= 3:  # æœ‰å®Œæ•´3å¹´æ•¸æ“š
            if len(set(row['seasonal_history'])) == 1:  # 3å¹´å®Œå…¨ä¸€è‡´
                if row.get('predicted_seasonal_cluster_2025') == row['seasonal_history'][0]:
                    seasonal_stable_veges.append(f"{row['vege_name']} (ç¾¤{row['seasonal_history'][0]})")
                else:
                    pred_val = row.get('predicted_seasonal_cluster_2025', '?')
                    seasonal_changing_veges.append(f"{row['vege_name']} ({row['seasonal_history'][0]}â†’{pred_val})")
    
    seasonal_stability_counts = [len(seasonal_stable_veges), len(seasonal_changing_veges)]
    
    if sum(seasonal_stability_counts) > 0:
        ax6.bar(stability_data, seasonal_stability_counts, color=['#8e44ad', '#d35400'])
        ax6.set_title("å­£ç¯€æ€§èšé¡ç©©å®šæ€§é æ¸¬", fontsize=12)
        ax6.set_ylabel("è”¬èœæ•¸é‡")
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, v in enumerate(seasonal_stability_counts):
            ax6.text(i, v + 0.5, str(v), ha='center', va='bottom', fontweight='bold')
    else:
        ax6.text(0.5, 0.5, 'ç„¡ç©©å®šæ€§æ•¸æ“š', ha='center', va='center', transform=ax6.transAxes)
        ax6.set_title("å­£ç¯€æ€§èšé¡ç©©å®šæ€§é æ¸¬", fontsize=12)

    # ç¬¬ä¸‰è¡Œï¼šé æ¸¬è©³ç´°åˆ—è¡¨
    ax7 = fig.add_subplot(gs[2, :])
    ax7.axis('off')
    
    # å‰µå»ºé æ¸¬æ‘˜è¦è¡¨æ ¼
    high_confidence_trend = predictions_df[predictions_df.get('trend_confidence', '') == 'confident']
    high_confidence_seasonal = predictions_df[predictions_df.get('seasonal_confidence', '') == 'confident']
    
    summary_text = []
    summary_text.append("ğŸ”® 2025å¹´èšé¡é æ¸¬æ‘˜è¦")
    summary_text.append("=" * 60)
    summary_text.append(f"ğŸ“Š ç¸½é æ¸¬è”¬èœæ•¸: {len(predictions_df)}")
    summary_text.append(f"ğŸ¯ é«˜ä¿¡å¿ƒè¶¨å‹¢é æ¸¬: {len(high_confidence_trend)} ç¨®è”¬èœ")
    summary_text.append(f"ğŸ¯ é«˜ä¿¡å¿ƒå­£ç¯€æ€§é æ¸¬: {len(high_confidence_seasonal)} ç¨®è”¬èœ")
    summary_text.append("")
    
    if len(stable_veges) > 0:
        summary_text.append("âœ… è¶¨å‹¢å®Œå…¨ç©©å®šè”¬èœ (2022-2025ä¸€è‡´):")
        for vege in stable_veges[:10]:  # åªé¡¯ç¤ºå‰10å€‹
            summary_text.append(f"   â€¢ {vege}")
        if len(stable_veges) > 10:
            summary_text.append(f"   â€¢ ... å…±{len(stable_veges)}ç¨®")
    
    summary_text.append("")
    
    if len(changing_veges) > 0:
        summary_text.append("ğŸ”„ é æ¸¬æœƒæ”¹è®Šçš„è”¬èœ:")
        for vege in changing_veges[:8]:  # åªé¡¯ç¤ºå‰8å€‹
            summary_text.append(f"   â€¢ {vege}")
        if len(changing_veges) > 8:
            summary_text.append(f"   â€¢ ... å…±{len(changing_veges)}ç¨®")
    
    # é¡¯ç¤ºæ‘˜è¦æ–‡å­—
    ax7.text(0.05, 0.95, '\n'.join(summary_text), transform=ax7.transAxes, 
            fontsize=10, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.7))

    plt.tight_layout()
    
    prediction_path = os.path.join(comparison_plots_dir, "2025å¹´èšé¡é æ¸¬åˆ†æ.png")
    plt.savefig(prediction_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ 2025å¹´èšé¡é æ¸¬åˆ†æåœ–å·²ä¿å­˜: 2025å¹´èšé¡é æ¸¬åˆ†æ.png")
    return prediction_path


def create_prediction_migration_flow_chart(comprehensive_df, predictions_df, comparison_plots_dir):
    """å‰µå»ºåŒ…å«2025å¹´é æ¸¬çš„èšé¡é·ç§»æµç¨‹åœ–"""
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•¸æ“š
    if len(predictions_df) == 0 or len(comprehensive_df) == 0:
        print("   âš ï¸  æ²’æœ‰è¶³å¤ æ•¸æ“šå‰µå»ºé·ç§»æµç¨‹åœ–")
        return None
    
    fig, axes = plt.subplots(2, 1, figsize=(18, 14))
    fig.suptitle("è”¬èœèšé¡é·ç§»æ¨¡å¼åˆ†æ (å«2025å¹´é æ¸¬)\n(2024å¹´è¶¨å‹¢èšé¡å·²èª¿æ•´ï¼Œ2025å¹´åŸºæ–¼3ç¥¨2å‹åˆ¶é æ¸¬)", fontsize=16)

    years = [2022, 2023, 2024, 2025]
    
    # æª¢æŸ¥predictions_dfæ˜¯å¦æœ‰å¿…è¦çš„æ¬„ä½
    required_cols = ['market_vege_id', 'predicted_trend_cluster_2025', 'predicted_seasonal_cluster_2025']
    missing_cols = [col for col in required_cols if col not in predictions_df.columns]
    if missing_cols:
        print(f"   âš ï¸  é æ¸¬DataFrameç¼ºå°‘æ¬„ä½: {missing_cols}")
        return None
    
    # åˆä½µæ•¸æ“š
    try:
        enhanced_df = comprehensive_df.merge(
            predictions_df[required_cols], 
            on='market_vege_id', how='left'
        )
    except Exception as e:
        print(f"   âŒ åˆä½µæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
    
    # è¶¨å‹¢èšé¡é·ç§»ï¼ˆåŒ…å«2024â†’2025é æ¸¬ï¼‰
    trend_transitions = {}
    for i in range(len(years)-1):
        year1, year2 = years[i], years[i+1]
        transitions = {}
        
        for _, row in enhanced_df.iterrows():
            if year1 == 2025:
                continue
            elif year2 == 2025:
                c1 = row.get(f'trend_cluster_{year1}', np.nan)
                c2 = row.get('predicted_trend_cluster_2025', np.nan)
            else:
                c1 = row.get(f'trend_cluster_{year1}', np.nan)
                c2 = row.get(f'trend_cluster_{year2}', np.nan)
            
            if not pd.isna(c1) and not pd.isna(c2):
                key = f"{int(c1)}â†’{int(c2)}"
                transitions[key] = transitions.get(key, 0) + 1
        
        period_label = f'{year1}-{year2}' + ('(é æ¸¬)' if year2 == 2025 else '')
        trend_transitions[period_label] = transitions

    # ç¹ªè£½è¶¨å‹¢é·ç§»
    ax1 = axes[0]
    x_pos = 0
    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'cyan', 'magenta']
    
    for period, transitions in trend_transitions.items():
        y_pos = 0
        max_val = max(transitions.values()) if transitions else 1
        
        for transition, count in sorted(transitions.items()):
            bar_color = colors[y_pos % len(colors)]
            alpha = 0.5 if 'é æ¸¬' in period else 0.7
            
            if count > 0:  # åªç¹ªè£½æœ‰æ•¸æ“šçš„é·ç§»
                ax1.barh(y_pos, count, left=x_pos, height=0.8, 
                        color=bar_color, alpha=alpha,
                        label=f'{transition} ({period})' if x_pos == 0 else "")
                
                # æ·»åŠ æ¨™ç±¤ï¼Œé æ¸¬æœŸé–“ç”¨ä¸åŒæ¨£å¼
                font_style = 'italic' if 'é æ¸¬' in period else 'normal'
                ax1.text(x_pos + count/2, y_pos, f'{transition}\n({count})', 
                        ha='center', va='center', fontsize=9, fontweight='bold',
                        style=font_style)
            y_pos += 1
        
        x_pos += max_val + 2

    ax1.set_title("è¶¨å‹¢èšé¡é·ç§»æ¨¡å¼ (æ ¼å¼: èµ·å§‹ç¾¤â†’ç›®æ¨™ç¾¤)\n2024å¹´æ•¸æ“šå·²å«ç¾¤èš2â†”ç¾¤èš3èª¿æ›ï¼Œ2024â†’2025ç‚ºé æ¸¬é·ç§»", fontsize=12)
    ax1.set_xlabel("é·ç§»æ•¸é‡")
    ax1.set_ylabel("é·ç§»é¡å‹")
    ax1.grid(True, alpha=0.3)

    # å­£ç¯€æ€§èšé¡é·ç§»ï¼ˆåŒ…å«2024â†’2025é æ¸¬ï¼‰
    seasonal_transitions = {}
    for i in range(len(years)-1):
        year1, year2 = years[i], years[i+1]
        transitions = {}
        
        for _, row in enhanced_df.iterrows():
            if year1 == 2025:
                continue
            elif year2 == 2025:
                c1 = row.get(f'seasonal_cluster_{year1}', np.nan)
                c2 = row.get('predicted_seasonal_cluster_2025', np.nan)
            else:
                c1 = row.get(f'seasonal_cluster_{year1}', np.nan)
                c2 = row.get(f'seasonal_cluster_{year2}', np.nan)
            
            if not pd.isna(c1) and not pd.isna(c2):
                key = f"{int(c1)}â†’{int(c2)}"
                transitions[key] = transitions.get(key, 0) + 1
        
        period_label = f'{year1}-{year2}' + ('(é æ¸¬)' if year2 == 2025 else '')
        seasonal_transitions[period_label] = transitions

    # ç¹ªè£½å­£ç¯€æ€§é·ç§»
    ax2 = axes[1]
    x_pos = 0
    
    for period, transitions in seasonal_transitions.items():
        y_pos = 0
        max_val = max(transitions.values()) if transitions else 1
        
        for transition, count in sorted(transitions.items()):
            bar_color = colors[y_pos % len(colors)]
            alpha = 0.5 if 'é æ¸¬' in period else 0.7
            
            if count > 0:  # åªç¹ªè£½æœ‰æ•¸æ“šçš„é·ç§»
                ax2.barh(y_pos, count, left=x_pos, height=0.8, 
                        color=bar_color, alpha=alpha,
                        label=f'{transition} ({period})' if x_pos == 0 else "")
                
                # æ·»åŠ æ¨™ç±¤ï¼Œé æ¸¬æœŸé–“ç”¨ä¸åŒæ¨£å¼
                font_style = 'italic' if 'é æ¸¬' in period else 'normal'
                ax2.text(x_pos + count/2, y_pos, f'{transition}\n({count})', 
                        ha='center', va='center', fontsize=9, fontweight='bold',
                        style=font_style)
            y_pos += 1
        
        x_pos += max_val + 2

    ax2.set_title("å­£ç¯€æ€§èšé¡é·ç§»æ¨¡å¼ (æ ¼å¼: èµ·å§‹ç¾¤â†’ç›®æ¨™ç¾¤)\n2024â†’2025ç‚ºé æ¸¬é·ç§»", fontsize=12)
    ax2.set_xlabel("é·ç§»æ•¸é‡")
    ax2.set_ylabel("é·ç§»é¡å‹")
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    
    migration_path = os.path.join(comparison_plots_dir, "èšé¡é·ç§»æµç¨‹åœ–_å«2025é æ¸¬.png")
    plt.savefig(migration_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ èšé¡é·ç§»æµç¨‹åœ–(å«2025é æ¸¬)å·²ä¿å­˜: èšé¡é·ç§»æµç¨‹åœ–_å«2025é æ¸¬.png")
    return migration_path


def create_2025_all_vegetables_clustering_chart(comprehensive_df, predictions_df, comparison_plots_dir, mapping_dict):
    """å‰µå»º2025å¹´æ‰€æœ‰è”¬èœçš„è¶¨å‹¢å’Œå­£ç¯€æ€§èšé¡çµæœç¸½è¦½åœ–"""
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•¸æ“š
    if len(predictions_df) == 0:
        print("   âš ï¸  æ²’æœ‰é æ¸¬æ•¸æ“šï¼Œè·³é2025å¹´ç¸½è¦½åœ–")
        return None
    
    # æª¢æŸ¥å¿…è¦æ¬„ä½
    required_cols = ['market_vege_id', 'predicted_trend_cluster_2025', 'predicted_seasonal_cluster_2025',
                     'trend_confidence', 'seasonal_confidence']
    missing_cols = [col for col in required_cols if col not in predictions_df.columns]
    if missing_cols:
        print(f"   âš ï¸  é æ¸¬DataFrameç¼ºå°‘æ¬„ä½: {missing_cols}")
        return None
    
    # åˆä½µæ•¸æ“š
    try:
        enhanced_df = comprehensive_df.merge(
            predictions_df[required_cols], 
            on='market_vege_id', how='left'
        )
    except Exception as e:
        print(f"   âŒ åˆä½µæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
    
    # éæ¿¾æœ‰æ•ˆé æ¸¬çš„è”¬èœ
    valid_predictions = enhanced_df[
        (~enhanced_df['predicted_trend_cluster_2025'].isna()) | 
        (~enhanced_df['predicted_seasonal_cluster_2025'].isna())
    ].copy()
    
    if len(valid_predictions) == 0:
        print("   âš ï¸  æ²’æœ‰æœ‰æ•ˆçš„é æ¸¬çµæœ")
        return None
    
    # å‰µå»ºåœ–è¡¨
    fig = plt.figure(figsize=(20, 16))
    gs = fig.add_gridspec(3, 2, height_ratios=[2, 2, 1], hspace=0.3, wspace=0.3)
    fig.suptitle("2025å¹´è”¬èœèšé¡é æ¸¬çµæœç¸½è¦½\n(åŸºæ–¼2022-2024å¹´3ç¥¨2å‹åˆ¶é æ¸¬)", fontsize=18, y=0.98)

    # æº–å‚™æ•¸æ“š
    vegetables = valid_predictions['vege_name'].tolist()
    trend_clusters = valid_predictions['predicted_trend_cluster_2025'].fillna(0).astype(int).tolist()
    seasonal_clusters = valid_predictions['predicted_seasonal_cluster_2025'].fillna(0).astype(int).tolist()
    trend_confidence = valid_predictions['trend_confidence'].fillna('insufficient_data').tolist()
    seasonal_confidence = valid_predictions['seasonal_confidence'].fillna('insufficient_data').tolist()
    
    # é¡è‰²æ˜ å°„
    trend_colors = {0: '#cccccc', 1: '#ff6b6b', 2: '#4ecdc4', 3: '#45b7d1'}  # 0=ç„¡é æ¸¬, 1-3=è¶¨å‹¢ç¾¤
    seasonal_colors = {0: '#cccccc', 1: '#ffa726', 2: '#ab47bc'}  # 0=ç„¡é æ¸¬, 1-2=å­£ç¯€ç¾¤
    confidence_alphas = {'confident': 1.0, 'uncertain': 0.6, 'insufficient_data': 0.3}
    
    # ç¬¬ä¸€è¡Œå·¦ï¼šè¶¨å‹¢èšé¡æ•£é»åœ–
    ax1 = fig.add_subplot(gs[0, 0])
    
    # æ ¹æ“šè¶¨å‹¢èšé¡åˆ†çµ„ç¹ªè£½
    for cluster in [1, 2, 3, 0]:  # 0æœ€å¾Œç¹ªè£½ï¼ˆç„¡é æ¸¬çš„ï¼‰
        cluster_data = valid_predictions[valid_predictions['predicted_trend_cluster_2025'].fillna(0) == cluster]
        if len(cluster_data) == 0:
            continue
            
        x_positions = range(len(cluster_data))
        y_positions = [cluster] * len(cluster_data)
        colors = [trend_colors[cluster]] * len(cluster_data)
        alphas = [confidence_alphas[conf] for conf in cluster_data['trend_confidence'].fillna('insufficient_data')]
        
        scatter = ax1.scatter(x_positions, y_positions, c=colors, alpha=alphas, s=100, edgecolors='black', linewidth=1)
        
        # æ·»åŠ è”¬èœåç¨±æ¨™ç±¤
        for i, (x, y, name, conf) in enumerate(zip(x_positions, y_positions, cluster_data['vege_name'], 
                                                  cluster_data['trend_confidence'].fillna('insufficient_data'))):
            fontweight = 'bold' if conf == 'confident' else 'normal'
            ax1.annotate(name, (x, y), xytext=(5, 5), textcoords='offset points', 
                        fontsize=8, fontweight=fontweight, rotation=45)
    
    ax1.set_title("2025å¹´è¶¨å‹¢èšé¡é æ¸¬çµæœ", fontsize=14, fontweight='bold')
    ax1.set_ylabel("è¶¨å‹¢èšé¡ç·¨è™Ÿ")
    ax1.set_xlabel("è”¬èœ (æŒ‰èšé¡åˆ†çµ„)")
    ax1.set_yticks([0, 1, 2, 3])
    ax1.set_yticklabels(['ç„¡é æ¸¬', 'è¶¨å‹¢ç¾¤1', 'è¶¨å‹¢ç¾¤2', 'è¶¨å‹¢ç¾¤3'])
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(-0.5, 3.5)
    
    # ç¬¬ä¸€è¡Œå³ï¼šå­£ç¯€æ€§èšé¡æ•£é»åœ–
    ax2 = fig.add_subplot(gs[0, 1])
    
    # æ ¹æ“šå­£ç¯€æ€§èšé¡åˆ†çµ„ç¹ªè£½
    for cluster in [1, 2, 0]:  # 0æœ€å¾Œç¹ªè£½ï¼ˆç„¡é æ¸¬çš„ï¼‰
        cluster_data = valid_predictions[valid_predictions['predicted_seasonal_cluster_2025'].fillna(0) == cluster]
        if len(cluster_data) == 0:
            continue
            
        x_positions = range(len(cluster_data))
        y_positions = [cluster] * len(cluster_data)
        colors = [seasonal_colors[cluster]] * len(cluster_data)
        alphas = [confidence_alphas[conf] for conf in cluster_data['seasonal_confidence'].fillna('insufficient_data')]
        
        scatter = ax2.scatter(x_positions, y_positions, c=colors, alpha=alphas, s=100, edgecolors='black', linewidth=1)
        
        # æ·»åŠ è”¬èœåç¨±æ¨™ç±¤
        for i, (x, y, name, conf) in enumerate(zip(x_positions, y_positions, cluster_data['vege_name'], 
                                                  cluster_data['seasonal_confidence'].fillna('insufficient_data'))):
            fontweight = 'bold' if conf == 'confident' else 'normal'
            ax2.annotate(name, (x, y), xytext=(5, 5), textcoords='offset points', 
                        fontsize=8, fontweight=fontweight, rotation=45)
    
    ax2.set_title("2025å¹´å­£ç¯€æ€§èšé¡é æ¸¬çµæœ", fontsize=14, fontweight='bold')
    ax2.set_ylabel("å­£ç¯€æ€§èšé¡ç·¨è™Ÿ")
    ax2.set_xlabel("è”¬èœ (æŒ‰èšé¡åˆ†çµ„)")
    ax2.set_yticks([0, 1, 2])
    ax2.set_yticklabels(['ç„¡é æ¸¬', 'å­£ç¯€ç¾¤1', 'å­£ç¯€ç¾¤2'])
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(-0.5, 2.5)
    
    # ç¬¬äºŒè¡Œï¼šèšé¡çµ„åˆçŸ©é™£ç†±åŠ›åœ–
    ax3 = fig.add_subplot(gs[1, :])
    
    # å‰µå»ºèšé¡çµ„åˆçŸ©é™£
    combination_matrix = np.zeros((4, 3))  # 4å€‹è¶¨å‹¢èšé¡(å«0) x 3å€‹å­£ç¯€æ€§èšé¡(å«0)
    combination_counts = {}
    
    for _, row in valid_predictions.iterrows():
        trend_cluster = int(row['predicted_trend_cluster_2025']) if not pd.isna(row['predicted_trend_cluster_2025']) else 0
        seasonal_cluster = int(row['predicted_seasonal_cluster_2025']) if not pd.isna(row['predicted_seasonal_cluster_2025']) else 0
        
        combination_matrix[trend_cluster, seasonal_cluster] += 1
        
        # è¨˜éŒ„çµ„åˆä¸­çš„è”¬èœåç¨±
        combo_key = f"T{trend_cluster}S{seasonal_cluster}"
        if combo_key not in combination_counts:
            combination_counts[combo_key] = []
        combination_counts[combo_key].append(row['vege_name'])
    
    # ç¹ªè£½ç†±åŠ›åœ–
    im = ax3.imshow(combination_matrix, cmap='YlOrRd', aspect='auto')
    
    # è¨­ç½®æ¨™ç±¤
    ax3.set_xticks(range(3))
    ax3.set_xticklabels(['ç„¡å­£ç¯€é æ¸¬', 'å­£ç¯€ç¾¤1', 'å­£ç¯€ç¾¤2'])
    ax3.set_yticks(range(4))
    ax3.set_yticklabels(['ç„¡è¶¨å‹¢é æ¸¬', 'è¶¨å‹¢ç¾¤1', 'è¶¨å‹¢ç¾¤2', 'è¶¨å‹¢ç¾¤3'])
    ax3.set_xlabel("å­£ç¯€æ€§èšé¡")
    ax3.set_ylabel("è¶¨å‹¢èšé¡")
    ax3.set_title("2025å¹´èšé¡çµ„åˆåˆ†å¸ƒç†±åŠ›åœ– (æ•¸å­—è¡¨ç¤ºè”¬èœæ•¸é‡)", fontsize=14, fontweight='bold')
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for i in range(4):
        for j in range(3):
            count = int(combination_matrix[i, j])
            if count > 0:
                ax3.text(j, i, str(count), ha="center", va="center", 
                        color="white" if count > combination_matrix.max()/2 else "black",
                        fontsize=12, fontweight='bold')
    
    # æ·»åŠ é¡è‰²æ¢
    plt.colorbar(im, ax=ax3, shrink=0.8, label='è”¬èœæ•¸é‡')
    
    # ç¬¬ä¸‰è¡Œï¼šè©³ç´°çµ±è¨ˆè¡¨æ ¼
    ax4 = fig.add_subplot(gs[2, :])
    ax4.axis('off')
    
    # å‰µå»ºçµ±è¨ˆæ‘˜è¦
    summary_text = []
    summary_text.append("ğŸ“Š 2025å¹´è”¬èœèšé¡é æ¸¬çµ±è¨ˆæ‘˜è¦")
    summary_text.append("=" * 80)
    summary_text.append(f"ğŸ”® ç¸½é æ¸¬è”¬èœæ•¸: {len(valid_predictions)}")
    
    # è¶¨å‹¢èšé¡çµ±è¨ˆ
    trend_stats_summary = valid_predictions['predicted_trend_cluster_2025'].value_counts().sort_index()
    summary_text.append(f"\nğŸ“ˆ è¶¨å‹¢èšé¡åˆ†å¸ƒ:")
    for cluster, count in trend_stats_summary.items():
        if not pd.isna(cluster):
            summary_text.append(f"   â€¢ è¶¨å‹¢ç¾¤{int(cluster)}: {count} ç¨®è”¬èœ")
    
    # å­£ç¯€æ€§èšé¡çµ±è¨ˆ
    seasonal_stats_summary = valid_predictions['predicted_seasonal_cluster_2025'].value_counts().sort_index()
    summary_text.append(f"\nğŸŒ± å­£ç¯€æ€§èšé¡åˆ†å¸ƒ:")
    for cluster, count in seasonal_stats_summary.items():
        if not pd.isna(cluster):
            summary_text.append(f"   â€¢ å­£ç¯€ç¾¤{int(cluster)}: {count} ç¨®è”¬èœ")
    
    # ä¿¡å¿ƒåº¦çµ±è¨ˆ
    trend_conf_stats = valid_predictions['trend_confidence'].value_counts()
    seasonal_conf_stats = valid_predictions['seasonal_confidence'].value_counts()
    summary_text.append(f"\nğŸ¯ é æ¸¬ä¿¡å¿ƒåº¦:")
    summary_text.append(f"   è¶¨å‹¢é æ¸¬ - é«˜ä¿¡å¿ƒ: {trend_conf_stats.get('confident', 0)}, ä¸ç¢ºå®š: {trend_conf_stats.get('uncertain', 0)}, æ•¸æ“šä¸è¶³: {trend_conf_stats.get('insufficient_data', 0)}")
    summary_text.append(f"   å­£ç¯€é æ¸¬ - é«˜ä¿¡å¿ƒ: {seasonal_conf_stats.get('confident', 0)}, ä¸ç¢ºå®š: {seasonal_conf_stats.get('uncertain', 0)}, æ•¸æ“šä¸è¶³: {seasonal_conf_stats.get('insufficient_data', 0)}")
    
    # ä¸»è¦çµ„åˆ
    summary_text.append(f"\nğŸ”„ ä¸»è¦èšé¡çµ„åˆ:")
    sorted_combos = sorted([(k, len(v)) for k, v in combination_counts.items() if len(v) > 0], 
                          key=lambda x: x[1], reverse=True)
    for combo, count in sorted_combos[:5]:  # é¡¯ç¤ºå‰5å€‹çµ„åˆ
        if count > 0:
            summary_text.append(f"   â€¢ {combo}: {count} ç¨®è”¬èœ")
    
    # é¡¯ç¤ºæ‘˜è¦æ–‡å­—
    summary_text_str = '\n'.join(summary_text)
    ax4.text(0.05, 0.95, summary_text_str, transform=ax4.transAxes, 
            fontsize=10, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8))
    
    # æ·»åŠ åœ–ä¾‹
    legend_elements = []
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#ff6b6b', 
                                     markersize=10, label='è¶¨å‹¢ç¾¤1', markeredgecolor='black'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#4ecdc4', 
                                     markersize=10, label='è¶¨å‹¢ç¾¤2', markeredgecolor='black'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#45b7d1', 
                                     markersize=10, label='è¶¨å‹¢ç¾¤3', markeredgecolor='black'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#ffa726', 
                                     markersize=10, label='å­£ç¯€ç¾¤1', markeredgecolor='black'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#ab47bc', 
                                     markersize=10, label='å­£ç¯€ç¾¤2', markeredgecolor='black'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='#cccccc', 
                                     markersize=10, label='ç„¡é æ¸¬', markeredgecolor='black'))
    
    # ä¿¡å¿ƒåº¦åœ–ä¾‹
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='black', 
                                     markersize=10, label='é«˜ä¿¡å¿ƒ', alpha=1.0, markeredgecolor='black'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='black', 
                                     markersize=10, label='ä¸ç¢ºå®š', alpha=0.6, markeredgecolor='black'))
    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='black', 
                                     markersize=10, label='æ•¸æ“šä¸è¶³', alpha=0.3, markeredgecolor='black'))
    
    # å°‡åœ–ä¾‹æ”¾åœ¨å³ä¸Šè§’
    fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.95), 
              title="èšé¡æ¨™ç±¤èˆ‡ä¿¡å¿ƒåº¦", title_fontsize=12, fontsize=10)
    
    plt.tight_layout()
    
    overview_path = os.path.join(comparison_plots_dir, "2025å¹´è”¬èœèšé¡é æ¸¬ç¸½è¦½.png")
    plt.savefig(overview_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

def create_2025_clustering_correlation_heatmap(comprehensive_df, predictions_df, comparison_plots_dir, mapping_dict):
    """å‰µå»º2025å¹´èšé¡é—œè¯æ€§åˆ†æç†±åŠ›åœ–ï¼Œç‰¹åˆ¥é—œæ³¨è¶¨å‹¢åˆ†ç¾¤3èˆ‡å­£ç¯€åˆ†ç¾¤2çš„é—œä¿‚"""
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆæ•¸æ“š
    if len(predictions_df) == 0:
        print("   âš ï¸  æ²’æœ‰é æ¸¬æ•¸æ“šï¼Œè·³éèšé¡é—œè¯æ€§åˆ†æ")
        return None
    
    # æª¢æŸ¥å¿…è¦æ¬„ä½
    required_cols = ['market_vege_id', 'predicted_trend_cluster_2025', 'predicted_seasonal_cluster_2025',
                     'trend_confidence', 'seasonal_confidence']
    missing_cols = [col for col in required_cols if col not in predictions_df.columns]
    if missing_cols:
        print(f"   âš ï¸  é æ¸¬DataFrameç¼ºå°‘æ¬„ä½: {missing_cols}")
        return None
    
    # åˆä½µæ•¸æ“š
    try:
        enhanced_df = comprehensive_df.merge(
            predictions_df[required_cols], 
            on='market_vege_id', how='left'
        )
    except Exception as e:
        print(f"   âŒ åˆä½µæ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
    
    # éæ¿¾æœ‰æ•ˆé æ¸¬çš„è”¬èœ
    valid_predictions = enhanced_df[
        (~enhanced_df['predicted_trend_cluster_2025'].isna()) & 
        (~enhanced_df['predicted_seasonal_cluster_2025'].isna())
    ].copy()
    
    if len(valid_predictions) == 0:
        print("   âš ï¸  æ²’æœ‰åŒæ™‚å…·æœ‰è¶¨å‹¢å’Œå­£ç¯€æ€§é æ¸¬çš„è”¬èœ")
        return None
    
    # å‰µå»ºåœ–è¡¨
    fig = plt.figure(figsize=(20, 16))
    gs = fig.add_gridspec(3, 3, height_ratios=[2, 1.5, 1], width_ratios=[2, 1, 1], 
                         hspace=0.3, wspace=0.3)
    fig.suptitle("2025å¹´è”¬èœèšé¡é—œè¯æ€§åˆ†æ\né‡é»é—œæ³¨ï¼šè¶¨å‹¢åˆ†ç¾¤3 â†” å­£ç¯€åˆ†ç¾¤2 çš„é—œä¿‚", 
                fontsize=18, y=0.98, fontweight='bold')

    # å‰µå»ºèšé¡é—œè¯çŸ©é™£
    trend_clusters = [1, 2, 3]
    seasonal_clusters = [1, 2]
    
    # åˆå§‹åŒ–çŸ©é™£å’Œè©³ç´°ä¿¡æ¯
    correlation_matrix = np.zeros((len(trend_clusters), len(seasonal_clusters)))
    cluster_details = {}
    
    for i, trend_cluster in enumerate(trend_clusters):
        for j, seasonal_cluster in enumerate(seasonal_clusters):
            # æ‰¾åˆ°å±¬æ–¼æ­¤çµ„åˆçš„è”¬èœ
            combo_veges = valid_predictions[
                (valid_predictions['predicted_trend_cluster_2025'] == trend_cluster) & 
                (valid_predictions['predicted_seasonal_cluster_2025'] == seasonal_cluster)
            ]
            
            count = len(combo_veges)
            correlation_matrix[i, j] = count
            
            # è¨˜éŒ„è©³ç´°ä¿¡æ¯
            key = f"T{trend_cluster}S{seasonal_cluster}"
            cluster_details[key] = {
                'count': count,
                'vegetables': combo_veges['vege_name'].tolist(),
                'trend_confidence': combo_veges['trend_confidence'].tolist(),
                'seasonal_confidence': combo_veges['seasonal_confidence'].tolist()
            }
    
    # ä¸»ç†±åŠ›åœ– (å·¦ä¸Šï¼Œè·¨å…©æ ¼)
    ax1 = fig.add_subplot(gs[0, :2])
    
    # å‰µå»ºè‡ªå®šç¾©é¡è‰²æ˜ å°„ï¼Œçªå‡ºé¡¯ç¤ºT3S2çµ„åˆ
    custom_colors = correlation_matrix.copy()
    max_val = correlation_matrix.max()
    
    # ä½¿ç”¨ä¸åŒçš„é¡è‰²æ–¹æ¡ˆçªå‡ºT3S2
    im1 = ax1.imshow(correlation_matrix, cmap='Reds', aspect='auto')
    
    # è¨­ç½®æ¨™ç±¤
    ax1.set_xticks(range(len(seasonal_clusters)))
    ax1.set_xticklabels([f'å­£ç¯€ç¾¤{s}' for s in seasonal_clusters], fontsize=12)
    ax1.set_yticks(range(len(trend_clusters)))
    ax1.set_yticklabels([f'è¶¨å‹¢ç¾¤{t}' for t in trend_clusters], fontsize=12)
    ax1.set_xlabel("å­£ç¯€æ€§èšé¡", fontsize=14, fontweight='bold')
    ax1.set_ylabel("è¶¨å‹¢èšé¡", fontsize=14, fontweight='bold')
    ax1.set_title("2025å¹´èšé¡çµ„åˆåˆ†å¸ƒç†±åŠ›åœ–", fontsize=16, fontweight='bold')
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤å’Œç‰¹æ®Šæ¨™è¨˜
    for i in range(len(trend_clusters)):
        for j in range(len(seasonal_clusters)):
            count = int(correlation_matrix[i, j])
            
            # ç‰¹åˆ¥æ¨™è¨˜T3S2çµ„åˆ
            if trend_clusters[i] == 3 and seasonal_clusters[j] == 2:
                # æ·»åŠ ç‰¹æ®Šé‚Šæ¡†
                rect = plt.Rectangle((j-0.4, i-0.4), 0.8, 0.8, fill=False, 
                                   edgecolor='gold', linewidth=4)
                ax1.add_patch(rect)
                
                # ç‰¹æ®Šæ¨™è¨˜æ–‡å­—
                ax1.text(j, i-0.2, f"â˜… {count} â˜…", ha="center", va="center", 
                        color="white" if count > max_val/2 else "black",
                        fontsize=16, fontweight='bold')
                ax1.text(j, i+0.2, "é‡é»çµ„åˆ", ha="center", va="center", 
                        color="gold", fontsize=10, fontweight='bold')
            else:
                ax1.text(j, i, str(count), ha="center", va="center", 
                        color="white" if count > max_val/2 else "black",
                        fontsize=14, fontweight='bold')
    
    # æ·»åŠ é¡è‰²æ¢
    plt.colorbar(im1, ax=ax1, shrink=0.8, label='è”¬èœæ•¸é‡')
    
    # æ¯”ä¾‹åˆ†æåœ– (å³ä¸Š)
    ax2 = fig.add_subplot(gs[0, 2])
    
    # è¨ˆç®—å„è¶¨å‹¢ç¾¤åœ¨ä¸åŒå­£ç¯€ç¾¤çš„åˆ†å¸ƒæ¯”ä¾‹
    trend_group_proportions = []
    trend_group_labels = []
    
    for i, trend_cluster in enumerate(trend_clusters):
        total_in_trend = correlation_matrix[i, :].sum()
        if total_in_trend > 0:
            proportions = correlation_matrix[i, :] / total_in_trend * 100
            
            # å‰µå»ºå †ç–Šæ¢å½¢åœ–
            bottom = 0
            for j, prop in enumerate(proportions):
                color = 'gold' if trend_cluster == 3 and seasonal_clusters[j] == 2 else f'C{j}'
                alpha = 1.0 if trend_cluster == 3 and seasonal_clusters[j] == 2 else 0.7
                
                ax2.bar(i, prop, bottom=bottom, 
                       color=color, alpha=alpha, 
                       label=f'å­£ç¯€ç¾¤{seasonal_clusters[j]}' if i == 0 else "",
                       edgecolor='black', linewidth=1)
                
                # æ·»åŠ ç™¾åˆ†æ¯”æ¨™ç±¤
                if prop > 5:  # åªåœ¨æ¯”ä¾‹å¤§æ–¼5%æ™‚é¡¯ç¤ºæ¨™ç±¤
                    ax2.text(i, bottom + prop/2, f'{prop:.0f}%', 
                           ha='center', va='center', fontweight='bold')
                
                bottom += prop
    
    ax2.set_xlabel('è¶¨å‹¢èšé¡', fontweight='bold')
    ax2.set_ylabel('å­£ç¯€ç¾¤åˆ†å¸ƒæ¯”ä¾‹ (%)', fontweight='bold')
    ax2.set_title('å„è¶¨å‹¢ç¾¤çš„å­£ç¯€æ€§åˆ†å¸ƒ', fontsize=12, fontweight='bold')
    ax2.set_xticks(range(len(trend_clusters)))
    ax2.set_xticklabels([f'è¶¨å‹¢ç¾¤{t}' for t in trend_clusters])
    ax2.legend(loc='upper right')
    ax2.set_ylim(0, 100)
    
    # ç‰¹æ®Šæ¨™è¨˜è¶¨å‹¢ç¾¤3
    ax2.axvline(x=2, color='gold', linestyle='--', linewidth=2, alpha=0.7)
    ax2.text(2, 95, 'é‡é»åˆ†æ', ha='center', va='top', color='gold', 
            fontweight='bold', fontsize=10)
    
    # T3S2è©³ç´°åˆ†æ (ä¸­é–“å·¦)
    ax3 = fig.add_subplot(gs[1, :2])
    ax3.axis('off')
    
    # åˆ†æT3S2çµ„åˆ
    t3s2_veges = cluster_details.get('T3S2', {})
    t3_total = sum(cluster_details.get(f'T3S{s}', {}).get('count', 0) for s in seasonal_clusters)
    s2_total = sum(cluster_details.get(f'T{t}S2', {}).get('count', 0) for t in trend_clusters)
    
    analysis_text = []
    analysis_text.append("ğŸ” è¶¨å‹¢åˆ†ç¾¤3 â†” å­£ç¯€åˆ†ç¾¤2 é—œè¯æ€§åˆ†æ")
    analysis_text.append("=" * 60)
    analysis_text.append(f"ğŸ“Š è¶¨å‹¢åˆ†ç¾¤3ç¸½è”¬èœæ•¸: {t3_total}")
    analysis_text.append(f"ğŸ“Š å­£ç¯€åˆ†ç¾¤2ç¸½è”¬èœæ•¸: {s2_total}")
    analysis_text.append(f"â­ T3S2çµ„åˆè”¬èœæ•¸: {t3s2_veges.get('count', 0)}")
    
    if t3_total > 0:
        t3_to_s2_ratio = (t3s2_veges.get('count', 0) / t3_total) * 100
        analysis_text.append(f"ğŸ“ˆ è¶¨å‹¢ç¾¤3ä¸­å±¬æ–¼å­£ç¯€ç¾¤2çš„æ¯”ä¾‹: {t3_to_s2_ratio:.1f}%")
        
        if t3_to_s2_ratio == 100:
            analysis_text.append("ğŸ¯ **é‡è¦ç™¼ç¾**: æ‰€æœ‰è¶¨å‹¢åˆ†ç¾¤3çš„è”¬èœéƒ½å±¬æ–¼å­£ç¯€åˆ†ç¾¤2ï¼")
        elif t3_to_s2_ratio >= 80:
            analysis_text.append("ğŸ¯ **é«˜åº¦é—œè¯**: è¶¨å‹¢åˆ†ç¾¤3èˆ‡å­£ç¯€åˆ†ç¾¤2é«˜åº¦ç›¸é—œï¼")
        elif t3_to_s2_ratio >= 50:
            analysis_text.append("ğŸ¯ **ä¸­åº¦é—œè¯**: è¶¨å‹¢åˆ†ç¾¤3èˆ‡å­£ç¯€åˆ†ç¾¤2æœ‰æ˜é¡¯é—œè¯")
        else:
            analysis_text.append("ğŸ¯ **ä½åº¦é—œè¯**: è¶¨å‹¢åˆ†ç¾¤3èˆ‡å­£ç¯€åˆ†ç¾¤2é—œè¯æ€§è¼ƒä½")
    
    if s2_total > 0:
        s2_from_t3_ratio = (t3s2_veges.get('count', 0) / s2_total) * 100
        analysis_text.append(f"ğŸ“ˆ å­£ç¯€ç¾¤2ä¸­ä¾†è‡ªè¶¨å‹¢ç¾¤3çš„æ¯”ä¾‹: {s2_from_t3_ratio:.1f}%")
    
    analysis_text.append("")
    analysis_text.append("ğŸ¥¬ T3S2çµ„åˆè”¬èœåˆ—è¡¨:")
    vegetables_list = t3s2_veges.get('vegetables', [])
    if vegetables_list:
        for i, vege in enumerate(vegetables_list):
            trend_conf = t3s2_veges.get('trend_confidence', [''])[i] if i < len(t3s2_veges.get('trend_confidence', [])) else ''
            seasonal_conf = t3s2_veges.get('seasonal_confidence', [''])[i] if i < len(t3s2_veges.get('seasonal_confidence', [])) else ''
            
            conf_indicator = ""
            if trend_conf == 'confident' and seasonal_conf == 'confident':
                conf_indicator = " â­â­"
            elif trend_conf == 'confident' or seasonal_conf == 'confident':
                conf_indicator = " â­"
            
            analysis_text.append(f"   â€¢ {vege}{conf_indicator}")
    else:
        analysis_text.append("   (ç„¡è”¬èœå±¬æ–¼æ­¤çµ„åˆ)")
    
    # é¡¯ç¤ºåˆ†ææ–‡å­—
    ax3.text(0.05, 0.95, '\n'.join(analysis_text), transform=ax3.transAxes, 
            fontsize=11, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.9))
    
    # ä¿¡å¿ƒåº¦åˆ†æ (ä¸­é–“å³)
    ax4 = fig.add_subplot(gs[1, 2])
    
    # åˆ†æT3S2çµ„åˆçš„é æ¸¬ä¿¡å¿ƒåº¦
    if t3s2_veges.get('count', 0) > 0:
        trend_conf_counts = pd.Series(t3s2_veges.get('trend_confidence', [])).value_counts()
        seasonal_conf_counts = pd.Series(t3s2_veges.get('seasonal_confidence', [])).value_counts()
        
        # å‰µå»ºä¿¡å¿ƒåº¦å°æ¯”åœ–
        conf_labels = ['confident', 'uncertain', 'insufficient_data']
        conf_colors = ['green', 'orange', 'red']
        
        x_pos = np.arange(len(conf_labels))
        width = 0.35
        
        trend_values = [trend_conf_counts.get(label, 0) for label in conf_labels]
        seasonal_values = [seasonal_conf_counts.get(label, 0) for label in conf_labels]
        
        ax4.bar(x_pos - width/2, trend_values, width, label='è¶¨å‹¢é æ¸¬', 
               color=conf_colors, alpha=0.7)
        ax4.bar(x_pos + width/2, seasonal_values, width, label='å­£ç¯€é æ¸¬', 
               color=conf_colors, alpha=0.5)
        
        ax4.set_xlabel('é æ¸¬ä¿¡å¿ƒåº¦')
        ax4.set_ylabel('è”¬èœæ•¸é‡')
        ax4.set_title('T3S2çµ„åˆ\né æ¸¬ä¿¡å¿ƒåº¦åˆ†å¸ƒ', fontweight='bold')
        ax4.set_xticks(x_pos)
        ax4.set_xticklabels(['é«˜ä¿¡å¿ƒ', 'ä¸ç¢ºå®š', 'æ•¸æ“šä¸è¶³'], rotation=45)
        ax4.legend()
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i, (t_val, s_val) in enumerate(zip(trend_values, seasonal_values)):
            if t_val > 0:
                ax4.text(i - width/2, t_val + 0.1, str(t_val), ha='center', va='bottom')
            if s_val > 0:
                ax4.text(i + width/2, s_val + 0.1, str(s_val), ha='center', va='bottom')
    else:
        ax4.text(0.5, 0.5, 'T3S2çµ„åˆ\nç„¡è”¬èœæ•¸æ“š', ha='center', va='center', 
                transform=ax4.transAxes, fontsize=12)
        ax4.set_title('T3S2çµ„åˆé æ¸¬ä¿¡å¿ƒåº¦', fontweight='bold')
    
    # å…¨å±€çµ±è¨ˆæ‘˜è¦ (åº•éƒ¨)
    ax5 = fig.add_subplot(gs[2, :])
    ax5.axis('off')
    
    # è¨ˆç®—å„ç¨®çµ±è¨ˆæŒ‡æ¨™
    total_valid = len(valid_predictions)
    
    summary_stats = []
    summary_stats.append("ğŸ“ˆ 2025å¹´èšé¡é—œè¯æ€§çµ±è¨ˆæ‘˜è¦")
    summary_stats.append("=" * 80)
    summary_stats.append(f"ğŸ“Š ç¸½æœ‰æ•ˆé æ¸¬è”¬èœæ•¸: {total_valid}")
    summary_stats.append("")
    
    # å„çµ„åˆçµ±è¨ˆ
    summary_stats.append("ğŸ”— æ‰€æœ‰èšé¡çµ„åˆåˆ†å¸ƒ:")
    for i, trend_cluster in enumerate(trend_clusters):
        for j, seasonal_cluster in enumerate(seasonal_clusters):
            count = int(correlation_matrix[i, j])
            percentage = (count / total_valid * 100) if total_valid > 0 else 0
            star = " â­" if trend_cluster == 3 and seasonal_cluster == 2 else ""
            summary_stats.append(f"   T{trend_cluster}S{seasonal_cluster}: {count} ç¨®è”¬èœ ({percentage:.1f}%){star}")
    
    summary_stats.append("")
    
    # é—œè¯æ€§åˆ†æçµè«–
    if t3_total > 0 and t3s2_veges.get('count', 0) == t3_total:
        summary_stats.append("ğŸ¯ **é—œéµç™¼ç¾**: 100%çš„è¶¨å‹¢åˆ†ç¾¤3è”¬èœéƒ½å±¬æ–¼å­£ç¯€åˆ†ç¾¤2")
        summary_stats.append("ğŸ’¡ **æ„ç¾©**: è¶¨å‹¢åˆ†ç¾¤3èˆ‡å­£ç¯€åˆ†ç¾¤2å­˜åœ¨å®Œç¾æ­£ç›¸é—œé—œä¿‚")
    elif t3_total > 0:
        ratio = (t3s2_veges.get('count', 0) / t3_total) * 100
        summary_stats.append(f"ğŸ¯ **é—œéµç™¼ç¾**: {ratio:.1f}%çš„è¶¨å‹¢åˆ†ç¾¤3è”¬èœå±¬æ–¼å­£ç¯€åˆ†ç¾¤2")
    
    # é¡¯ç¤ºçµ±è¨ˆæ‘˜è¦
    ax5.text(0.05, 0.95, '\n'.join(summary_stats), transform=ax5.transAxes, 
            fontsize=10, verticalalignment='top', fontfamily='monospace',
            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8))
    
    plt.tight_layout()
    
    correlation_path = os.path.join(comparison_plots_dir, "2025å¹´èšé¡é—œè¯æ€§åˆ†æç†±åŠ›åœ–.png")
    plt.savefig(correlation_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ 2025å¹´èšé¡é—œè¯æ€§åˆ†æç†±åŠ›åœ–å·²ä¿å­˜: 2025å¹´èšé¡é—œè¯æ€§åˆ†æç†±åŠ›åœ–.png")
    return correlation_path


# ä»¥ä¸‹ç‚ºåŸæœ‰å‡½æ•¸çš„å®Œæ•´ä»£ç¢¼ï¼ˆä¿æŒä¸è®Šï¼‰
def adjust_2024_trend_cluster_labels(cluster_labels, year):
    """
    èª¿æ•´2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤ï¼šå°‡ç¾¤èš2å’Œç¾¤èš3äº’æ›
    """
    if year == 2024:
        # å‰µå»ºæ¨™ç±¤æ˜ å°„ï¼š0->0, 1->2, 2->1 (å› ç‚ºåŸå§‹æ¨™ç±¤æ˜¯0-based)
        adjusted_labels = cluster_labels.copy()
        adjusted_labels[cluster_labels == 1] = 2  # åŸç¾¤èš2 -> ç¾¤èš3
        adjusted_labels[cluster_labels == 2] = 1  # åŸç¾¤èš3 -> ç¾¤èš2
        print(f"   ğŸ”„ 2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤å·²èª¿æ•´ï¼šç¾¤èš2â†”ç¾¤èš3")
        return adjusted_labels
    return cluster_labels


def load_vegetable_mapping():
    """è®€å–è”¬èœIDå°æ‡‰è¡¨ï¼Œå¦‚æœç„¡æ³•è®€å–å‰‡ä½¿ç”¨é è¨­å°æ‡‰"""
    mapping_file = "è”¬èœID_å°æ‡‰æª”æ¡ˆè¡¨.csv"

    # é è¨­è”¬èœåç¨±å°æ‡‰è¡¨
    default_mapping = {
        "FN1": "å››å­£è±†",
        "SG3": "è’œè‹—",
        "FN0": "è±‡è±†",
        # å¯ä»¥åœ¨é€™è£¡æ·»åŠ æ›´å¤šé è¨­å°æ‡‰
    }

    if os.path.exists(mapping_file):
        try:
            print(f"ğŸ” å˜—è©¦è®€å–è”¬èœIDå°æ‡‰è¡¨: {mapping_file}")

            # å˜—è©¦ä¸åŒç·¨ç¢¼å’Œåˆ†éš”ç¬¦
            for encoding in ["utf-8-sig", "utf-8", "big5", "gbk", "cp950"]:
                for sep in ["\t", ","]:
                    try:
                        df = pd.read_csv(mapping_file, encoding=encoding, sep=sep)

                        # æª¢æŸ¥æ¬„ä½åç¨±ï¼ˆå¯èƒ½æœ‰ä¸åŒçš„å‘½åæ–¹å¼ï¼‰
                        possible_id_cols = ["market_vege_id", "vege_id", "è”¬èœID", "id"]
                        possible_name_cols = [
                            "vege_name",
                            "vege.name",
                            "è”¬èœåç¨±",
                            "name",
                            "åç¨±",
                        ]

                        id_col = None
                        name_col = None

                        for col in df.columns:
                            if any(
                                pc in col.lower()
                                for pc in ["market_vege_id", "vege_id"]
                            ):
                                id_col = col
                            elif any(
                                pc in col.lower()
                                for pc in ["vege_name", "vege.name", "name"]
                            ):
                                name_col = col

                        if id_col and name_col:
                            # æ¸…ç†æ•¸æ“š
                            df = df.dropna(subset=[id_col, name_col])
                            df[name_col] = df[name_col].astype(str).str.strip()

                            # éæ¿¾æ‰æ˜é¡¯çš„äº‚ç¢¼ï¼ˆåŒ…å«ä¸å¯è¦‹å­—ç¬¦æˆ–é•·åº¦ç•°å¸¸ï¼‰
                            df = df[df[name_col].str.len() <= 10]
                            df = df[
                                ~df[name_col].str.contains(
                                    r"[^\u4e00-\u9fff\w\s]", regex=True, na=False
                                )
                            ]

                            if len(df) > 0:
                                mapping_dict = dict(zip(df[id_col], df[name_col]))
                                print(
                                    f"âœ… æˆåŠŸè®€å–è”¬èœIDå°æ‡‰è¡¨ (ç·¨ç¢¼: {encoding}, åˆ†éš”ç¬¦: '{sep}')"
                                )
                                print(f"ğŸ“‹ è®€å–åˆ° {len(mapping_dict)} å€‹æœ‰æ•ˆå°æ‡‰")

                                # é¡¯ç¤ºå‰å¹¾å€‹å°æ‡‰ä½œç‚ºé©—è­‰
                                sample_items = list(mapping_dict.items())[:5]
                                for k, v in sample_items:
                                    print(f"   {k}: {v}")

                                return mapping_dict
                    except Exception as e:
                        continue

        except Exception as e:
            print(f"âš ï¸ è®€å–å°æ‡‰è¡¨éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

    print("ğŸ“š ä½¿ç”¨å…§å»ºè”¬èœåç¨±å°æ‡‰è¡¨")
    print(f"ğŸ“‹ å…§å»ºå°æ‡‰è¡¨åŒ…å« {len(default_mapping)} å€‹è”¬èœ")
    return default_mapping


def get_chinese_name(vege_id, mapping_dict):
    """ç²å–è”¬èœçš„ä¸­æ–‡åç¨±"""
    return mapping_dict.get(vege_id, vege_id)


def create_id_to_name_mapping_list(vege_ids, mapping_dict):
    """å‰µå»ºIDåˆ°ä¸­æ–‡åç¨±çš„æ˜ å°„åˆ—è¡¨ï¼Œä¿æŒé †åº"""
    return [get_chinese_name(vege_id, mapping_dict) for vege_id in vege_ids]


def setup_directories():
    """å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾"""
    analysis_dir = "complete_vegetable_clustering_analysis"
    plots_dir = os.path.join(analysis_dir, "plots")
    decomp_plots_dir = os.path.join(plots_dir, "decomposition_examples")
    individual_plots_dir = os.path.join(plots_dir, "individual_vegetables")
    comparison_plots_dir = os.path.join(plots_dir, "comparison_analysis")

    for directory in [analysis_dir, plots_dir, decomp_plots_dir, individual_plots_dir, comparison_plots_dir]:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"âœ… å»ºç«‹è³‡æ–™å¤¾: {directory}")

    return analysis_dir, plots_dir, decomp_plots_dir, individual_plots_dir, comparison_plots_dir


def extract_typhoon_dates_from_data(df):
    """å¾è³‡æ–™ä¸­æå–é¢±é¢¨æ—¥æœŸ"""
    print("ğŸŒªï¸ å¾è³‡æ–™ä¸­æå–é¢±é¢¨æ—¥æœŸ...")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰typhoonæ¬„ä½
    if 'typhoon' not in df.columns:
        print("âš ï¸ è³‡æ–™ä¸­æœªæ‰¾åˆ°typhoonæ¬„ä½")
        return {}
    
    # æå–é¢±é¢¨æ—¥æœŸ
    typhoon_data = df[df['typhoon'] == 1].copy()
    
    if len(typhoon_data) == 0:
        print("âš ï¸ è³‡æ–™ä¸­æœªæ‰¾åˆ°é¢±é¢¨æ¨™è¨˜")
        return {}
    
    # æŒ‰å¹´ä»½åˆ†çµ„é¢±é¢¨æ—¥æœŸ
    typhoon_dates_by_year = {}
    
    for year in [2022, 2023, 2024]:
        year_typhoon = typhoon_data[typhoon_data['ObsTime'].dt.year == year]
        
        if len(year_typhoon) > 0:
            # ç²å–è©²å¹´åº¦çš„é¢±é¢¨æ—¥æœŸï¼Œä¸¦è½‰æ›ç‚ºå¹´å…§å¤©æ•¸
            year_dates = year_typhoon['ObsTime'].dt.dayofyear.unique()
            typhoon_dates_by_year[year] = sorted(year_dates)
            print(f"   ğŸ“… {year}å¹´: æ‰¾åˆ° {len(year_dates)} å€‹é¢±é¢¨æ—¥æœŸ")
        else:
            typhoon_dates_by_year[year] = []
            print(f"   ğŸ“… {year}å¹´: ç„¡é¢±é¢¨æ—¥æœŸ")
    
    return typhoon_dates_by_year


def dtw_distance(ts1, ts2):
    """è¨ˆç®—DTWè·é›¢"""
    if len(ts1) == 0 or len(ts2) == 0:
        return float("inf")

    ts1_clean = ts1[~np.isnan(ts1)]
    ts2_clean = ts2[~np.isnan(ts2)]

    if len(ts1_clean) == 0 or len(ts2_clean) == 0:
        return float("inf")

    try:
        if DTW_AVAILABLE:
            distance, _ = fastdtw(ts1_clean, ts2_clean, dist=euclidean)
            return distance
        else:
            min_len = min(len(ts1_clean), len(ts2_clean))
            return np.linalg.norm(ts1_clean[:min_len] - ts2_clean[:min_len])
    except:
        min_len = min(len(ts1_clean), len(ts2_clean))
        if min_len == 0:
            return float("inf")
        return np.linalg.norm(ts1_clean[:min_len] - ts2_clean[:min_len])


def decompose_time_series(df, vege_id, year, min_periods=60):
    """æ™‚é–“åºåˆ—åˆ†è§£"""
    vege_data = df[df["market_vege_id"] == vege_id].copy()

    if len(vege_data) < min_periods:
        return None

    vege_data = vege_data.sort_values("ObsTime").reset_index(drop=True)
    ts = pd.Series(
        vege_data["avg_price_per_kg"].values, index=pd.to_datetime(vege_data["ObsTime"])
    )

    ts = ts.dropna()
    if ts.index.duplicated().any():
        ts = ts[~ts.index.duplicated(keep="last")]

    if len(ts) < min_periods:
        return None

    # ç¢ºå®šåˆ†è§£é€±æœŸ
    n_obs = len(ts)
    if n_obs >= 365:
        period = 365
    elif n_obs >= 52:
        period = 52
    elif n_obs >= 30:
        period = 30
    else:
        period = max(2, n_obs // 3)

    try:
        decomp_add = seasonal_decompose(
            ts, model="additive", period=period, extrapolate_trend="freq"
        )

        # å˜—è©¦ä¹˜æ³•åˆ†è§£
        decomp_mul = None
        if (ts > 0).all():
            try:
                decomp_mul = seasonal_decompose(
                    ts, model="multiplicative", period=period, extrapolate_trend="freq"
                )
            except:
                pass

        return {
            "vege_id": vege_id,
            "year": year,
            "original": ts,
            "additive_trend": decomp_add.trend.dropna(),
            "additive_seasonal": decomp_add.seasonal.dropna(),
            "additive_residual": decomp_add.resid.dropna(),
            "multiplicative_trend": decomp_mul.trend.dropna() if decomp_mul else None,
            "multiplicative_seasonal": (
                decomp_mul.seasonal.dropna() if decomp_mul else None
            ),
            "multiplicative_residual": (
                decomp_mul.resid.dropna() if decomp_mul else None
            ),
            "period": period,
        }
    except Exception as e:
        print(f"      âŒ {vege_id} åˆ†è§£å¤±æ•—: {e}")
        return None


def create_distance_matrix(time_series_dict):
    """å‰µå»ºDTWè·é›¢çŸ©é™£"""
    vege_ids = list(time_series_dict.keys())
    n = len(vege_ids)
    distance_matrix = np.zeros((n, n))

    for i in range(n):
        for j in range(i + 1, n):
            ts1 = time_series_dict[vege_ids[i]]
            ts2 = time_series_dict[vege_ids[j]]

            dist = dtw_distance(ts1, ts2)
            distance_matrix[i, j] = dist
            distance_matrix[j, i] = dist

    return distance_matrix, vege_ids


def perform_clustering_with_evaluation(
    distance_matrix, vege_ids, n_clusters, k_range=(2, 8), year=None
):
    """åŸ·è¡Œèšé¡ä¸¦è©•ä¼°ä¸åŒKå€¼ï¼Œä¸¦æ‡‰ç”¨2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤èª¿æ•´"""
    max_dist = np.max(distance_matrix)
    if max_dist > 0:
        similarity_matrix = np.exp(-distance_matrix / (max_dist * 0.1))
    else:
        similarity_matrix = np.ones_like(distance_matrix)

    # è©•ä¼°ä¸åŒKå€¼
    silhouette_scores = []
    inertias = []
    max_k = min(k_range[1], len(vege_ids) - 1)
    k_values = range(k_range[0], max_k + 1)

    for k in k_values:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = kmeans.fit_predict(similarity_matrix)

        if len(set(labels)) > 1:
            sil_score = silhouette_score(similarity_matrix, labels)
            silhouette_scores.append(sil_score)
        else:
            silhouette_scores.append(-1)

        inertias.append(kmeans.inertia_)

    # ä½¿ç”¨æŒ‡å®šçš„èšé¡æ•¸
    final_kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = final_kmeans.fit_predict(similarity_matrix)

    # æ‡‰ç”¨2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤èª¿æ•´
    if year:
        cluster_labels = adjust_2024_trend_cluster_labels(cluster_labels, year)

    if len(set(cluster_labels)) > 1:
        final_silhouette = silhouette_score(similarity_matrix, cluster_labels)
    else:
        final_silhouette = -1

    return {
        "cluster_labels": cluster_labels,
        "silhouette_score": final_silhouette,
        "vege_ids": vege_ids,
        "n_clusters": n_clusters,
        "k_values": list(k_values),
        "silhouette_scores": silhouette_scores,
        "inertias": inertias,
        "similarity_matrix": similarity_matrix,
    }


def create_comprehensive_analysis(yearly_results, analysis_dir, mapping_dict):
    """å‰µå»ºç¶œåˆåˆ†æ"""
    # æ”¶é›†æ‰€æœ‰è”¬èœ
    all_veges = set()
    for results in yearly_results.values():
        all_veges.update(results["decomposition"].keys())
    all_veges = sorted(list(all_veges))

    # å‰µå»ºç¶œåˆè¡¨æ ¼
    comprehensive_data = []
    for vege_id in all_veges:
        vege_name = get_chinese_name(vege_id, mapping_dict)
        row_data = {"market_vege_id": vege_id, "vege_name": vege_name}

        for year in [2022, 2023, 2024]:
            if year in yearly_results:
                clustering = yearly_results[year]["clustering"]

                # è¶¨å‹¢èšé¡ - ç·¨è™Ÿå¾1é–‹å§‹ï¼Œ2024å¹´æ¨™ç±¤å·²åœ¨perform_clustering_with_evaluationä¸­èª¿æ•´
                if "trend" in clustering:
                    trend_result = clustering["trend"]
                    if vege_id in trend_result["vege_ids"]:
                        vege_idx = trend_result["vege_ids"].index(vege_id)
                        cluster_label = trend_result["cluster_labels"][vege_idx]
                        # æ³¨æ„ï¼šé€™è£¡ä¸å†é€²è¡Œé¡å¤–èª¿æ•´ï¼Œå› ç‚ºclustering resultå·²ç¶“åŒ…å«èª¿æ•´å¾Œçš„æ¨™ç±¤
                        row_data[f"trend_cluster_{year}"] = cluster_label + 1
                    else:
                        row_data[f"trend_cluster_{year}"] = np.nan
                else:
                    row_data[f"trend_cluster_{year}"] = np.nan

                # å­£ç¯€æ€§èšé¡ - ç·¨è™Ÿå¾1é–‹å§‹
                if "seasonal" in clustering:
                    seasonal_result = clustering["seasonal"]
                    if vege_id in seasonal_result["vege_ids"]:
                        vege_idx = seasonal_result["vege_ids"].index(vege_id)
                        row_data[f"seasonal_cluster_{year}"] = (
                            seasonal_result["cluster_labels"][vege_idx] + 1
                        )
                    else:
                        row_data[f"seasonal_cluster_{year}"] = np.nan
                else:
                    row_data[f"seasonal_cluster_{year}"] = np.nan
            else:
                row_data[f"trend_cluster_{year}"] = np.nan
                row_data[f"seasonal_cluster_{year}"] = np.nan

        # è¨ˆç®—ç©©å®šæ€§æŒ‡æ¨™
        trend_clusters = [
            row_data[f"trend_cluster_{year}"]
            for year in [2022, 2023, 2024]
            if not pd.isna(row_data[f"trend_cluster_{year}"])
        ]
        seasonal_clusters = [
            row_data[f"seasonal_cluster_{year}"]
            for year in [2022, 2023, 2024]
            if not pd.isna(row_data[f"seasonal_cluster_{year}"])
        ]

        row_data["trend_stability"] = (
            len(set(trend_clusters)) == 1 if len(trend_clusters) > 1 else np.nan
        )
        row_data["seasonal_stability"] = (
            len(set(seasonal_clusters)) == 1 if len(seasonal_clusters) > 1 else np.nan
        )
        row_data["years_analyzed"] = len(
            [
                year
                for year in [2022, 2023, 2024]
                if not pd.isna(row_data[f"trend_cluster_{year}"])
                or not pd.isna(row_data[f"seasonal_cluster_{year}"])
            ]
        )

        comprehensive_data.append(row_data)

    comprehensive_df = pd.DataFrame(comprehensive_data)
    comprehensive_path = os.path.join(analysis_dir, "ç¶œåˆèšé¡åˆ†æçµæœ.csv")
    comprehensive_df.to_csv(comprehensive_path, index=False, encoding="utf-8-sig")

    print(f"   ğŸ“ ç¶œåˆåˆ†æå·²ä¿å­˜: ç¶œåˆèšé¡åˆ†æçµæœ.csv")
    return comprehensive_df


def main():
    """ä¸»ç¨‹å¼"""
    print(f"ğŸ“‚ å·¥ä½œç›®éŒ„: {os.getcwd()}")
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # è¼‰å…¥è”¬èœåç¨±å°æ‡‰è¡¨
    print("\nğŸ” è¼‰å…¥è”¬èœåç¨±å°æ‡‰è¡¨...")
    mapping_dict = load_vegetable_mapping()

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    analysis_dir, plots_dir, decomp_plots_dir, individual_plots_dir, comparison_plots_dir = setup_directories()

    # è®€å–è³‡æ–™
    print("\nğŸ“‚ è®€å–å¤šå¹´åº¦è³‡æ–™...")
    df = pd.read_excel("daily_avg_price_vege.xlsx")
    df["ObsTime"] = pd.to_datetime(df["ObsTime"])
    print(f"âœ… æˆåŠŸè®€å– {len(df):,} ç­†è¨˜éŒ„")

    # æå–é¢±é¢¨æ—¥æœŸ
    typhoon_dates_by_year = extract_typhoon_dates_from_data(df)
    typhoon_summary = {year: len(dates) for year, dates in typhoon_dates_by_year.items()}

    # åˆ†å¹´ä»½è™•ç†
    yearly_results = {}

    for year in [2022, 2023, 2024]:
        print(f"\nğŸ“… åˆ†æ {year} å¹´...")
        year_df = df[df["ObsTime"].dt.year == year].copy()

        if len(year_df) == 0:
            print(f"   âš ï¸  {year}å¹´ç„¡è³‡æ–™")
            continue

        print(f"   ğŸ“Š {year}å¹´: {len(year_df):,} ç­†è¨˜éŒ„, {year_df['market_vege_id'].nunique()} ç¨®è”¬èœ")

        # æ™‚é–“åºåˆ—åˆ†è§£
        print("   ğŸ”„ åŸ·è¡Œæ™‚é–“åºåˆ—åˆ†è§£...")
        decomp_results = {}
        vege_ids = year_df["market_vege_id"].unique()

        for vege_id in vege_ids:
            vege_name = get_chinese_name(vege_id, mapping_dict)
            result = decompose_time_series(year_df, vege_id, year)
            if result is not None:
                decomp_results[vege_id] = result

        print(f"   âœ… æˆåŠŸåˆ†è§£ {len(decomp_results)} ç¨®è”¬èœ")

        if len(decomp_results) < max(SEASONAL_CLUSTERS, TREND_CLUSTERS):
            print(f"   âš ï¸  æœ‰æ•ˆåˆ†è§£æ•¸é‡ä¸è¶³ï¼Œè·³éèšé¡")
            yearly_results[year] = {
                "decomposition": decomp_results,
                "clustering": {},
            }
            continue

        year_clustering = {}

        # è¶¨å‹¢èšé¡
        if len(decomp_results) >= TREND_CLUSTERS:
            print("   ğŸ¯ åŸ·è¡Œè¶¨å‹¢èšé¡...")
            trend_series = {
                vege_id: result["additive_trend"].values
                for vege_id, result in decomp_results.items()
                if len(result["additive_trend"]) > 0
            }

            if len(trend_series) >= TREND_CLUSTERS:
                trend_dist_matrix, trend_vege_ids = create_distance_matrix(trend_series)
                trend_results = perform_clustering_with_evaluation(
                    trend_dist_matrix, trend_vege_ids, TREND_CLUSTERS, year=year
                )
                year_clustering["trend"] = trend_results

                print(f"      âœ… è¶¨å‹¢èšé¡å®Œæˆ (è¼ªå»“ä¿‚æ•¸: {trend_results['silhouette_score']:.3f})")

        # å­£ç¯€æ€§èšé¡
        if len(decomp_results) >= SEASONAL_CLUSTERS:
            print("   ğŸ¯ åŸ·è¡Œå­£ç¯€æ€§èšé¡...")
            seasonal_series = {
                vege_id: result["additive_seasonal"].values
                for vege_id, result in decomp_results.items()
                if len(result["additive_seasonal"]) > 0
            }

            if len(seasonal_series) >= SEASONAL_CLUSTERS:
                seasonal_dist_matrix, seasonal_vege_ids = create_distance_matrix(
                    seasonal_series
                )
                seasonal_results = perform_clustering_with_evaluation(
                    seasonal_dist_matrix, seasonal_vege_ids, SEASONAL_CLUSTERS
                )
                year_clustering["seasonal"] = seasonal_results

                print(f"      âœ… å­£ç¯€æ€§èšé¡å®Œæˆ (è¼ªå»“ä¿‚æ•¸: {seasonal_results['silhouette_score']:.3f})")

        yearly_results[year] = {
            "decomposition": decomp_results,
            "clustering": year_clustering,
        }

    # å‰µå»ºç¶œåˆåˆ†æ
    print("\nğŸ“‹ å‰µå»ºç¶œåˆåˆ†æ...")
    comprehensive_df = create_comprehensive_analysis(yearly_results, analysis_dir, mapping_dict)

    # æª¢æŸ¥æ˜¯å¦æœ‰èšé¡æ•¸æ“š
    has_clustering_data = False
    for col in comprehensive_df.columns:
        if 'cluster' in col and not comprehensive_df[col].isna().all():
            has_clustering_data = True
            break
    
    if not has_clustering_data:
        print("   âš ï¸  æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„èšé¡æ•¸æ“šï¼Œè·³éé æ¸¬åŠŸèƒ½")
        print("   ğŸ’¡  è«‹æª¢æŸ¥æ•¸æ“šæ˜¯å¦åŒ…å«è¶³å¤ çš„æ™‚é–“åºåˆ—ç”¨æ–¼èšé¡åˆ†æ")
        return

    # ğŸ”® æ–°å¢ï¼šé æ¸¬2025å¹´èšé¡çµæœ
    print("\nğŸ”® åŸ·è¡Œ2025å¹´èšé¡é æ¸¬...")
    predictions_df, trend_stats, seasonal_stats = predict_2025_clusters(comprehensive_df)
    prediction_stats = (trend_stats, seasonal_stats)

    # ä¿å­˜é æ¸¬çµæœ
    predictions_path = os.path.join(analysis_dir, "2025å¹´èšé¡é æ¸¬çµæœ.csv")
    predictions_df.to_csv(predictions_path, index=False, encoding="utf-8-sig")
    print(f"   ğŸ“ 2025å¹´é æ¸¬çµæœå·²ä¿å­˜: 2025å¹´èšé¡é æ¸¬çµæœ.csv")

    # æª¢æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆé æ¸¬
    total_predictions = len(predictions_df)
    valid_trend_predictions = len(predictions_df[~predictions_df['predicted_trend_cluster_2025'].isna()])
    valid_seasonal_predictions = len(predictions_df[~predictions_df['predicted_seasonal_cluster_2025'].isna()])
    
    if valid_trend_predictions == 0 and valid_seasonal_predictions == 0:
        print("   âš ï¸  æ²’æœ‰æœ‰æ•ˆçš„é æ¸¬çµæœï¼Œè·³éé æ¸¬åœ–è¡¨ç”Ÿæˆ")
        return

    # ğŸ¨ å‰µå»ºæ–°å¢çš„é æ¸¬åˆ†æåœ–è¡¨
    print("\nğŸ¨ å‰µå»ºé æ¸¬åˆ†æåœ–è¡¨...")
    
    try:
        # 1. å¢å¼·ç‰ˆç©©å®šæ€§ç†±åŠ›åœ–ï¼ˆå«2025é æ¸¬ï¼‰
        create_enhanced_stability_heatmap_with_prediction(
            comprehensive_df, predictions_df, comparison_plots_dir, mapping_dict
        )
        
        # 2. 2025å¹´é æ¸¬åˆ†æåœ–è¡¨
        create_2025_prediction_analysis_charts(
            predictions_df, prediction_stats, comparison_plots_dir
        )
        
        # 3. é æ¸¬é·ç§»æµç¨‹åœ–
        create_prediction_migration_flow_chart(
            comprehensive_df, predictions_df, comparison_plots_dir
        )
        
        # 4. æ–°å¢ï¼š2025å¹´æ‰€æœ‰è”¬èœèšé¡ç¸½è¦½åœ–
        create_2025_all_vegetables_clustering_chart(
            comprehensive_df, predictions_df, comparison_plots_dir, mapping_dict
        )
        
        # 5. æ–°å¢ï¼š2025å¹´èšé¡é—œè¯æ€§åˆ†æç†±åŠ›åœ–
        create_2025_clustering_correlation_heatmap(
            comprehensive_df, predictions_df, comparison_plots_dir, mapping_dict
        )
    except Exception as e:
        print(f"   âš ï¸  é æ¸¬åœ–è¡¨ç”Ÿæˆéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        print("   ğŸ’¡  ä½†é æ¸¬çµæœCSVå·²æˆåŠŸä¿å­˜")

    # æœ€çµ‚æ‘˜è¦
    print(f"\nğŸ‰ å®Œæ•´è”¬èœåƒ¹æ ¼DTWèšé¡åˆ†æå®Œæˆ (å«2025é æ¸¬)!")
    print("=" * 80)
    print(f"ğŸ“Š åˆ†æçµæœ:")
    print(f"   âœ… æˆåŠŸåˆ†æå¹´ä»½: {len(yearly_results)}")
    print(f"   ğŸ”® 2025å¹´é æ¸¬: {total_predictions} ç¨®è”¬èœ")
    print(f"   ğŸ“Š æœ‰æ•ˆè¶¨å‹¢é æ¸¬: {valid_trend_predictions} ç¨®è”¬èœ")
    print(f"   ğŸ“Š æœ‰æ•ˆå­£ç¯€æ€§é æ¸¬: {valid_seasonal_predictions} ç¨®è”¬èœ")

    # é æ¸¬çµ±è¨ˆæ‘˜è¦
    print(f"\nğŸ”® 2025å¹´é æ¸¬çµ±è¨ˆ:")
    print(f"   ğŸ“Š è¶¨å‹¢èšé¡é«˜ä¿¡å¿ƒé æ¸¬: {trend_stats['confident']} ç¨®è”¬èœ")
    print(f"   ğŸ“Š å­£ç¯€æ€§èšé¡é«˜ä¿¡å¿ƒé æ¸¬: {seasonal_stats['confident']} ç¨®è”¬èœ")

    print(f"\nğŸš€ æ–°å¢åŠŸèƒ½åŒ…å«:")
    print(f"   ğŸ”® 2025å¹´èšé¡é æ¸¬ (3ç¥¨2å‹åˆ¶)")
    print(f"   ğŸ“ˆ å¢å¼·ç‰ˆèšé¡ç©©å®šæ€§ç†±åŠ›åœ– (å«2025é æ¸¬)")
    print(f"   ğŸ“Š 2025å¹´é æ¸¬åˆ†æåœ–è¡¨")
    print(f"   ğŸ”„ é æ¸¬é·ç§»æµç¨‹åœ–")
    print(f"   ğŸ¯ 2025å¹´è”¬èœèšé¡é æ¸¬ç¸½è¦½åœ–")
    print(f"   ğŸ”— 2025å¹´èšé¡é—œè¯æ€§åˆ†æç†±åŠ›åœ–")
    print(f"   ğŸ“ 2025å¹´èšé¡é æ¸¬çµæœ.csv")

    print(f"\nâœ¨ å®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    print("ğŸš€ å®Œæ•´èšé¡åˆ†æç¨‹å¼é–‹å§‹åŸ·è¡Œ...")
    print("ğŸ”„ 2024å¹´è¶¨å‹¢èšé¡ä¿®æ”¹ç‰ˆæœ¬ - ç¾¤èš2â†”ç¾¤èš3æ¨™ç±¤èª¿æ›")
    print("ğŸ“ ä¿®æ­£ç‰ˆæœ¬ - çµ±ä¸€æ¨™ç±¤è™•ç†é‚è¼¯ï¼Œæ‰€æœ‰åœ–è¡¨æ¨™é¡Œå·²æ›´æ–°")
    print("ğŸŒªï¸ å¢å¼·ç‰ˆæœ¬ - å«é¢±é¢¨æ¨™è¨»åŠŸèƒ½")
    print("ğŸ”® é æ¸¬ç‰ˆæœ¬ - å«2025å¹´èšé¡é æ¸¬åŠŸèƒ½")
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ›” ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print(f"\nğŸ‘‹ ç¨‹å¼çµæŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")