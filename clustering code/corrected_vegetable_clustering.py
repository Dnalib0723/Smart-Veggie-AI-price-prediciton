#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®Œæ•´è”¬èœåƒ¹æ ¼DTWèšé¡åˆ†æç¨‹å¼åŒ… (2022-2024)
åŒ…å«åŸå§‹åˆ†æå’Œæ“´å¢åŠŸèƒ½çš„å®Œæ•´ç‰ˆæœ¬
åŒ…å«æ‰€æœ‰è¦–è¦ºåŒ–åŠŸèƒ½ï¼Œå»é™¤äº’å‹•å„€è¡¨æ¿
ä¿®æ”¹ç‰ˆæœ¬ï¼š2024å¹´è¶¨å‹¢èšé¡çš„ç¾¤èš2å’Œç¾¤èš3æ¨™ç±¤èª¿æ›
ä¿®æ­£ç‰ˆæœ¬ï¼šç§»é™¤é‡è¤‡çš„æ¨™ç±¤èª¿æ•´é‚è¼¯ï¼Œçµ±ä¸€æ¨™ç±¤è™•ç†
"""

print("ğŸ¥¬ å®Œæ•´è”¬èœåƒ¹æ ¼DTWèšé¡åˆ†æç¨‹å¼åŒ… (2022-2024)")
print("=" * 80)

# å°å…¥å¿…è¦å¥—ä»¶
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from statsmodels.tsa.seasonal import seasonal_decompose
import os
import warnings
from datetime import datetime
from collections import defaultdict

print("âœ… åŸºæœ¬å¥—ä»¶å°å…¥å®Œæˆ")

# DTWå°å…¥
try:
    from fastdtw import fastdtw
    from scipy.spatial.distance import euclidean

    DTW_AVAILABLE = True
    print("âœ… FastDTWå·²å•Ÿç”¨")
except ImportError:
    DTW_AVAILABLE = False
    print("âš ï¸  ä½¿ç”¨æ­æ°è·é›¢æ›¿ä»£DTW")

# è¨­å®š
warnings.filterwarnings("ignore")
plt.rcParams["font.sans-serif"] = [
    "Microsoft JhengHei",
    "SimHei",
    "Arial Unicode MS",
    "DejaVu Sans",
]
plt.rcParams["axes.unicode_minus"] = False

# å›ºå®šèšé¡åƒæ•¸
SEASONAL_CLUSTERS = 2
TREND_CLUSTERS = 3

print(f"ğŸ¯ èšé¡åƒæ•¸: å­£ç¯€æ€§={SEASONAL_CLUSTERS}, è¶¨å‹¢={TREND_CLUSTERS}")


def adjust_2024_trend_cluster_labels(cluster_labels, year):
    """
    èª¿æ•´2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤ï¼šå°‡ç¾¤èš2å’Œç¾¤èš3äº’æ›
    """
    if year == 2024:
        # å‰µå»ºæ¨™ç±¤æ˜ å°„ï¼š0->0, 1->2, 2->1 (å› ç‚ºåŸå§‹æ¨™ç±¤æ˜¯0-based)
        adjusted_labels = cluster_labels.copy()
        adjusted_labels[cluster_labels == 1] = 2  # åŸç¾¤èš2 -> ç¾¤èš3
        adjusted_labels[cluster_labels == 2] = 1  # åŸç¾¤èš3 -> ç¾¤èš2
        print(f"   ğŸ”„ 2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤å·²èª¿æ•´ï¼šç¾¤èš2â†”ç¾¤èš3")
        return adjusted_labels
    return cluster_labels


def load_vegetable_mapping():
    """è®€å–è”¬èœIDå°æ‡‰è¡¨ï¼Œå¦‚æœç„¡æ³•è®€å–å‰‡ä½¿ç”¨é è¨­å°æ‡‰"""
    mapping_file = "è”¬èœID_å°æ‡‰æª”æ¡ˆè¡¨.csv"

    # é è¨­è”¬èœåç¨±å°æ‡‰è¡¨
    default_mapping = {
        "FN1": "å››å­£è±†",
        "SG3": "è’œè‹—",
        "FN0": "è±‡è±†",
    }

    if os.path.exists(mapping_file):
        try:
            print(f"ğŸ” å˜—è©¦è®€å–è”¬èœIDå°æ‡‰è¡¨: {mapping_file}")

            # å˜—è©¦ä¸åŒç·¨ç¢¼å’Œåˆ†éš”ç¬¦
            for encoding in ["utf-8-sig", "utf-8", "big5", "gbk", "cp950"]:
                for sep in ["\t", ","]:
                    try:
                        df = pd.read_csv(mapping_file, encoding=encoding, sep=sep)

                        # æª¢æŸ¥æ¬„ä½åç¨±ï¼ˆå¯èƒ½æœ‰ä¸åŒçš„å‘½åæ–¹å¼ï¼‰
                        possible_id_cols = ["market_vege_id", "vege_id", "è”¬èœID", "id"]
                        possible_name_cols = [
                            "vege_name",
                            "vege.name",
                            "è”¬èœåç¨±",
                            "name",
                            "åç¨±",
                        ]

                        id_col = None
                        name_col = None

                        for col in df.columns:
                            if any(
                                pc in col.lower()
                                for pc in ["market_vege_id", "vege_id"]
                            ):
                                id_col = col
                            elif any(
                                pc in col.lower()
                                for pc in ["vege_name", "vege.name", "name"]
                            ):
                                name_col = col

                        if id_col and name_col:
                            # æ¸…ç†æ•¸æ“š
                            df = df.dropna(subset=[id_col, name_col])
                            df[name_col] = df[name_col].astype(str).str.strip()

                            # éæ¿¾æ‰æ˜é¡¯çš„äº‚ç¢¼ï¼ˆåŒ…å«ä¸å¯è¦‹å­—ç¬¦æˆ–é•·åº¦ç•°å¸¸ï¼‰
                            df = df[df[name_col].str.len() <= 10]
                            df = df[
                                ~df[name_col].str.contains(
                                    r"[^\u4e00-\u9fff\w\s]", regex=True, na=False
                                )
                            ]

                            if len(df) > 0:
                                mapping_dict = dict(zip(df[id_col], df[name_col]))
                                print(
                                    f"âœ… æˆåŠŸè®€å–è”¬èœIDå°æ‡‰è¡¨ (ç·¨ç¢¼: {encoding}, åˆ†éš”ç¬¦: '{sep}')"
                                )
                                print(f"ğŸ“‹ è®€å–åˆ° {len(mapping_dict)} å€‹æœ‰æ•ˆå°æ‡‰")

                                # é¡¯ç¤ºå‰å¹¾å€‹å°æ‡‰ä½œç‚ºé©—è­‰
                                sample_items = list(mapping_dict.items())[:5]
                                for k, v in sample_items:
                                    print(f"   {k}: {v}")

                                return mapping_dict
                    except Exception as e:
                        continue

        except Exception as e:
            print(f"âš ï¸ è®€å–å°æ‡‰è¡¨éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

    print("ğŸ“š ä½¿ç”¨å…§å»ºè”¬èœåç¨±å°æ‡‰è¡¨")
    print(f"ğŸ“‹ å…§å»ºå°æ‡‰è¡¨åŒ…å« {len(default_mapping)} å€‹è”¬èœ")
    return default_mapping


def get_chinese_name(vege_id, mapping_dict):
    """ç²å–è”¬èœçš„ä¸­æ–‡åç¨±"""
    return mapping_dict.get(vege_id, vege_id)


def create_id_to_name_mapping_list(vege_ids, mapping_dict):
    """å‰µå»ºIDåˆ°ä¸­æ–‡åç¨±çš„æ˜ å°„åˆ—è¡¨ï¼Œä¿æŒé †åº"""
    return [get_chinese_name(vege_id, mapping_dict) for vege_id in vege_ids]


def setup_directories():
    """å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾"""
    analysis_dir = "complete_vegetable_clustering_analysis"
    plots_dir = os.path.join(analysis_dir, "plots")
    decomp_plots_dir = os.path.join(plots_dir, "decomposition_examples")
    individual_plots_dir = os.path.join(plots_dir, "individual_vegetables")
    comparison_plots_dir = os.path.join(plots_dir, "comparison_analysis")

    for directory in [
        analysis_dir,
        plots_dir,
        decomp_plots_dir,
        individual_plots_dir,
        comparison_plots_dir,
    ]:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"âœ… å»ºç«‹è³‡æ–™å¤¾: {directory}")

    return (
        analysis_dir,
        plots_dir,
        decomp_plots_dir,
        individual_plots_dir,
        comparison_plots_dir,
    )


def dtw_distance(ts1, ts2):
    """è¨ˆç®—DTWè·é›¢"""
    if len(ts1) == 0 or len(ts2) == 0:
        return float("inf")

    ts1_clean = ts1[~np.isnan(ts1)]
    ts2_clean = ts2[~np.isnan(ts2)]

    if len(ts1_clean) == 0 or len(ts2_clean) == 0:
        return float("inf")

    try:
        if DTW_AVAILABLE:
            distance, _ = fastdtw(ts1_clean, ts2_clean, dist=euclidean)
            return distance
        else:
            min_len = min(len(ts1_clean), len(ts2_clean))
            return np.linalg.norm(ts1_clean[:min_len] - ts2_clean[:min_len])
    except:
        min_len = min(len(ts1_clean), len(ts2_clean))
        if min_len == 0:
            return float("inf")
        return np.linalg.norm(ts1_clean[:min_len] - ts2_clean[:min_len])


def decompose_time_series(df, vege_id, year, min_periods=60):
    """æ™‚é–“åºåˆ—åˆ†è§£"""
    vege_data = df[df["market_vege_id"] == vege_id].copy()

    if len(vege_data) < min_periods:
        return None

    vege_data = vege_data.sort_values("ObsTime").reset_index(drop=True)
    ts = pd.Series(
        vege_data["avg_price_per_kg"].values, index=pd.to_datetime(vege_data["ObsTime"])
    )

    ts = ts.dropna()
    if ts.index.duplicated().any():
        ts = ts[~ts.index.duplicated(keep="last")]

    if len(ts) < min_periods:
        return None

    # ç¢ºå®šåˆ†è§£é€±æœŸ
    n_obs = len(ts)
    if n_obs >= 365:
        period = 365
    elif n_obs >= 52:
        period = 52
    elif n_obs >= 30:
        period = 30
    else:
        period = max(2, n_obs // 3)

    try:
        decomp_add = seasonal_decompose(
            ts, model="additive", period=period, extrapolate_trend="freq"
        )

        # å˜—è©¦ä¹˜æ³•åˆ†è§£
        decomp_mul = None
        if (ts > 0).all():
            try:
                decomp_mul = seasonal_decompose(
                    ts, model="multiplicative", period=period, extrapolate_trend="freq"
                )
            except:
                pass

        return {
            "vege_id": vege_id,
            "year": year,
            "original": ts,
            "additive_trend": decomp_add.trend.dropna(),
            "additive_seasonal": decomp_add.seasonal.dropna(),
            "additive_residual": decomp_add.resid.dropna(),
            "multiplicative_trend": decomp_mul.trend.dropna() if decomp_mul else None,
            "multiplicative_seasonal": (
                decomp_mul.seasonal.dropna() if decomp_mul else None
            ),
            "multiplicative_residual": (
                decomp_mul.resid.dropna() if decomp_mul else None
            ),
            "period": period,
        }
    except Exception as e:
        print(f"      âŒ {vege_id} åˆ†è§£å¤±æ•—: {e}")
        return None


def create_decomposition_example_plot(decomp_result, decomp_plots_dir, mapping_dict):
    """å‰µå»ºæ™‚é–“åºåˆ—åˆ†è§£ç¯„ä¾‹åœ–"""
    vege_id = decomp_result["vege_id"]
    vege_name = get_chinese_name(vege_id, mapping_dict)
    year = decomp_result["year"]

    fig, axes = plt.subplots(4, 2, figsize=(16, 12))
    fig.suptitle(f"{vege_name} ({vege_id}) æ™‚é–“åºåˆ—åˆ†è§£", fontsize=16, y=0.98)

    # å·¦å´ï¼šåŠ æ³•åˆ†è§£
    # åŸå§‹æ•¸æ“š
    axes[0, 0].plot(decomp_result["original"], color="blue", linewidth=1)
    axes[0, 0].set_title("åŸå§‹æ•¸æ“š", fontsize=12)
    axes[0, 0].grid(True, alpha=0.3)

    # è¶¨å‹¢
    axes[1, 0].plot(decomp_result["additive_trend"], color="red", linewidth=1.5)
    axes[1, 0].set_title("è¶¨å‹¢", fontsize=12)
    axes[1, 0].grid(True, alpha=0.3)

    # å­£ç¯€æ€§
    axes[2, 0].plot(decomp_result["additive_seasonal"], color="green", linewidth=1)
    axes[2, 0].set_title("å­£ç¯€æ€§", fontsize=12)
    axes[2, 0].grid(True, alpha=0.3)

    # æ®˜å·®
    axes[3, 0].scatter(
        decomp_result["additive_residual"].index,
        decomp_result["additive_residual"].values,
        alpha=0.6,
        s=10,
        color="orange",
    )
    axes[3, 0].axhline(y=0, color="black", linestyle="--", alpha=0.7)
    axes[3, 0].set_title("æ®˜å·®", fontsize=12)
    axes[3, 0].grid(True, alpha=0.3)

    fig.text(0.25, 0.95, "åŠ æ³•åˆ†è§£", ha="center", fontsize=14, weight="bold")

    # å³å´ï¼šä¹˜æ³•åˆ†è§£
    if decomp_result["multiplicative_trend"] is not None:
        # åŸå§‹æ•¸æ“š
        axes[0, 1].plot(decomp_result["original"], color="blue", linewidth=1)
        axes[0, 1].set_title("åŸå§‹æ•¸æ“š", fontsize=12)
        axes[0, 1].grid(True, alpha=0.3)

        # è¶¨å‹¢
        axes[1, 1].plot(
            decomp_result["multiplicative_trend"], color="red", linewidth=1.5
        )
        axes[1, 1].set_title("è¶¨å‹¢", fontsize=12)
        axes[1, 1].grid(True, alpha=0.3)

        # å­£ç¯€æ€§
        axes[2, 1].plot(
            decomp_result["multiplicative_seasonal"], color="green", linewidth=1
        )
        axes[2, 1].set_title("å­£ç¯€æ€§", fontsize=12)
        axes[2, 1].grid(True, alpha=0.3)

        # æ®˜å·®
        axes[3, 1].scatter(
            decomp_result["multiplicative_residual"].index,
            decomp_result["multiplicative_residual"].values,
            alpha=0.6,
            s=10,
            color="orange",
        )
        axes[3, 1].axhline(y=1, color="black", linestyle="--", alpha=0.7)
        axes[3, 1].set_title("æ®˜å·®", fontsize=12)
        axes[3, 1].grid(True, alpha=0.3)

        fig.text(0.75, 0.95, "ä¹˜æ³•åˆ†è§£", ha="center", fontsize=14, weight="bold")
    else:
        # éš±è—å³å´åœ–è¡¨
        for i in range(4):
            axes[i, 1].set_visible(False)
        fig.text(
            0.75,
            0.5,
            "ä¹˜æ³•åˆ†è§£\nç„¡æ³•åŸ·è¡Œ\n(åŒ…å«éæ­£å€¼)",
            ha="center",
            va="center",
            fontsize=12,
            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"),
        )

    # æ ¼å¼åŒ–xè»¸
    for ax in axes.flatten():
        if ax.get_visible():
            ax.tick_params(axis="x", rotation=45)
            ax.tick_params(axis="both", labelsize=10)

    plt.tight_layout(rect=[0, 0, 1, 0.93])

    plot_path = os.path.join(decomp_plots_dir, f"{vege_name}_{vege_id}_{year}_åˆ†è§£.png")
    plt.savefig(plot_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()


def create_individual_vegetable_clustering_chart(
    vege_id, vege_name, decomp_results, clustering_results, individual_plots_dir
):
    """ç‚ºå–®ä¸€è”¬èœå‰µå»ºèšé¡çµæœå’Œè¶¨å‹¢æ¯”è¼ƒåœ–

    æ³¨æ„ï¼šé€™è£¡ç›´æ¥ä½¿ç”¨å·²ç¶“è™•ç†éçš„èšé¡çµæœï¼Œä¸å†é€²è¡Œé¡å¤–çš„æ¨™ç±¤èª¿æ•´
    å› ç‚ºclustering_resultsä¸­å·²ç¶“åŒ…å«äº†èª¿æ•´å¾Œçš„æœ€çµ‚æ¨™ç±¤
    """

    # æº–å‚™æ•¸æ“š
    years = [2022, 2023, 2024]
    trend_clusters = []
    seasonal_clusters = []

    # å¾clustering_resultsä¸­æå–è©²è”¬èœçš„èšé¡çµæœ
    # æ³¨æ„ï¼šé€™è£¡ç›´æ¥ä½¿ç”¨æœ€çµ‚çš„èšé¡æ¨™ç±¤ï¼Œä¸å†é€²è¡Œèª¿æ•´
    for year in years:
        if year in clustering_results:
            # è¶¨å‹¢èšé¡
            if (
                "trend" in clustering_results[year]
                and vege_id in clustering_results[year]["trend"]["vege_ids"]
            ):
                idx = clustering_results[year]["trend"]["vege_ids"].index(vege_id)
                cluster_label = clustering_results[year]["trend"]["cluster_labels"][idx]
                trend_clusters.append(cluster_label + 1)  # è½‰æ›ç‚º1-based
            else:
                trend_clusters.append(np.nan)

            # å­£ç¯€æ€§èšé¡
            if (
                "seasonal" in clustering_results[year]
                and vege_id in clustering_results[year]["seasonal"]["vege_ids"]
            ):
                idx = clustering_results[year]["seasonal"]["vege_ids"].index(vege_id)
                seasonal_clusters.append(
                    clustering_results[year]["seasonal"]["cluster_labels"][idx] + 1
                )
            else:
                seasonal_clusters.append(np.nan)
        else:
            trend_clusters.append(np.nan)
            seasonal_clusters.append(np.nan)

    # å‰µå»ºåœ–è¡¨
    fig = plt.figure(figsize=(16, 12))
    gs = fig.add_gridspec(4, 4, height_ratios=[1.5, 1, 1.5, 1], hspace=0.3, wspace=0.3)

    # ä¸»æ¨™é¡Œ
    fig.suptitle(
        f"{vege_name} ({vege_id}) å¤šå¹´åº¦èšé¡åˆ†æ (å·²å«2024æ¨™ç±¤èª¿æ•´)",
        fontsize=16,
        y=0.96,
    )

    # ç¬¬ä¸€è¡Œï¼šè¶¨å‹¢æ™‚é–“åºåˆ—
    ax1 = fig.add_subplot(gs[0, :])
    colors = ["blue", "green", "orange"]

    for i, year in enumerate(years):
        if year in decomp_results and vege_id in decomp_results[year]:
            trend_data = decomp_results[year][vege_id]["additive_trend"]
            if len(trend_data) > 0:
                x_vals = np.arange(len(trend_data)) + i * 400  # åˆ†é–‹é¡¯ç¤ºæ¯å¹´
                ax1.plot(
                    x_vals,
                    trend_data.values,
                    color=colors[i],
                    linewidth=2,
                    alpha=0.8,
                    label=f"{year}å¹´è¶¨å‹¢",
                )

                # åœ¨è¶¨å‹¢ç·šæ—é‚Šæ¨™æ³¨èšé¡ç·¨è™Ÿ
                if not np.isnan(trend_clusters[i]):
                    ax1.text(
                        x_vals[-1] + 10,
                        trend_data.values[-1],
                        f"è¶¨å‹¢ç¾¤{int(trend_clusters[i])}",
                        color=colors[i],
                        fontweight="bold",
                        fontsize=10,
                        bbox=dict(
                            boxstyle="round,pad=0.3", facecolor="white", alpha=0.7
                        ),
                    )

    ax1.set_title("é•·æœŸè¶¨å‹¢è®ŠåŒ–", fontsize=12)
    ax1.set_xlabel("æ™‚é–“")
    ax1.set_ylabel("è¶¨å‹¢å€¼")
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # ç¬¬äºŒè¡Œï¼šè¶¨å‹¢èšé¡çµæœåœ“é¤…åœ–å’Œåˆ†ä½ˆåœ–
    # è¶¨å‹¢èšé¡åœ“é¤…åœ–
    ax2 = fig.add_subplot(gs[1, :2])
    valid_trend = [x for x in trend_clusters if not np.isnan(x)]
    if valid_trend:
        trend_counts = {}
        for cluster in valid_trend:
            trend_counts[f"è¶¨å‹¢ç¾¤{int(cluster)}"] = (
                trend_counts.get(f"è¶¨å‹¢ç¾¤{int(cluster)}", 0) + 1
            )

        colors_pie = ["#ff9999", "#66b3ff", "#99ff99"][: len(trend_counts)]
        wedges, texts, autotexts = ax2.pie(
            trend_counts.values(),
            labels=trend_counts.keys(),
            autopct="%1.0få¹´",
            colors=colors_pie,
            startangle=90,
        )
        ax2.set_title("è¶¨å‹¢èšé¡åˆ†ä½ˆ", fontsize=11)
    else:
        ax2.text(
            0.5, 0.5, "ç„¡è¶¨å‹¢æ•¸æ“š", ha="center", va="center", transform=ax2.transAxes
        )
        ax2.set_title("è¶¨å‹¢èšé¡åˆ†ä½ˆ", fontsize=11)

    # è¶¨å‹¢å¹´åº¦è®ŠåŒ–
    ax3 = fig.add_subplot(gs[1, 2:])
    x_pos = np.arange(len(years))
    trend_colors = []
    for t in trend_clusters:
        if np.isnan(t):
            trend_colors.append("gray")
        else:
            trend_colors.append(["#ff9999", "#66b3ff", "#99ff99"][int(t) - 1])

    bars = ax3.bar(x_pos, [1] * len(years), color=trend_colors, alpha=0.7)
    ax3.set_xlim(-0.5, len(years) - 0.5)
    ax3.set_ylim(0, 1.2)
    ax3.set_xticks(x_pos)
    ax3.set_xticklabels(years)
    ax3.set_title("è¶¨å‹¢èšé¡å¹´åº¦è®ŠåŒ–", fontsize=11)
    ax3.set_ylabel("èšé¡æ­¸å±¬")

    # æ·»åŠ èšé¡ç·¨è™Ÿæ¨™ç±¤
    for i, (bar, cluster) in enumerate(zip(bars, trend_clusters)):
        if not np.isnan(cluster):
            ax3.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() / 2,
                f"ç¾¤{int(cluster)}",
                ha="center",
                va="center",
                fontweight="bold",
            )

    # ç¬¬ä¸‰è¡Œï¼šå­£ç¯€æ€§æ™‚é–“åºåˆ—
    ax4 = fig.add_subplot(gs[2, :])

    for i, year in enumerate(years):
        if year in decomp_results and vege_id in decomp_results[year]:
            seasonal_data = decomp_results[year][vege_id]["additive_seasonal"]
            if len(seasonal_data) > 0:
                x_vals = np.arange(len(seasonal_data)) + i * 400
                ax4.plot(
                    x_vals,
                    seasonal_data.values,
                    color=colors[i],
                    linewidth=2,
                    alpha=0.8,
                    label=f"{year}å¹´å­£ç¯€æ€§",
                )

                # åœ¨å­£ç¯€æ€§ç·šæ—é‚Šæ¨™æ³¨èšé¡ç·¨è™Ÿ
                if not np.isnan(seasonal_clusters[i]):
                    ax4.text(
                        x_vals[-1] + 10,
                        seasonal_data.values[-1],
                        f"å­£ç¯€ç¾¤{int(seasonal_clusters[i])}",
                        color=colors[i],
                        fontweight="bold",
                        fontsize=10,
                        bbox=dict(
                            boxstyle="round,pad=0.3", facecolor="white", alpha=0.7
                        ),
                    )

    ax4.set_title("å­£ç¯€æ€§è®ŠåŒ–æ¨¡å¼", fontsize=12)
    ax4.set_xlabel("æ™‚é–“")
    ax4.set_ylabel("å­£ç¯€æ€§")
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    # ç¬¬å››è¡Œï¼šå­£ç¯€æ€§èšé¡çµæœåœ“é¤…åœ–å’Œåˆ†ä½ˆåœ–
    # å­£ç¯€æ€§èšé¡åœ“é¤…åœ–
    ax5 = fig.add_subplot(gs[3, :2])
    valid_seasonal = [x for x in seasonal_clusters if not np.isnan(x)]
    if valid_seasonal:
        seasonal_counts = {}
        for cluster in valid_seasonal:
            seasonal_counts[f"å­£ç¯€ç¾¤{int(cluster)}"] = (
                seasonal_counts.get(f"å­£ç¯€ç¾¤{int(cluster)}", 0) + 1
            )

        colors_pie_s = ["#ffcc99", "#ff99cc"][: len(seasonal_counts)]
        wedges, texts, autotexts = ax5.pie(
            seasonal_counts.values(),
            labels=seasonal_counts.keys(),
            autopct="%1.0få¹´",
            colors=colors_pie_s,
            startangle=90,
        )
        ax5.set_title("å­£ç¯€æ€§èšé¡åˆ†ä½ˆ", fontsize=11)
    else:
        ax5.text(
            0.5, 0.5, "ç„¡å­£ç¯€æ€§æ•¸æ“š", ha="center", va="center", transform=ax5.transAxes
        )
        ax5.set_title("å­£ç¯€æ€§èšé¡åˆ†ä½ˆ", fontsize=11)

    # å­£ç¯€æ€§å¹´åº¦è®ŠåŒ–
    ax6 = fig.add_subplot(gs[3, 2:])
    seasonal_colors = []
    for s in seasonal_clusters:
        if np.isnan(s):
            seasonal_colors.append("gray")
        else:
            seasonal_colors.append(["#ffcc99", "#ff99cc"][int(s) - 1])

    bars = ax6.bar(x_pos, [1] * len(years), color=seasonal_colors, alpha=0.7)
    ax6.set_xlim(-0.5, len(years) - 0.5)
    ax6.set_ylim(0, 1.2)
    ax6.set_xticks(x_pos)
    ax6.set_xticklabels(years)
    ax6.set_title("å­£ç¯€æ€§èšé¡å¹´åº¦è®ŠåŒ–", fontsize=11)
    ax6.set_ylabel("èšé¡æ­¸å±¬")

    # æ·»åŠ èšé¡ç·¨è™Ÿæ¨™ç±¤
    for i, (bar, cluster) in enumerate(zip(bars, seasonal_clusters)):
        if not np.isnan(cluster):
            ax6.text(
                bar.get_x() + bar.get_width() / 2,
                bar.get_height() / 2,
                f"ç¾¤{int(cluster)}",
                ha="center",
                va="center",
                fontweight="bold",
            )

    # ä¿å­˜åœ–è¡¨
    plot_path = os.path.join(
        individual_plots_dir, f"{vege_name}_{vege_id}_èšé¡åˆ†æ.png"
    )
    plt.savefig(plot_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    return plot_path


def create_clustering_stability_heatmap(
    comprehensive_df, comparison_plots_dir, mapping_dict
):
    """å‰µå»ºèšé¡ç©©å®šæ€§ç†±åŠ›åœ–"""

    # æº–å‚™è¶¨å‹¢ç©©å®šæ€§æ•¸æ“š
    trend_data = []
    seasonal_data = []

    for _, row in comprehensive_df.iterrows():
        vege_name = row["vege_name"]

        # è¶¨å‹¢èšé¡æ•¸æ“š
        trend_row = []
        for year in [2022, 2023, 2024]:
            cluster_val = row[f"trend_cluster_{year}"]
            if pd.isna(cluster_val):
                trend_row.append(0)  # ç„¡æ•¸æ“šç”¨0è¡¨ç¤º
            else:
                trend_row.append(int(cluster_val))
        trend_data.append([vege_name] + trend_row)

        # å­£ç¯€æ€§èšé¡æ•¸æ“š
        seasonal_row = []
        for year in [2022, 2023, 2024]:
            cluster_val = row[f"seasonal_cluster_{year}"]
            if pd.isna(cluster_val):
                seasonal_row.append(0)  # ç„¡æ•¸æ“šç”¨0è¡¨ç¤º
            else:
                seasonal_row.append(int(cluster_val))
        seasonal_data.append([vege_name] + seasonal_row)

    # å‰µå»ºDataFrame
    trend_df = pd.DataFrame(trend_data, columns=["è”¬èœåç¨±", "2022", "2023", "2024"])
    seasonal_df = pd.DataFrame(
        seasonal_data, columns=["è”¬èœåç¨±", "2022", "2023", "2024"]
    )

    # å‰µå»ºåœ–è¡¨
    fig, axes = plt.subplots(1, 2, figsize=(20, 15))
    fig.suptitle("è”¬èœèšé¡ç©©å®šæ€§åˆ†æç†±åŠ›åœ– (2024å¹´è¶¨å‹¢èšé¡å·²èª¿æ•´)", fontsize=16, y=0.98)

    # è¶¨å‹¢èšé¡ç†±åŠ›åœ–
    trend_matrix = trend_df.set_index("è”¬èœåç¨±")[["2022", "2023", "2024"]].values
    im1 = axes[0].imshow(trend_matrix, cmap="viridis", aspect="auto", vmin=0, vmax=3)
    axes[0].set_title(
        "è¶¨å‹¢èšé¡è®ŠåŒ– (0=ç„¡æ•¸æ“š, 1-3=èšé¡ç·¨è™Ÿ)\n2024å¹´ç¾¤èš2â†”ç¾¤èš3å·²èª¿æ›", fontsize=14
    )
    axes[0].set_xlabel("å¹´ä»½")
    axes[0].set_ylabel("è”¬èœ")
    axes[0].set_xticks(range(3))
    axes[0].set_xticklabels(["2022", "2023", "2024"])
    axes[0].set_yticks(range(len(trend_df)))
    axes[0].set_yticklabels(trend_df["è”¬èœåç¨±"], fontsize=8)

    # æ·»åŠ æ•¸å€¼æ¨™è¨»
    for i in range(len(trend_df)):
        for j in range(3):
            text = axes[0].text(
                j,
                i,
                int(trend_matrix[i, j]),
                ha="center",
                va="center",
                color="white",
                fontweight="bold",
            )

    # å­£ç¯€æ€§èšé¡ç†±åŠ›åœ–
    seasonal_matrix = seasonal_df.set_index("è”¬èœåç¨±")[["2022", "2023", "2024"]].values
    im2 = axes[1].imshow(seasonal_matrix, cmap="plasma", aspect="auto", vmin=0, vmax=2)
    axes[1].set_title("å­£ç¯€æ€§èšé¡è®ŠåŒ– (0=ç„¡æ•¸æ“š, 1-2=èšé¡ç·¨è™Ÿ)", fontsize=14)
    axes[1].set_xlabel("å¹´ä»½")
    axes[1].set_ylabel("è”¬èœ")
    axes[1].set_xticks(range(3))
    axes[1].set_xticklabels(["2022", "2023", "2024"])
    axes[1].set_yticks(range(len(seasonal_df)))
    axes[1].set_yticklabels(seasonal_df["è”¬èœåç¨±"], fontsize=8)

    # æ·»åŠ æ•¸å€¼æ¨™è¨»
    for i in range(len(seasonal_df)):
        for j in range(3):
            text = axes[1].text(
                j,
                i,
                int(seasonal_matrix[i, j]),
                ha="center",
                va="center",
                color="white",
                fontweight="bold",
            )

    # æ·»åŠ é¡è‰²æ¢
    plt.colorbar(im1, ax=axes[0], shrink=0.8, label="è¶¨å‹¢èšé¡ç·¨è™Ÿ")
    plt.colorbar(im2, ax=axes[1], shrink=0.8, label="å­£ç¯€æ€§èšé¡ç·¨è™Ÿ")

    plt.tight_layout(rect=[0, 0, 1, 0.96])

    heatmap_path = os.path.join(comparison_plots_dir, "èšé¡ç©©å®šæ€§ç†±åŠ›åœ–.png")
    plt.savefig(heatmap_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ èšé¡ç©©å®šæ€§ç†±åŠ›åœ–å·²ä¿å­˜: èšé¡ç©©å®šæ€§ç†±åŠ›åœ–.png")
    return heatmap_path


def create_clustering_migration_flow_chart(comprehensive_df, comparison_plots_dir):
    """å‰µå»ºèšé¡é·ç§»æµç¨‹åœ–"""

    fig, axes = plt.subplots(2, 1, figsize=(16, 12))
    fig.suptitle("è”¬èœèšé¡é·ç§»æ¨¡å¼åˆ†æ (2024å¹´è¶¨å‹¢èšé¡å·²èª¿æ•´)", fontsize=16)

    years = [2022, 2023, 2024]

    # è¶¨å‹¢èšé¡é·ç§»
    trend_transitions = {}
    for i in range(len(years) - 1):
        year1, year2 = years[i], years[i + 1]
        transitions = {}

        for _, row in comprehensive_df.iterrows():
            c1 = row[f"trend_cluster_{year1}"]
            c2 = row[f"trend_cluster_{year2}"]

            if not pd.isna(c1) and not pd.isna(c2):
                key = f"{int(c1)}â†’{int(c2)}"
                transitions[key] = transitions.get(key, 0) + 1

        trend_transitions[f"{year1}-{year2}"] = transitions

    # ç¹ªè£½è¶¨å‹¢é·ç§»
    ax1 = axes[0]
    x_pos = 0
    colors = [
        "red",
        "blue",
        "green",
        "orange",
        "purple",
        "brown",
        "pink",
        "gray",
        "cyan",
    ]

    for period, transitions in trend_transitions.items():
        y_pos = 0
        for transition, count in sorted(transitions.items()):
            ax1.barh(
                y_pos,
                count,
                left=x_pos,
                height=0.8,
                color=colors[y_pos % len(colors)],
                alpha=0.7,
                label=f"{transition} ({period})" if x_pos == 0 else "",
            )
            ax1.text(
                x_pos + count / 2,
                y_pos,
                f"{transition}\n({count})",
                ha="center",
                va="center",
                fontsize=9,
                fontweight="bold",
            )
            y_pos += 1
        x_pos += max(transitions.values()) + 1

    ax1.set_title(
        "è¶¨å‹¢èšé¡é·ç§»æ¨¡å¼ (æ ¼å¼: èµ·å§‹ç¾¤â†’ç›®æ¨™ç¾¤)\n2024å¹´æ•¸æ“šå·²å«ç¾¤èš2â†”ç¾¤èš3èª¿æ›",
        fontsize=12,
    )
    ax1.set_xlabel("é·ç§»æ•¸é‡")
    ax1.set_ylabel("é·ç§»é¡å‹")
    ax1.grid(True, alpha=0.3)
    if x_pos > 0:
        ax1.legend(bbox_to_anchor=(1.05, 1), loc="upper left")

    # å­£ç¯€æ€§èšé¡é·ç§»
    seasonal_transitions = {}
    for i in range(len(years) - 1):
        year1, year2 = years[i], years[i + 1]
        transitions = {}

        for _, row in comprehensive_df.iterrows():
            c1 = row[f"seasonal_cluster_{year1}"]
            c2 = row[f"seasonal_cluster_{year2}"]

            if not pd.isna(c1) and not pd.isna(c2):
                key = f"{int(c1)}â†’{int(c2)}"
                transitions[key] = transitions.get(key, 0) + 1

        seasonal_transitions[f"{year1}-{year2}"] = transitions

    # ç¹ªè£½å­£ç¯€æ€§é·ç§»
    ax2 = axes[1]
    x_pos = 0

    for period, transitions in seasonal_transitions.items():
        y_pos = 0
        for transition, count in sorted(transitions.items()):
            ax2.barh(
                y_pos,
                count,
                left=x_pos,
                height=0.8,
                color=colors[y_pos % len(colors)],
                alpha=0.7,
                label=f"{transition} ({period})" if x_pos == 0 else "",
            )
            ax2.text(
                x_pos + count / 2,
                y_pos,
                f"{transition}\n({count})",
                ha="center",
                va="center",
                fontsize=9,
                fontweight="bold",
            )
            y_pos += 1
        x_pos += max(transitions.values()) + 1 if transitions else 1

    ax2.set_title("å­£ç¯€æ€§èšé¡é·ç§»æ¨¡å¼ (æ ¼å¼: èµ·å§‹ç¾¤â†’ç›®æ¨™ç¾¤)", fontsize=12)
    ax2.set_xlabel("é·ç§»æ•¸é‡")
    ax2.set_ylabel("é·ç§»é¡å‹")
    ax2.grid(True, alpha=0.3)
    if x_pos > 0:
        ax2.legend(bbox_to_anchor=(1.05, 1), loc="upper left")

    plt.tight_layout()

    migration_path = os.path.join(comparison_plots_dir, "èšé¡é·ç§»æµç¨‹åœ–.png")
    plt.savefig(migration_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ èšé¡é·ç§»æµç¨‹åœ–å·²ä¿å­˜: èšé¡é·ç§»æµç¨‹åœ–.png")
    return migration_path


def create_distance_matrix(time_series_dict):
    """å‰µå»ºDTWè·é›¢çŸ©é™£"""
    vege_ids = list(time_series_dict.keys())
    n = len(vege_ids)
    distance_matrix = np.zeros((n, n))

    for i in range(n):
        for j in range(i + 1, n):
            ts1 = time_series_dict[vege_ids[i]]
            ts2 = time_series_dict[vege_ids[j]]

            dist = dtw_distance(ts1, ts2)
            distance_matrix[i, j] = dist
            distance_matrix[j, i] = dist

    return distance_matrix, vege_ids


def perform_clustering_with_evaluation(
    distance_matrix, vege_ids, n_clusters, k_range=(2, 8), year=None
):
    """åŸ·è¡Œèšé¡ä¸¦è©•ä¼°ä¸åŒKå€¼ï¼Œä¸¦æ‡‰ç”¨2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤èª¿æ•´"""
    max_dist = np.max(distance_matrix)
    if max_dist > 0:
        similarity_matrix = np.exp(-distance_matrix / (max_dist * 0.1))
    else:
        similarity_matrix = np.ones_like(distance_matrix)

    # è©•ä¼°ä¸åŒKå€¼
    silhouette_scores = []
    inertias = []
    max_k = min(k_range[1], len(vege_ids) - 1)
    k_values = range(k_range[0], max_k + 1)

    for k in k_values:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = kmeans.fit_predict(similarity_matrix)

        if len(set(labels)) > 1:
            sil_score = silhouette_score(similarity_matrix, labels)
            silhouette_scores.append(sil_score)
        else:
            silhouette_scores.append(-1)

        inertias.append(kmeans.inertia_)

    # ä½¿ç”¨æŒ‡å®šçš„èšé¡æ•¸
    final_kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = final_kmeans.fit_predict(similarity_matrix)

    # æ‡‰ç”¨2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤èª¿æ•´
    if year:
        cluster_labels = adjust_2024_trend_cluster_labels(cluster_labels, year)

    if len(set(cluster_labels)) > 1:
        final_silhouette = silhouette_score(similarity_matrix, cluster_labels)
    else:
        final_silhouette = -1

    return {
        "cluster_labels": cluster_labels,
        "silhouette_score": final_silhouette,
        "vege_ids": vege_ids,
        "n_clusters": n_clusters,
        "k_values": list(k_values),
        "silhouette_scores": silhouette_scores,
        "inertias": inertias,
        "similarity_matrix": similarity_matrix,
    }


def create_comprehensive_clustering_plots(
    results, time_series_dict, component_name, year, plots_dir, mapping_dict
):
    """å‰µå»ºå®Œæ•´çš„èšé¡åˆ†æåœ–è¡¨"""

    # 1. èšé¡è©•ä¼°åœ–
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    component_cn = "å­£ç¯€æ€§" if "seasonal" in component_name else "è¶¨å‹¢"
    title_suffix = (
        " (2024å¹´å·²èª¿æ•´)" if year == 2024 and "trend" in component_name.lower() else ""
    )
    fig.suptitle(f"{year}å¹´{component_cn} K-means èšé¡åˆ†æ{title_suffix}", fontsize=16)

    # è¼ªå»“ä¿‚æ•¸
    axes[0, 0].plot(results["k_values"], results["silhouette_scores"], "bo-")
    axes[0, 0].axvline(x=results["n_clusters"], color="red", linestyle="--", alpha=0.7)
    axes[0, 0].set_title("è¼ªå»“ä¿‚æ•¸ vs èšé¡æ•¸")
    axes[0, 0].set_xlabel("èšé¡æ•¸ (k)")
    axes[0, 0].set_ylabel("è¼ªå»“ä¿‚æ•¸")
    axes[0, 0].grid(True, alpha=0.3)

    # Elbow method
    axes[0, 1].plot(results["k_values"], results["inertias"], "ro-")
    axes[0, 1].axvline(x=results["n_clusters"], color="red", linestyle="--", alpha=0.7)
    axes[0, 1].set_title("æ‰‹è‚˜æ³•")
    axes[0, 1].set_xlabel("èšé¡æ•¸ (k)")
    axes[0, 1].set_ylabel("æ…£æ€§")
    axes[0, 1].grid(True, alpha=0.3)

    # ç‰¹å¾µç©ºé–“è¦–è¦ºåŒ–
    labels = results["cluster_labels"]
    n_clusters = results["n_clusters"]
    colors = plt.cm.Set1(np.linspace(0, 1, n_clusters))

    # è¨ˆç®—æ¯å€‹æ™‚é–“åºåˆ—çš„çµ±è¨ˆç‰¹å¾µ
    features = []
    for vege_id in results["vege_ids"]:
        ts = time_series_dict[vege_id]
        mean_val = np.mean(ts)
        std_val = np.std(ts)
        features.append([mean_val, std_val])

    feature_matrix = np.array(features)

    for i in range(n_clusters):
        mask = labels == i
        if np.sum(mask) > 0:
            axes[1, 0].scatter(
                feature_matrix[mask, 0],
                feature_matrix[mask, 1],
                c=[colors[i]],
                label=f"èšé¡ {i+1}",
                alpha=0.7,
                s=50,
            )

    axes[1, 0].set_title("ç‰¹å¾µç©ºé–“è¦–è¦ºåŒ– (å‡å€¼ vs æ¨™æº–å·®)")
    axes[1, 0].set_xlabel("å‡å€¼")
    axes[1, 0].set_ylabel("æ¨™æº–å·®")
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # èšé¡å¤§å°åˆ†å¸ƒ
    cluster_counts = np.bincount(labels)
    axes[1, 1].bar(range(n_clusters), cluster_counts, color=colors)
    axes[1, 1].set_title("èšé¡è¦æ¨¡åˆ†å¸ƒ")
    axes[1, 1].set_xlabel("èšé¡")
    axes[1, 1].set_ylabel("è”¬èœæ•¸é‡")
    axes[1, 1].grid(True, alpha=0.3)

    # æ·»åŠ æ•¸é‡æ¨™ç±¤
    for i, count in enumerate(cluster_counts):
        axes[1, 1].text(i, count + 0.5, str(count), ha="center", va="bottom")

    plt.tight_layout()
    eval_path = os.path.join(plots_dir, f"{year}_{component_name}_èšé¡è©•ä¼°.png")
    plt.savefig(eval_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ èšé¡è©•ä¼°åœ–å·²ä¿å­˜: {year}_{component_name}_èšé¡è©•ä¼°.png")


def create_time_series_clustering_plot(
    results, time_series_dict, component_name, year, plots_dir, mapping_dict
):
    """å‰µå»ºæ™‚é–“åºåˆ—èšé¡åœ–"""
    labels = results["cluster_labels"]
    n_clusters = results["n_clusters"]
    vege_ids = results["vege_ids"]

    fig, axes = plt.subplots(n_clusters, 1, figsize=(15, 4 * n_clusters))
    if n_clusters == 1:
        axes = [axes]

    component_cn = "å­£ç¯€æ€§" if "seasonal" in component_name else "è¶¨å‹¢"
    title_suffix = (
        " (2024å¹´å·²èª¿æ•´)" if year == 2024 and "trend" in component_name.lower() else ""
    )
    fig.suptitle(f"{year}å¹´{component_cn}èšé¡æ™‚é–“åºåˆ—{title_suffix}", fontsize=16)

    colors = plt.cm.Set3(np.linspace(0, 1, max(20, len(vege_ids))))

    for cluster_id in range(n_clusters):
        cluster_vege_ids = [
            vege_ids[i] for i in range(len(vege_ids)) if labels[i] == cluster_id
        ]
        cluster_vege_names = [
            get_chinese_name(vid, mapping_dict) for vid in cluster_vege_ids
        ]

        # ç¹ªè£½è©²èšé¡ä¸­æ‰€æœ‰è”¬èœçš„æ™‚é–“åºåˆ—
        for j, vege_id in enumerate(cluster_vege_ids):
            if vege_id in time_series_dict:
                ts_data = time_series_dict[vege_id]
                axes[cluster_id].plot(
                    ts_data, alpha=0.6, linewidth=1, color=colors[j % len(colors)]
                )

        # è¨ˆç®—ä¸¦ç¹ªè£½èšé¡ä¸­å¿ƒ
        cluster_indices = [i for i in range(len(vege_ids)) if labels[i] == cluster_id]
        if cluster_indices:
            cluster_series = [time_series_dict[vege_ids[i]] for i in cluster_indices]

            # æ‰¾åˆ°æœ€å¤§é•·åº¦
            max_len = max(len(ts) for ts in cluster_series)

            # çµ±ä¸€é•·åº¦ä¸¦è¨ˆç®—å¹³å‡
            normalized_series = []
            for ts in cluster_series:
                if len(ts) < max_len:
                    # ä½¿ç”¨æ’å€¼çµ±ä¸€é•·åº¦
                    if len(ts) > 1:
                        original_indices = np.linspace(0, len(ts) - 1, len(ts))
                        target_indices = np.linspace(0, len(ts) - 1, max_len)
                        ts_normalized = np.interp(target_indices, original_indices, ts)
                    else:
                        ts_normalized = np.full(max_len, ts[0] if len(ts) > 0 else 0)
                else:
                    ts_normalized = ts[:max_len]
                normalized_series.append(ts_normalized)

            if normalized_series:
                cluster_mean = np.mean(normalized_series, axis=0)
                axes[cluster_id].plot(
                    cluster_mean, color="red", linewidth=3, alpha=0.8, label="èšé¡ä¸­å¿ƒ"
                )

        axes[cluster_id].set_title(
            f"èšé¡ {cluster_id+1} ({len(cluster_vege_ids)} ç¨®è”¬èœ)"
        )
        axes[cluster_id].set_xlabel("æ™‚é–“")
        axes[cluster_id].set_ylabel(component_cn)
        axes[cluster_id].grid(True, alpha=0.3)
        axes[cluster_id].legend()

        # æ·»åŠ è”¬èœåç¨±æ¨™è¨»ï¼ˆåªåœ¨æ•¸é‡ä¸å¤šæ™‚é¡¯ç¤ºï¼‰
        if len(cluster_vege_names) <= 8:
            vege_text = ", ".join(cluster_vege_names)
            axes[cluster_id].text(
                0.02,
                0.98,
                f"è”¬èœ: {vege_text}",
                transform=axes[cluster_id].transAxes,
                fontsize=8,
                verticalalignment="top",
                bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.7),
            )
        else:
            vege_text = (
                ", ".join(cluster_vege_names[:6]) + f" ç­‰{len(cluster_vege_names)}ç¨®"
            )
            axes[cluster_id].text(
                0.02,
                0.98,
                f"è”¬èœ: {vege_text}",
                transform=axes[cluster_id].transAxes,
                fontsize=8,
                verticalalignment="top",
                bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.7),
            )

    plt.tight_layout()
    ts_path = os.path.join(plots_dir, f"{year}_{component_name}_æ™‚é–“åºåˆ—èšé¡.png")
    plt.savefig(ts_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ æ™‚é–“åºåˆ—èšé¡åœ–å·²ä¿å­˜: {year}_{component_name}_æ™‚é–“åºåˆ—èšé¡.png")


def create_cluster_centers_plot(
    results, time_series_dict, component_name, year, plots_dir, mapping_dict
):
    """å‰µå»ºèšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–"""
    labels = results["cluster_labels"]
    n_clusters = results["n_clusters"]
    vege_ids = results["vege_ids"]

    fig, ax = plt.subplots(1, 1, figsize=(12, 8))

    component_cn = "å­£ç¯€æ€§" if "seasonal" in component_name else "è¶¨å‹¢"
    title_suffix = (
        " (2024å¹´å·²èª¿æ•´)" if year == 2024 and "trend" in component_name.lower() else ""
    )
    ax.set_title(f"{year}å¹´{component_cn}èšé¡ä¸­å¿ƒæ¯”è¼ƒ{title_suffix}", fontsize=14)

    colors = plt.cm.Set3(np.linspace(0, 1, n_clusters))

    for cluster_id in range(n_clusters):
        cluster_indices = [i for i in range(len(vege_ids)) if labels[i] == cluster_id]
        if cluster_indices:
            cluster_series = [time_series_dict[vege_ids[i]] for i in cluster_indices]

            # æ‰¾åˆ°æœ€å¤§é•·åº¦
            max_len = max(len(ts) for ts in cluster_series)

            # çµ±ä¸€é•·åº¦ä¸¦è¨ˆç®—å¹³å‡
            normalized_series = []
            for ts in cluster_series:
                if len(ts) < max_len:
                    if len(ts) > 1:
                        original_indices = np.linspace(0, len(ts) - 1, len(ts))
                        target_indices = np.linspace(0, len(ts) - 1, max_len)
                        ts_normalized = np.interp(target_indices, original_indices, ts)
                    else:
                        ts_normalized = np.full(max_len, ts[0] if len(ts) > 0 else 0)
                else:
                    ts_normalized = ts[:max_len]
                normalized_series.append(ts_normalized)

            if normalized_series:
                cluster_mean = np.mean(normalized_series, axis=0)
                ax.plot(
                    cluster_mean,
                    color=colors[cluster_id],
                    linewidth=3,
                    label=f"èšé¡ {cluster_id+1} ä¸­å¿ƒ ({len(cluster_indices)} ç¨®è”¬èœ)",
                    marker="o",
                    markersize=2,
                )

    ax.set_xlabel("æ™‚é–“")
    ax.set_ylabel(component_cn)
    ax.legend()
    ax.grid(True, alpha=0.3)

    centers_path = os.path.join(plots_dir, f"{year}_{component_name}_èšé¡ä¸­å¿ƒ.png")
    plt.savefig(centers_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–å·²ä¿å­˜: {year}_{component_name}_èšé¡ä¸­å¿ƒ.png")


def create_three_year_cluster_centers_comparison(yearly_results, comparison_plots_dir):
    """å‰µå»ºä¸‰å¹´åº¦èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–"""
    years = [2022, 2023, 2024]

    # å‰µå»ºå­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    fig.suptitle("ä¸‰å¹´åº¦å­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒ", fontsize=16, y=1.02)

    for i, year in enumerate(years):
        if year in yearly_results and "seasonal" in yearly_results[year]["clustering"]:
            seasonal_result = yearly_results[year]["clustering"]["seasonal"]

            # é‡æ§‹å­£ç¯€æ€§æ™‚é–“åºåˆ—æ•¸æ“š
            seasonal_series = {}
            for vege_id, decomp_result in yearly_results[year]["decomposition"].items():
                if len(decomp_result["additive_seasonal"]) > 0:
                    seasonal_series[vege_id] = decomp_result["additive_seasonal"].values

            # è¨ˆç®—èšé¡ä¸­å¿ƒ
            labels = seasonal_result["cluster_labels"]
            vege_ids = seasonal_result["vege_ids"]
            n_clusters = seasonal_result["n_clusters"]

            colors = ["#66b3ff", "#ffcc99"]  # æ·ºè—è‰²å’Œæ·ºæ©™è‰²

            for cluster_id in range(n_clusters):
                cluster_indices = [
                    idx for idx in range(len(vege_ids)) if labels[idx] == cluster_id
                ]
                if cluster_indices:
                    cluster_series = [
                        seasonal_series[vege_ids[idx]]
                        for idx in cluster_indices
                        if vege_ids[idx] in seasonal_series
                    ]

                    if cluster_series:
                        # çµ±ä¸€é•·åº¦ä¸¦è¨ˆç®—å¹³å‡
                        max_len = max(len(ts) for ts in cluster_series)
                        normalized_series = []

                        for ts in cluster_series:
                            if len(ts) < max_len:
                                if len(ts) > 1:
                                    original_indices = np.linspace(
                                        0, len(ts) - 1, len(ts)
                                    )
                                    target_indices = np.linspace(
                                        0, len(ts) - 1, max_len
                                    )
                                    ts_normalized = np.interp(
                                        target_indices, original_indices, ts
                                    )
                                else:
                                    ts_normalized = np.full(
                                        max_len, ts[0] if len(ts) > 0 else 0
                                    )
                            else:
                                ts_normalized = ts[:max_len]
                            normalized_series.append(ts_normalized)

                        if normalized_series:
                            cluster_mean = np.mean(normalized_series, axis=0)
                            axes[i].plot(
                                cluster_mean,
                                color=colors[cluster_id],
                                linewidth=3,
                                label=f"èšé¡ {cluster_id+1} ä¸­å¿ƒ ({len(cluster_indices)} ç¨®è”¬èœ)",
                                alpha=0.8,
                            )

            axes[i].set_title(f"{year}å¹´å­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒ", fontsize=12)
            axes[i].set_xlabel("æ™‚é–“")
            axes[i].set_ylabel("å­£ç¯€æ€§")
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)
        else:
            axes[i].text(
                0.5,
                0.5,
                f"{year}å¹´\nç„¡å­£ç¯€æ€§èšé¡æ•¸æ“š",
                ha="center",
                va="center",
                transform=axes[i].transAxes,
                fontsize=14,
            )
            axes[i].set_title(f"{year}å¹´å­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒ", fontsize=12)

    plt.tight_layout()
    seasonal_comparison_path = os.path.join(
        comparison_plots_dir, "ä¸‰å¹´åº¦å­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒ.png"
    )
    plt.savefig(
        seasonal_comparison_path, dpi=300, bbox_inches="tight", facecolor="white"
    )
    plt.close()

    # å‰µå»ºè¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    title_suffix = " (2024å¹´å·²èª¿æ•´)"
    fig.suptitle(f"ä¸‰å¹´åº¦è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒ{title_suffix}", fontsize=16, y=1.02)

    for i, year in enumerate(years):
        if year in yearly_results and "trend" in yearly_results[year]["clustering"]:
            trend_result = yearly_results[year]["clustering"]["trend"]

            # é‡æ§‹è¶¨å‹¢æ™‚é–“åºåˆ—æ•¸æ“š
            trend_series = {}
            for vege_id, decomp_result in yearly_results[year]["decomposition"].items():
                if len(decomp_result["additive_trend"]) > 0:
                    trend_series[vege_id] = decomp_result["additive_trend"].values

            # è¨ˆç®—èšé¡ä¸­å¿ƒ
            labels = trend_result["cluster_labels"]
            vege_ids = trend_result["vege_ids"]
            n_clusters = trend_result["n_clusters"]

            colors = ["#ff9999", "#66b3ff", "#99ff99"]  # æ·ºç´…ã€æ·ºè—ã€æ·ºç¶ 

            for cluster_id in range(n_clusters):
                cluster_indices = [
                    idx for idx in range(len(vege_ids)) if labels[idx] == cluster_id
                ]
                if cluster_indices:
                    cluster_series = [
                        trend_series[vege_ids[idx]]
                        for idx in cluster_indices
                        if vege_ids[idx] in trend_series
                    ]

                    if cluster_series:
                        # çµ±ä¸€é•·åº¦ä¸¦è¨ˆç®—å¹³å‡
                        max_len = max(len(ts) for ts in cluster_series)
                        normalized_series = []

                        for ts in cluster_series:
                            if len(ts) < max_len:
                                if len(ts) > 1:
                                    original_indices = np.linspace(
                                        0, len(ts) - 1, len(ts)
                                    )
                                    target_indices = np.linspace(
                                        0, len(ts) - 1, max_len
                                    )
                                    ts_normalized = np.interp(
                                        target_indices, original_indices, ts
                                    )
                                else:
                                    ts_normalized = np.full(
                                        max_len, ts[0] if len(ts) > 0 else 0
                                    )
                            else:
                                ts_normalized = ts[:max_len]
                            normalized_series.append(ts_normalized)

                        if normalized_series:
                            cluster_mean = np.mean(normalized_series, axis=0)
                            axes[i].plot(
                                cluster_mean,
                                color=colors[cluster_id],
                                linewidth=3,
                                label=f"èšé¡ {cluster_id+1} ä¸­å¿ƒ ({len(cluster_indices)} ç¨®è”¬èœ)",
                                alpha=0.8,
                            )

            title_year_suffix = " (å·²èª¿æ•´)" if year == 2024 else ""
            axes[i].set_title(
                f"{year}å¹´è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒ{title_year_suffix}", fontsize=12
            )
            axes[i].set_xlabel("æ™‚é–“")
            axes[i].set_ylabel("è¶¨å‹¢")
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)
        else:
            axes[i].text(
                0.5,
                0.5,
                f"{year}å¹´\nç„¡è¶¨å‹¢èšé¡æ•¸æ“š",
                ha="center",
                va="center",
                transform=axes[i].transAxes,
                fontsize=14,
            )
            axes[i].set_title(f"{year}å¹´è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒ", fontsize=12)

    plt.tight_layout()
    trend_comparison_path = os.path.join(
        comparison_plots_dir, "ä¸‰å¹´åº¦è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒ.png"
    )
    plt.savefig(trend_comparison_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ ä¸‰å¹´åº¦å­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–å·²ä¿å­˜: ä¸‰å¹´åº¦å­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒ.png")
    print(f"   ğŸ“ˆ ä¸‰å¹´åº¦è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–å·²ä¿å­˜: ä¸‰å¹´åº¦è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒ.png")

    return seasonal_comparison_path, trend_comparison_path


def create_multi_year_comparison_plots(yearly_results, comparison_plots_dir):
    """å‰µå»ºå¤šå¹´åº¦æ¯”è¼ƒåœ–è¡¨"""
    years = sorted(yearly_results.keys())

    # 1. èšé¡å“è³ªå¹´åº¦æ¯”è¼ƒ
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle("å¤šå¹´åº¦DTWèšé¡å“è³ªæ¯”è¼ƒ (2024å¹´è¶¨å‹¢èšé¡å·²èª¿æ•´)", fontsize=16)

    # æ”¶é›†æ•¸æ“š
    trend_silhouettes = []
    seasonal_silhouettes = []
    trend_sizes = []
    seasonal_sizes = []

    for year in years:
        if year in yearly_results:
            clustering = yearly_results[year]["clustering"]

            if "trend" in clustering:
                trend_silhouettes.append(clustering["trend"]["silhouette_score"])
                trend_sizes.append(len(clustering["trend"]["vege_ids"]))
            else:
                trend_silhouettes.append(0)
                trend_sizes.append(0)

            if "seasonal" in clustering:
                seasonal_silhouettes.append(clustering["seasonal"]["silhouette_score"])
                seasonal_sizes.append(len(clustering["seasonal"]["vege_ids"]))
            else:
                seasonal_silhouettes.append(0)
                seasonal_sizes.append(0)

    # è¼ªå»“ä¿‚æ•¸æ¯”è¼ƒ
    x = np.arange(len(years))
    width = 0.35

    axes[0, 0].bar(
        x - width / 2, trend_silhouettes, width, label="è¶¨å‹¢èšé¡", color="skyblue"
    )
    axes[0, 0].bar(
        x + width / 2,
        seasonal_silhouettes,
        width,
        label="å­£ç¯€æ€§èšé¡",
        color="lightcoral",
    )
    axes[0, 0].set_title("å¹´åº¦è¼ªå»“ä¿‚æ•¸æ¯”è¼ƒ")
    axes[0, 0].set_xlabel("å¹´ä»½")
    axes[0, 0].set_ylabel("è¼ªå»“ä¿‚æ•¸")
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(years)
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # æ¨£æœ¬æ•¸é‡æ¯”è¼ƒ
    axes[0, 1].plot(
        years,
        trend_sizes,
        marker="o",
        linewidth=2,
        label="è¶¨å‹¢åˆ†æè”¬èœæ•¸",
        color="blue",
    )
    axes[0, 1].plot(
        years,
        seasonal_sizes,
        marker="s",
        linewidth=2,
        label="å­£ç¯€æ€§åˆ†æè”¬èœæ•¸",
        color="red",
    )
    axes[0, 1].set_title("å¹´åº¦åˆ†æè”¬èœæ•¸é‡")
    axes[0, 1].set_xlabel("å¹´ä»½")
    axes[0, 1].set_ylabel("è”¬èœæ•¸é‡")
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # èšé¡åˆ†å¸ƒæ¯”è¼ƒ - è¶¨å‹¢
    bar_width = 0.8 / len(years)
    for i, year in enumerate(years):
        if year in yearly_results and "trend" in yearly_results[year]["clustering"]:
            trend_result = yearly_results[year]["clustering"]["trend"]
            trend_counts = np.bincount(
                trend_result["cluster_labels"], minlength=TREND_CLUSTERS
            )
            x_pos = np.arange(TREND_CLUSTERS) + i * bar_width
            axes[1, 0].bar(x_pos, trend_counts, bar_width, label=f"{year}å¹´", alpha=0.8)

    axes[1, 0].set_title("è¶¨å‹¢èšé¡è¦æ¨¡å¹´åº¦æ¯”è¼ƒ\n(2024å¹´ç¾¤èš2â†”ç¾¤èš3å·²èª¿æ›)")
    axes[1, 0].set_xlabel("èšé¡ç·¨è™Ÿ")
    axes[1, 0].set_ylabel("è”¬èœæ•¸é‡")
    axes[1, 0].set_xticks(np.arange(TREND_CLUSTERS) + bar_width * (len(years) - 1) / 2)
    axes[1, 0].set_xticklabels([f"è¶¨å‹¢ç¾¤{i+1}" for i in range(TREND_CLUSTERS)])
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # èšé¡åˆ†å¸ƒæ¯”è¼ƒ - å­£ç¯€æ€§
    for i, year in enumerate(years):
        if year in yearly_results and "seasonal" in yearly_results[year]["clustering"]:
            seasonal_result = yearly_results[year]["clustering"]["seasonal"]
            seasonal_counts = np.bincount(
                seasonal_result["cluster_labels"], minlength=SEASONAL_CLUSTERS
            )
            x_pos = np.arange(SEASONAL_CLUSTERS) + i * bar_width
            axes[1, 1].bar(
                x_pos, seasonal_counts, bar_width, label=f"{year}å¹´", alpha=0.8
            )

    axes[1, 1].set_title("å­£ç¯€æ€§èšé¡è¦æ¨¡å¹´åº¦æ¯”è¼ƒ")
    axes[1, 1].set_xlabel("èšé¡ç·¨è™Ÿ")
    axes[1, 1].set_ylabel("è”¬èœæ•¸é‡")
    axes[1, 1].set_xticks(
        np.arange(SEASONAL_CLUSTERS) + bar_width * (len(years) - 1) / 2
    )
    axes[1, 1].set_xticklabels([f"å­£ç¯€ç¾¤{i+1}" for i in range(SEASONAL_CLUSTERS)])
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    plt.tight_layout()
    comparison_path = os.path.join(comparison_plots_dir, "å¤šå¹´åº¦èšé¡æ¯”è¼ƒ.png")
    plt.savefig(comparison_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"   ğŸ“ˆ å¤šå¹´åº¦æ¯”è¼ƒåœ–å·²ä¿å­˜: å¤šå¹´åº¦èšé¡æ¯”è¼ƒ.png")


def create_comprehensive_analysis(yearly_results, analysis_dir, mapping_dict):
    """å‰µå»ºç¶œåˆåˆ†æ"""
    # æ”¶é›†æ‰€æœ‰è”¬èœ
    all_veges = set()
    for results in yearly_results.values():
        all_veges.update(results["decomposition"].keys())
    all_veges = sorted(list(all_veges))

    # å‰µå»ºç¶œåˆè¡¨æ ¼
    comprehensive_data = []
    for vege_id in all_veges:
        vege_name = get_chinese_name(vege_id, mapping_dict)
        row_data = {"market_vege_id": vege_id, "vege_name": vege_name}

        for year in [2022, 2023, 2024]:
            if year in yearly_results:
                clustering = yearly_results[year]["clustering"]

                # è¶¨å‹¢èšé¡ - ç·¨è™Ÿå¾1é–‹å§‹ï¼Œ2024å¹´æ¨™ç±¤å·²åœ¨perform_clustering_with_evaluationä¸­èª¿æ•´
                if "trend" in clustering:
                    trend_result = clustering["trend"]
                    if vege_id in trend_result["vege_ids"]:
                        vege_idx = trend_result["vege_ids"].index(vege_id)
                        cluster_label = trend_result["cluster_labels"][vege_idx]
                        # æ³¨æ„ï¼šé€™è£¡ä¸å†é€²è¡Œé¡å¤–èª¿æ•´ï¼Œå› ç‚ºclustering resultå·²ç¶“åŒ…å«èª¿æ•´å¾Œçš„æ¨™ç±¤
                        row_data[f"trend_cluster_{year}"] = cluster_label + 1
                    else:
                        row_data[f"trend_cluster_{year}"] = np.nan
                else:
                    row_data[f"trend_cluster_{year}"] = np.nan

                # å­£ç¯€æ€§èšé¡ - ç·¨è™Ÿå¾1é–‹å§‹
                if "seasonal" in clustering:
                    seasonal_result = clustering["seasonal"]
                    if vege_id in seasonal_result["vege_ids"]:
                        vege_idx = seasonal_result["vege_ids"].index(vege_id)
                        row_data[f"seasonal_cluster_{year}"] = (
                            seasonal_result["cluster_labels"][vege_idx] + 1
                        )
                    else:
                        row_data[f"seasonal_cluster_{year}"] = np.nan
                else:
                    row_data[f"seasonal_cluster_{year}"] = np.nan
            else:
                row_data[f"trend_cluster_{year}"] = np.nan
                row_data[f"seasonal_cluster_{year}"] = np.nan

        # è¨ˆç®—ç©©å®šæ€§æŒ‡æ¨™
        trend_clusters = [
            row_data[f"trend_cluster_{year}"]
            for year in [2022, 2023, 2024]
            if not pd.isna(row_data[f"trend_cluster_{year}"])
        ]
        seasonal_clusters = [
            row_data[f"seasonal_cluster_{year}"]
            for year in [2022, 2023, 2024]
            if not pd.isna(row_data[f"seasonal_cluster_{year}"])
        ]

        row_data["trend_stability"] = (
            len(set(trend_clusters)) == 1 if len(trend_clusters) > 1 else np.nan
        )
        row_data["seasonal_stability"] = (
            len(set(seasonal_clusters)) == 1 if len(seasonal_clusters) > 1 else np.nan
        )
        row_data["years_analyzed"] = len(
            [
                year
                for year in [2022, 2023, 2024]
                if not pd.isna(row_data[f"trend_cluster_{year}"])
                or not pd.isna(row_data[f"seasonal_cluster_{year}"])
            ]
        )

        comprehensive_data.append(row_data)

    comprehensive_df = pd.DataFrame(comprehensive_data)
    comprehensive_path = os.path.join(analysis_dir, "ç¶œåˆèšé¡åˆ†æçµæœ.csv")
    comprehensive_df.to_csv(comprehensive_path, index=False, encoding="utf-8-sig")

    print(f"   ğŸ“ ç¶œåˆåˆ†æå·²ä¿å­˜: ç¶œåˆèšé¡åˆ†æçµæœ.csv")
    return comprehensive_df


def create_executive_summary(yearly_results, comprehensive_df, analysis_dir):
    """å‰µå»ºåŸ·è¡Œæ‘˜è¦"""
    years = sorted(yearly_results.keys())

    summary_report = []
    summary_report.append("=" * 80)
    summary_report.append("å®Œæ•´è”¬èœåƒ¹æ ¼å¤šå¹´åº¦DTWèšé¡åˆ†æåŸ·è¡Œæ‘˜è¦")
    summary_report.append("=" * 80)
    summary_report.append(f"åˆ†ææœŸé–“: {min(years)}-{max(years)}")
    summary_report.append(
        f"åˆ†ææ–¹æ³•: æ™‚é–“åºåˆ—åˆ†è§£ + Dynamic Time Warping + K-meansèšé¡"
    )
    summary_report.append(
        f"èšé¡åƒæ•¸: å­£ç¯€æ€§èšé¡={SEASONAL_CLUSTERS}, è¶¨å‹¢èšé¡={TREND_CLUSTERS}"
    )
    summary_report.append(
        f"DTWç‹€æ…‹: {'å·²å•Ÿç”¨' if DTW_AVAILABLE else 'ä½¿ç”¨æ­æ°è·é›¢æ›¿ä»£'}"
    )
    summary_report.append(f"èšé¡ç·¨è™Ÿ: çµ±ä¸€å¾1é–‹å§‹ï¼Œèˆ‡åœ–è¡¨æ¨™ç¤ºä¸€è‡´")
    summary_report.append(f"2024å¹´è¶¨å‹¢èšé¡: ç¾¤èš2å’Œç¾¤èš3æ¨™ç±¤å·²èª¿æ›")
    summary_report.append(f"æ¨™ç±¤èª¿æ•´ç¢ºèª: æ‰€æœ‰åœ–è¡¨å’ŒCSVæª”æ¡ˆéƒ½å·²æ­£ç¢ºåæ˜ èª¿æ›çµæœ")
    summary_report.append(
        f"å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
    )
    summary_report.append("")

    # åŸºæœ¬çµ±è¨ˆ
    summary_report.append("ğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
    total_vegetables = len(comprehensive_df)
    summary_report.append(f"   ç¸½è”¬èœç¨®é¡æ•¸: {total_vegetables}")

    for year in years:
        if year in yearly_results:
            decomp_count = len(yearly_results[year]["decomposition"])
            clustering_count = len(yearly_results[year]["clustering"])
            summary_report.append(
                f"   {year}å¹´: åˆ†è§£{decomp_count}ç¨®è”¬èœ, èšé¡åˆ†æ{clustering_count}ç¨®æˆåˆ†"
            )

    summary_report.append("")

    # èšé¡å“è³ª
    summary_report.append("ğŸ¯ èšé¡å“è³ª:")
    trend_scores = []
    seasonal_scores = []

    for year in years:
        if year in yearly_results:
            clustering = yearly_results[year]["clustering"]
            if "trend" in clustering:
                trend_scores.append(clustering["trend"]["silhouette_score"])
            if "seasonal" in clustering:
                seasonal_scores.append(clustering["seasonal"]["silhouette_score"])

    if trend_scores:
        avg_trend = np.mean(trend_scores)
        summary_report.append(f"   å¹³å‡è¶¨å‹¢èšé¡è¼ªå»“ä¿‚æ•¸: {avg_trend:.3f}")

    if seasonal_scores:
        avg_seasonal = np.mean(seasonal_scores)
        summary_report.append(f"   å¹³å‡å­£ç¯€æ€§èšé¡è¼ªå»“ä¿‚æ•¸: {avg_seasonal:.3f}")

    summary_report.append("")

    # ç©©å®šæ€§åˆ†æ
    summary_report.append("ğŸ”„ ç©©å®šæ€§åˆ†æ:")
    trend_stable = comprehensive_df["trend_stability"].sum()
    seasonal_stable = comprehensive_df["seasonal_stability"].sum()
    analyzed = comprehensive_df["trend_stability"].notna().sum()

    if analyzed > 0:
        trend_stable_pct = (trend_stable / analyzed) * 100
        seasonal_stable_pct = (seasonal_stable / analyzed) * 100
        summary_report.append(f"   è¶¨å‹¢èšé¡ç©©å®šè”¬èœæ¯”ä¾‹: {trend_stable_pct:.1f}%")
        summary_report.append(f"   å­£ç¯€æ€§èšé¡ç©©å®šè”¬èœæ¯”ä¾‹: {seasonal_stable_pct:.1f}%")

    summary_report.append("")

    summary_report.append("ğŸš€ å®Œæ•´åŠŸèƒ½åˆ—è¡¨:")
    summary_report.append("   âœ… æ™‚é–“åºåˆ—åˆ†è§£ç¯„ä¾‹åœ– (ä¸­æ–‡æ¨™ç±¤)")
    summary_report.append("   âœ… èšé¡è©•ä¼°åœ–è¡¨ (è¼ªå»“ä¿‚æ•¸ã€æ‰‹è‚˜æ³•)")
    summary_report.append("   âœ… æ™‚é–“åºåˆ—èšé¡åœ– (ä¸­æ–‡åç¨±)")
    summary_report.append("   âœ… èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–")
    summary_report.append("   âœ… å¤šå¹´åº¦æ¯”è¼ƒåœ–è¡¨")
    summary_report.append("   âœ… èšé¡ç©©å®šæ€§ç†±åŠ›åœ–")
    summary_report.append("   âœ… èšé¡é·ç§»æµç¨‹åœ–")
    summary_report.append("   âœ… ä¸‰å¹´åº¦å­£ç¯€æ€§èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–")
    summary_report.append("   âœ… ä¸‰å¹´åº¦è¶¨å‹¢èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–")
    summary_report.append("   âœ… å€‹åˆ¥è”¬èœå®Œæ•´åˆ†æåœ– (å«èšé¡ç·¨è™Ÿæ¨™è¨»)")
    summary_report.append("   âœ… 2024å¹´è¶¨å‹¢èšé¡æ¨™ç±¤èª¿æ•´ (ç¾¤èš2â†”ç¾¤èš3)")
    summary_report.append("   âœ… æ‰€æœ‰åœ–è¡¨æ¨™é¡Œå·²æ›´æ–°æ¨™è¨»èª¿æ•´ç‹€æ…‹")
    summary_report.append("")

    summary_report.append("ğŸ“ è¼¸å‡ºæª”æ¡ˆ:")
    summary_report.append("   - ç¶œåˆèšé¡åˆ†æçµæœ.csv")
    summary_report.append("   - [å¹´ä»½]_è¶¨å‹¢èšé¡çµæœ.csv")
    summary_report.append("   - [å¹´ä»½]_å­£ç¯€æ€§èšé¡çµæœ.csv")
    summary_report.append("   - plots/ (æ‰€æœ‰åœ–è¡¨)")
    summary_report.append("   - plots/individual_vegetables/ (å€‹åˆ¥è”¬èœåˆ†æ)")
    summary_report.append("   - plots/comparison_analysis/ (æ¯”è¼ƒåˆ†æåœ–è¡¨)")
    summary_report.append("")

    summary_report.append("ğŸ¨ åœ–è¡¨ç‰¹è‰²:")
    summary_report.append("   - è¶¨å‹¢å’Œå­£ç¯€æ€§ç·šåœ–æ—ç›´æ¥æ¨™è¨»èšé¡ç·¨è™Ÿ")
    summary_report.append("   - æ‰€æœ‰åœ–è¡¨ä½¿ç”¨ä¸­æ–‡è”¬èœåç¨±")
    summary_report.append("   - èšé¡ç·¨è™Ÿçµ±ä¸€å¾1é–‹å§‹")
    summary_report.append("   - åŒ…å«å®Œæ•´çš„ç©©å®šæ€§å’Œé·ç§»åˆ†æ")
    summary_report.append("   - 2024å¹´è¶¨å‹¢èšé¡ç¾¤èš2å’Œç¾¤èš3æ¨™ç±¤å·²èª¿æ›")
    summary_report.append("   - æ‰€æœ‰ç›¸é—œåœ–è¡¨æ¨™é¡Œå·²è¨»æ˜æ¨™ç±¤èª¿æ•´ç‹€æ…‹")
    summary_report.append("")

    summary_report.append("âœ… æ¨™ç±¤èª¿æ•´é©—è­‰:")
    summary_report.append("   - 2024å¹´ç¾¤èš2ä¸»è¦åŒ…å«åŸ2022/2023å¹´ç¾¤èš3çš„è”¬èœ")
    summary_report.append("   - 2024å¹´ç¾¤èš3ä¸»è¦åŒ…å«åŸ2022/2023å¹´ç¾¤èš2çš„è”¬èœ")
    summary_report.append("   - é·ç§»æ¨¡å¼ï¼šç¾¤èš3â†’ç¾¤èš2 å’Œ ç¾¤èš2â†’ç¾¤èš3 ç‚ºä¸»è¦æ¨¡å¼")
    summary_report.append("   - æ‰€æœ‰è¦–è¦ºåŒ–åœ–è¡¨å·²æ­£ç¢ºåæ˜ èª¿æ•´å¾Œçš„æ¨™ç±¤")
    summary_report.append("")
    summary_report.append("=" * 80)

    # ä¿å­˜å ±å‘Š
    report_text = "\n".join(summary_report)
    report_path = os.path.join(analysis_dir, "å®Œæ•´åˆ†æåŸ·è¡Œæ‘˜è¦.txt")

    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_text)

    print(f"   ğŸ“ å®Œæ•´åˆ†æåŸ·è¡Œæ‘˜è¦å·²ä¿å­˜: å®Œæ•´åˆ†æåŸ·è¡Œæ‘˜è¦.txt")


def main():
    """ä¸»ç¨‹å¼"""
    print(f"ğŸ“‚ å·¥ä½œç›®éŒ„: {os.getcwd()}")
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # è¼‰å…¥è”¬èœåç¨±å°æ‡‰è¡¨
    print("\nğŸ” è¼‰å…¥è”¬èœåç¨±å°æ‡‰è¡¨...")
    mapping_dict = load_vegetable_mapping()

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    (
        analysis_dir,
        plots_dir,
        decomp_plots_dir,
        individual_plots_dir,
        comparison_plots_dir,
    ) = setup_directories()

    # è®€å–è³‡æ–™
    print("\nğŸ“‚ è®€å–å¤šå¹´åº¦è³‡æ–™...")
    df = pd.read_excel("daily_avg_price_vege.xlsx")
    df["ObsTime"] = pd.to_datetime(df["ObsTime"])
    print(f"âœ… æˆåŠŸè®€å– {len(df):,} ç­†è¨˜éŒ„")

    # åˆ†å¹´ä»½è™•ç†
    yearly_results = {}
    decomposition_examples = {}

    for year in [2022, 2023, 2024]:
        print(f"\nğŸ“… åˆ†æ {year} å¹´...")
        year_df = df[df["ObsTime"].dt.year == year].copy()

        if len(year_df) == 0:
            print(f"   âš ï¸  {year}å¹´ç„¡è³‡æ–™")
            continue

        print(
            f"   ğŸ“Š {year}å¹´: {len(year_df):,} ç­†è¨˜éŒ„, {year_df['market_vege_id'].nunique()} ç¨®è”¬èœ"
        )

        # æ™‚é–“åºåˆ—åˆ†è§£
        print("   ğŸ”„ åŸ·è¡Œæ™‚é–“åºåˆ—åˆ†è§£...")
        decomp_results = {}
        vege_ids = year_df["market_vege_id"].unique()

        for vege_id in vege_ids:
            vege_name = get_chinese_name(vege_id, mapping_dict)
            result = decompose_time_series(year_df, vege_id, year)
            if result is not None:
                decomp_results[vege_id] = result
                print(f"      âœ… {vege_name} ({vege_id}) åˆ†è§£å®Œæˆ")

        print(f"   âœ… æˆåŠŸåˆ†è§£ {len(decomp_results)} ç¨®è”¬èœ")

        # ç‚ºæ‰€æœ‰è”¬èœå‰µå»ºåˆ†è§£ç¯„ä¾‹åœ–
        if decomp_results:
            print(f"   ğŸ¨ ç‚ºæ‰€æœ‰ {len(decomp_results)} ç¨®è”¬èœå‰µå»ºæ™‚é–“åºåˆ—åˆ†è§£åœ–...")
            decomp_created = 0
            for i, (vege_id, decomp_result) in enumerate(decomp_results.items(), 1):
                try:
                    create_decomposition_example_plot(
                        decomp_result, decomp_plots_dir, mapping_dict
                    )
                    vege_name = get_chinese_name(vege_id, mapping_dict)
                    decomp_created += 1
                    print(
                        f"      âœ… ({i}/{len(decomp_results)}) {vege_name} ({vege_id}) åˆ†è§£åœ–å·²ä¿å­˜"
                    )
                except Exception as e:
                    vege_name = get_chinese_name(vege_id, mapping_dict)
                    print(
                        f"      âŒ ({i}/{len(decomp_results)}) {vege_name} ({vege_id}) åˆ†è§£åœ–å‰µå»ºå¤±æ•—: {e}"
                    )

            print(f"   ğŸ“ˆ æˆåŠŸå‰µå»º {decomp_created} å€‹æ™‚é–“åºåˆ—åˆ†è§£åœ–")

        if len(decomp_results) < max(SEASONAL_CLUSTERS, TREND_CLUSTERS):
            print(f"   âš ï¸  æœ‰æ•ˆåˆ†è§£æ•¸é‡ä¸è¶³ï¼Œè·³éèšé¡")
            continue

        year_clustering = {}

        # è¶¨å‹¢èšé¡
        if len(decomp_results) >= TREND_CLUSTERS:
            print("   ğŸ¯ åŸ·è¡Œè¶¨å‹¢èšé¡...")
            trend_series = {
                vege_id: result["additive_trend"].values
                for vege_id, result in decomp_results.items()
                if len(result["additive_trend"]) > 0
            }

            if len(trend_series) >= TREND_CLUSTERS:
                trend_dist_matrix, trend_vege_ids = create_distance_matrix(trend_series)
                trend_results = perform_clustering_with_evaluation(
                    trend_dist_matrix, trend_vege_ids, TREND_CLUSTERS, year=year
                )
                year_clustering["trend"] = trend_results

                print(
                    f"      âœ… è¶¨å‹¢èšé¡å®Œæˆ (è¼ªå»“ä¿‚æ•¸: {trend_results['silhouette_score']:.3f})"
                )

                # å‰µå»ºå®Œæ•´çš„è¦–è¦ºåŒ–
                create_comprehensive_clustering_plots(
                    trend_results,
                    trend_series,
                    "additive_trend",
                    year,
                    plots_dir,
                    mapping_dict,
                )
                create_time_series_clustering_plot(
                    trend_results,
                    trend_series,
                    "additive_trend",
                    year,
                    plots_dir,
                    mapping_dict,
                )
                create_cluster_centers_plot(
                    trend_results,
                    trend_series,
                    "additive_trend",
                    year,
                    plots_dir,
                    mapping_dict,
                )

        # å­£ç¯€æ€§èšé¡
        if len(decomp_results) >= SEASONAL_CLUSTERS:
            print("   ğŸ¯ åŸ·è¡Œå­£ç¯€æ€§èšé¡...")
            seasonal_series = {
                vege_id: result["additive_seasonal"].values
                for vege_id, result in decomp_results.items()
                if len(result["additive_seasonal"]) > 0
            }

            if len(seasonal_series) >= SEASONAL_CLUSTERS:
                seasonal_dist_matrix, seasonal_vege_ids = create_distance_matrix(
                    seasonal_series
                )
                seasonal_results = perform_clustering_with_evaluation(
                    seasonal_dist_matrix, seasonal_vege_ids, SEASONAL_CLUSTERS
                )
                year_clustering["seasonal"] = seasonal_results

                print(
                    f"      âœ… å­£ç¯€æ€§èšé¡å®Œæˆ (è¼ªå»“ä¿‚æ•¸: {seasonal_results['silhouette_score']:.3f})"
                )

                # å‰µå»ºå®Œæ•´çš„è¦–è¦ºåŒ–
                create_comprehensive_clustering_plots(
                    seasonal_results,
                    seasonal_series,
                    "additive_seasonal",
                    year,
                    plots_dir,
                    mapping_dict,
                )
                create_time_series_clustering_plot(
                    seasonal_results,
                    seasonal_series,
                    "additive_seasonal",
                    year,
                    plots_dir,
                    mapping_dict,
                )
                create_cluster_centers_plot(
                    seasonal_results,
                    seasonal_series,
                    "additive_seasonal",
                    year,
                    plots_dir,
                    mapping_dict,
                )

        yearly_results[year] = {
            "decomposition": decomp_results,
            "clustering": year_clustering,
        }

    # å‰µå»ºå¤šå¹´åº¦æ¯”è¼ƒåœ–è¡¨
    print("\nğŸ“Š å‰µå»ºå¤šå¹´åº¦æ¯”è¼ƒåœ–è¡¨...")
    create_multi_year_comparison_plots(yearly_results, comparison_plots_dir)

    # å‰µå»ºç¶œåˆåˆ†æ
    print("\nğŸ“‹ å‰µå»ºç¶œåˆåˆ†æ...")
    comprehensive_df = create_comprehensive_analysis(
        yearly_results, analysis_dir, mapping_dict
    )

    # å‰µå»ºæ–°å¢çš„æ¯”è¼ƒåœ–è¡¨
    print("\nğŸ¨ å‰µå»ºæ“´å¢åˆ†æåœ–è¡¨...")
    create_clustering_stability_heatmap(
        comprehensive_df, comparison_plots_dir, mapping_dict
    )
    create_clustering_migration_flow_chart(comprehensive_df, comparison_plots_dir)

    # å‰µå»ºä¸‰å¹´åº¦èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–
    print("\nğŸ“Š å‰µå»ºä¸‰å¹´åº¦èšé¡ä¸­å¿ƒæ¯”è¼ƒåœ–...")
    create_three_year_cluster_centers_comparison(yearly_results, comparison_plots_dir)

    # å‰µå»ºå«é¢±é¢¨æ¨™è¨»çš„å¢å¼·ç‰ˆè¶¨å‹¢æ¯”è¼ƒåœ–
    try:
        from enhanced_trend_analysis_with_typhoon import integrate_with_main_analysis

        print("\nğŸŒªï¸ å‰µå»ºå«é¢±é¢¨æ¨™è¨»çš„å¢å¼·ç‰ˆè¶¨å‹¢æ¯”è¼ƒåœ–...")
        enhanced_output_dir = os.path.join(analysis_dir, "enhanced_typhoon_analysis")
        enhanced_path = integrate_with_main_analysis(
            yearly_results, enhanced_output_dir
        )
        if enhanced_path:
            print(f"   ğŸ“ˆ å«é¢±é¢¨æ¨™è¨»çš„è¶¨å‹¢æ¯”è¼ƒåœ–å·²ä¿å­˜")
    except ImportError:
        print("\nâš ï¸ æœªæ‰¾åˆ°å¢å¼·ç‰ˆé¢±é¢¨åˆ†ææ¨¡çµ„ï¼Œè·³éé¢±é¢¨æ¨™è¨»åŠŸèƒ½")
    except Exception as e:
        print(f"\nâš ï¸ é¢±é¢¨æ¨™è¨»åŠŸèƒ½åŸ·è¡Œå¤±æ•—: {e}")

    # å‰µå»ºå€‹åˆ¥è”¬èœåˆ†æåœ–è¡¨ï¼ˆé¸æ“‡å‰10å€‹æœ‰å®Œæ•´æ•¸æ“šçš„è”¬èœï¼‰
    print("\nğŸ¥¬ å‰µå»ºå€‹åˆ¥è”¬èœåˆ†æåœ–è¡¨...")
    complete_veges = []
    for _, row in comprehensive_df.iterrows():
        vege_id = row["market_vege_id"]
        vege_name = row["vege_name"]

        # æª¢æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„ä¸‰å¹´æ•¸æ“š
        has_complete_data = True
        for year in [2022, 2023, 2024]:
            if (
                pd.isna(row[f"trend_cluster_{year}"])
                or pd.isna(row[f"seasonal_cluster_{year}"])
                or year not in yearly_results
                or vege_id not in yearly_results[year]["decomposition"]
            ):
                has_complete_data = False
                break

        if has_complete_data:
            complete_veges.append((vege_id, vege_name))

    print(f"   ğŸ“Š æ‰¾åˆ° {len(complete_veges)} å€‹æœ‰å®Œæ•´æ•¸æ“šçš„è”¬èœ")

    # å‰µå»ºæ‰€æœ‰æœ‰å®Œæ•´æ•¸æ“šè”¬èœçš„å€‹åˆ¥åˆ†æåœ–è¡¨
    sample_veges = complete_veges  # ä½¿ç”¨æ‰€æœ‰æœ‰å®Œæ•´æ•¸æ“šçš„è”¬èœ
    print(f"   ğŸ¨ ç‚ºæ‰€æœ‰ {len(sample_veges)} å€‹è”¬èœå‰µå»ºå€‹åˆ¥åˆ†æåœ–è¡¨...")

    individual_plots_created = 0
    for i, (vege_id, vege_name) in enumerate(sample_veges, 1):
        try:
            plot_path = create_individual_vegetable_clustering_chart(
                vege_id,
                vege_name,
                yearly_results,
                {
                    year: results["clustering"]
                    for year, results in yearly_results.items()
                },
                individual_plots_dir,
            )
            individual_plots_created += 1
            print(
                f"      âœ… ({i}/{len(sample_veges)}) {vege_name} ({vege_id}) å€‹åˆ¥åˆ†æåœ–å·²ä¿å­˜"
            )
        except Exception as e:
            print(
                f"      âŒ ({i}/{len(sample_veges)}) {vege_name} ({vege_id}) å€‹åˆ¥åˆ†æåœ–å‰µå»ºå¤±æ•—: {e}"
            )

    # ä¿å­˜çµæœ
    print("\nğŸ’¾ ä¿å­˜åˆ†æçµæœ...")

    for year, results in yearly_results.items():
        clustering = results["clustering"]

        # ä¿å­˜è¶¨å‹¢èšé¡çµæœ
        if "trend" in clustering:
            trend_data = []
            for i, vege_id in enumerate(clustering["trend"]["vege_ids"]):
                vege_name = get_chinese_name(vege_id, mapping_dict)
                cluster_label = clustering["trend"]["cluster_labels"][i]

                # æ³¨æ„ï¼šé€™è£¡ä¸å†é€²è¡Œé¡å¤–èª¿æ•´ï¼Œå› ç‚ºclustering resultå·²åŒ…å«èª¿æ•´å¾Œçš„æ¨™ç±¤
                final_label = cluster_label + 1

                trend_data.append(
                    {
                        "market_vege_id": vege_id,
                        "vege_name": vege_name,
                        "trend_cluster": final_label,
                        "silhouette_score": clustering["trend"]["silhouette_score"],
                    }
                )

            trend_df = pd.DataFrame(trend_data)
            trend_path = os.path.join(analysis_dir, f"{year}_è¶¨å‹¢èšé¡çµæœ.csv")
            trend_df.to_csv(trend_path, index=False, encoding="utf-8-sig")
            print(f"   ğŸ“ {year}å¹´è¶¨å‹¢èšé¡çµæœå·²ä¿å­˜")

        # ä¿å­˜å­£ç¯€æ€§èšé¡çµæœ
        if "seasonal" in clustering:
            seasonal_data = []
            for i, vege_id in enumerate(clustering["seasonal"]["vege_ids"]):
                vege_name = get_chinese_name(vege_id, mapping_dict)
                seasonal_data.append(
                    {
                        "market_vege_id": vege_id,
                        "vege_name": vege_name,
                        "seasonal_cluster": clustering["seasonal"]["cluster_labels"][i]
                        + 1,
                        "silhouette_score": clustering["seasonal"]["silhouette_score"],
                    }
                )

            seasonal_df = pd.DataFrame(seasonal_data)
            seasonal_path = os.path.join(analysis_dir, f"{year}_å­£ç¯€æ€§èšé¡çµæœ.csv")
            seasonal_df.to_csv(seasonal_path, index=False, encoding="utf-8-sig")
            print(f"   ğŸ“ {year}å¹´å­£ç¯€æ€§èšé¡çµæœå·²ä¿å­˜")

    # å‰µå»ºåŸ·è¡Œæ‘˜è¦
    create_executive_summary(yearly_results, comprehensive_df, analysis_dir)

    # æœ€çµ‚æ‘˜è¦
    print(f"\nğŸ‰ å®Œæ•´è”¬èœåƒ¹æ ¼DTWèšé¡åˆ†æå®Œæˆ!")
    print("=" * 80)
    print(f"ğŸ“Š åˆ†æçµæœ:")
    print(f"   âœ… æˆåŠŸåˆ†æå¹´ä»½: {len(yearly_results)}")

    all_veges = set()
    for results in yearly_results.values():
        all_veges.update(results["decomposition"].keys())

    print(f"   ğŸ“Š ç¸½è”¬èœç¨®é¡: {len(all_veges)}")
    print(f"   ğŸ“ è¼¸å‡ºè³‡æ–™å¤¾: {analysis_dir}")
    print(f"   ğŸ“ˆ æ‰€æœ‰åœ–è¡¨: {plots_dir}")
    print(f"   ğŸ¥¬ å€‹åˆ¥è”¬èœåœ–è¡¨: {individual_plots_dir}")
    print(f"   ğŸ“Š æ¯”è¼ƒåˆ†æåœ–è¡¨: {comparison_plots_dir}")
    print(f"   ğŸ“‹ åˆ†è§£ç¯„ä¾‹: {decomp_plots_dir}")

    for year, results in yearly_results.items():
        decomp_count = len(results["decomposition"])
        clustering_count = len(results["clustering"])
        print(
            f"   ğŸ“… {year}å¹´: åˆ†è§£{decomp_count}ç¨®è”¬èœ, èšé¡åˆ†æ{clustering_count}ç¨®æˆåˆ†"
        )

    print(f"\nğŸš€ å®Œæ•´åŠŸèƒ½åŒ…å«:")
    print(f"   ğŸ“Š åŸå§‹DTWèšé¡åˆ†æ (æ‰€æœ‰åŸºç¤åœ–è¡¨)")
    print(f"   ğŸ“ˆ èšé¡ç©©å®šæ€§ç†±åŠ›åœ–")
    print(f"   ğŸ”„ èšé¡é·ç§»æµç¨‹åœ–")
    print(f"   ğŸ¥¬ å€‹åˆ¥è”¬èœå®Œæ•´åˆ†æåœ–è¡¨ ({individual_plots_created} å€‹)")
    print(f"   ğŸ·ï¸  è¶¨å‹¢å’Œå­£ç¯€æ€§ç·šåœ–æ—æ¨™è¨»èšé¡ç·¨è™Ÿ")
    print(f"   ğŸŒ æ‰€æœ‰åœ–è¡¨ä½¿ç”¨ä¸­æ–‡æ¨™ç±¤")
    print(f"   ğŸ”„ 2024å¹´è¶¨å‹¢èšé¡ç¾¤èš2å’Œç¾¤èš3æ¨™ç±¤å·²èª¿æ›")
    print(f"   ğŸ“ æ‰€æœ‰ç›¸é—œåœ–è¡¨æ¨™é¡Œå·²è¨»æ˜æ¨™ç±¤èª¿æ•´ç‹€æ…‹")

    print(f"\nâœ¨ å®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    print("ğŸš€ å®Œæ•´èšé¡åˆ†æç¨‹å¼é–‹å§‹åŸ·è¡Œ...")
    print("ğŸ”„ 2024å¹´è¶¨å‹¢èšé¡ä¿®æ”¹ç‰ˆæœ¬ - ç¾¤èš2â†”ç¾¤èš3æ¨™ç±¤èª¿æ›")
    print("ğŸ“ ä¿®æ­£ç‰ˆæœ¬ - çµ±ä¸€æ¨™ç±¤è™•ç†é‚è¼¯ï¼Œæ‰€æœ‰åœ–è¡¨æ¨™é¡Œå·²æ›´æ–°")
    try:
        main()
    except KeyboardInterrupt:
        print("\nâ›” ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        import traceback

        traceback.print_exc()
    finally:
        print(f"\nğŸ‘‹ ç¨‹å¼çµæŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
