# -*- coding: utf-8 -*-
"""
ä¿®å¾©æ•¸æ“šæ´©æ¼çš„Prophetå›æ­¸è®Šæ•¸æ¸¬è©¦
é‡é»ä¿®å¾©ç‰¹å¾µå‰µå»ºä¸­çš„æ™‚é–“æ´©æ¼å•é¡Œ
"""

import os
import numpy as np
import pandas as pd
import warnings
from datetime import datetime, timedelta
import json
import time

# å°å…¥å¿…è¦çš„åº«
try:
    from prophet import Prophet

    PROPHET_AVAILABLE = True
    print("âœ… Prophetè¼‰å…¥æˆåŠŸ")
except ImportError:
    print("âŒ Prophetæœªå®‰è£")
    PROPHET_AVAILABLE = False

try:
    from sklearn.metrics import r2_score, mean_absolute_error

    SKLEARN_AVAILABLE = True
    print("âœ… sklearnè¼‰å…¥æˆåŠŸ")
except ImportError:
    print("âŒ sklearnæœªå®‰è£")
    SKLEARN_AVAILABLE = False

warnings.filterwarnings("ignore")

# ====== è¨­å®š ======
CSV_FILE = "NEW_low_volatility_merged.csv"
OUTPUT_DIR = "fixed_prophet_test_results"
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("ğŸ”§ ä¿®å¾©æ•¸æ“šæ´©æ¼çš„Prophetæ¸¬è©¦")
print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {OUTPUT_DIR}")

# Propheté…ç½®
PROPHET_PARAMS = {
    "changepoint_prior_scale": 0.02,
    "n_changepoints": 15,
    "seasonality_prior_scale": 2.0,
    "seasonality_mode": "additive",
    "weekly_seasonality": 7,
    "yearly_seasonality": 15,
    "daily_seasonality": False,
    "mcmc_samples": 0,
    "uncertainty_samples": 100,
}


class FixedProphetTester:
    """ä¿®å¾©æ•¸æ“šæ´©æ¼çš„Prophetæ¸¬è©¦å™¨"""

    def __init__(self):
        self.prophet_params = PROPHET_PARAMS
        self.test_results = []
        self.failed_vegetables = []
        self.success_vegetables = []

        print("ğŸ¯ ä½¿ç”¨ä¿®å¾©å¾Œçš„å®‰å…¨ç‰¹å¾µå‰µå»º")

    def create_safe_features(self, df):
        """
        å®‰å…¨çš„ç‰¹å¾µå‰µå»º - é¿å…æ•¸æ“šæ´©æ¼

        é—œéµåŸå‰‡ï¼š
        1. æ‰€æœ‰ç‰¹å¾µéƒ½å¿…é ˆåŸºæ–¼æ­·å²æ•¸æ“š
        2. ä¸èƒ½ä½¿ç”¨ç•¶æœŸæˆ–æœªä¾†çš„ä¿¡æ¯
        3. ç§»å‹•å¹³å‡å¿…é ˆæ­£ç¢ºæ»¯å¾Œ
        """
        df = df.copy()

        if "y" not in df.columns:
            return df, []

        print("ğŸ”§ å‰µå»ºå®‰å…¨ç‰¹å¾µï¼ˆé¿å…æ•¸æ“šæ´©æ¼ï¼‰...")
        created_features = []

        try:
            # ç¢ºä¿æ•¸æ“šæŒ‰æ™‚é–“æ’åº
            if "ds" in df.columns:
                df = df.sort_values("ds").reset_index(drop=True)

            # âœ… ç‰¹å¾µ1: price_lag_1 - çœŸæ­£çš„æ˜¨æ—¥åƒ¹æ ¼
            df["price_lag_1"] = df["y"].shift(1)
            created_features.append("price_lag_1")
            print("    âœ… price_lag_1: ä½¿ç”¨shift(1)ç¢ºä¿æ˜¯æ˜¨æ—¥åƒ¹æ ¼")

            # âœ… ç‰¹å¾µ2: price_change_1 - æ˜¨æ—¥ç›¸å°æ–¼å‰æ—¥çš„è®ŠåŒ–
            # æ³¨æ„ï¼šé€™æ˜¯æ˜¨æ—¥çš„è®ŠåŒ–ï¼Œä¸æ˜¯ä»Šæ—¥çš„è®ŠåŒ–
            df["price_change_1"] = df["y"].shift(1) - df["y"].shift(2)
            # ç¬¬ä¸€å’Œç¬¬äºŒå€‹å€¼æœƒæ˜¯NaNï¼Œé€™æ˜¯æ­£ç¢ºçš„
            created_features.append("price_change_1")
            print("    âœ… price_change_1: æ˜¨æ—¥ç›¸å°å‰æ—¥çš„è®ŠåŒ–")

            # âœ… ç‰¹å¾µ3: price_ma_7 - åŸºæ–¼æ­·å²æ•¸æ“šçš„7å¤©ç§»å‹•å¹³å‡
            # ä½¿ç”¨shift(1)ç¢ºä¿åªç”¨æ­·å²æ•¸æ“š
            df["price_ma_7"] = df["y"].shift(1).rolling(window=7, min_periods=1).mean()
            created_features.append("price_ma_7")
            print("    âœ… price_ma_7: åŸºæ–¼æ­·å²æ•¸æ“šçš„ç§»å‹•å¹³å‡")

            # ğŸ”§ æ•¸æ“šæ¸…ç†å’Œé©—è­‰
            for feature in created_features[:]:
                if feature in df.columns:
                    try:
                        # è™•ç†ç„¡é™å€¼
                        df[feature] = df[feature].replace([np.inf, -np.inf], np.nan)

                        # æª¢æŸ¥NaNæ¯”ä¾‹
                        nan_ratio = df[feature].isna().sum() / len(df)
                        print(f"    ğŸ“Š {feature}: NaNæ¯”ä¾‹ {nan_ratio:.2%}")

                        if nan_ratio > 0.9:  # è¶…é90%æ˜¯NaNæ‰ç§»é™¤
                            print(f"    âš ï¸ ç§»é™¤ {feature} (NaNæ¯”ä¾‹éé«˜)")
                            created_features.remove(feature)
                            df.drop(columns=[feature], inplace=True)
                        else:
                            # å¡«å……NaNå€¼ - æ³¨æ„ï¼šåªç”¨è¨“ç·´æœŸé–“çš„çµ±è¨ˆ
                            # é€™è£¡æš«æ™‚ç”¨å…¨å±€ä¸­ä½æ•¸ï¼Œåœ¨è¨“ç·´æ™‚æœƒé‡æ–°è¨ˆç®—
                            if df[feature].notna().any():
                                median_val = df[feature].median()
                                if pd.isna(median_val):
                                    median_val = 0
                                df[feature] = df[feature].fillna(median_val)
                            else:
                                df[feature] = 0

                    except Exception as e:
                        print(f"    âŒ ç‰¹å¾µ {feature} è™•ç†å¤±æ•—: {e}")
                        if feature in created_features:
                            created_features.remove(feature)
                        if feature in df.columns:
                            df.drop(columns=[feature], inplace=True)

            print(f"  âœ… æˆåŠŸå‰µå»º {len(created_features)} å€‹å®‰å…¨ç‰¹å¾µ")

            # ğŸ§ª åˆç†æ€§æª¢æŸ¥
            self.sanity_check_features(df, created_features)

            return df, created_features

        except Exception as e:
            print(f"  âŒ ç‰¹å¾µå‰µå»ºå¤±æ•—: {e}")
            return df, []

    def sanity_check_features(self, df, features):
        """åˆç†æ€§æª¢æŸ¥ - ç¢ºä¿æ²’æœ‰æ•¸æ“šæ´©æ¼"""
        print("    ğŸ§ª åŸ·è¡Œåˆç†æ€§æª¢æŸ¥...")

        for feature in features:
            if feature in df.columns:
                # æª¢æŸ¥èˆ‡ç›®æ¨™çš„ç›¸é—œæ€§
                valid_mask = df[feature].notna() & df["y"].notna()
                if valid_mask.sum() > 10:
                    correlation = df.loc[valid_mask, feature].corr(
                        df.loc[valid_mask, "y"]
                    )
                    print(f"      ğŸ“Š {feature} èˆ‡ç›®æ¨™ç›¸é—œæ€§: {correlation:.4f}")

                    if correlation > 0.95:
                        print(f"      ğŸš¨ è­¦å‘Š: {feature} ç›¸é—œæ€§éé«˜ï¼Œå¯èƒ½æœ‰æ•¸æ“šæ´©æ¼ï¼")

                # æª¢æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦ç‚ºNaNï¼ˆæ»¯å¾Œç‰¹å¾µæ‡‰è©²æ˜¯ï¼‰
                if feature in ["price_lag_1", "price_change_1"]:
                    if not pd.isna(df[feature].iloc[0]):
                        print(
                            f"      ğŸš¨ è­¦å‘Š: {feature} ç¬¬ä¸€è¡Œä¸æ˜¯NaNï¼Œå¯èƒ½æ²’æœ‰æ­£ç¢ºæ»¯å¾Œï¼"
                        )
                    else:
                        print(f"      âœ… {feature} æ­£ç¢ºæ»¯å¾Œï¼ˆç¬¬ä¸€è¡Œç‚ºNaNï¼‰")

    def safe_prophet_predict(
        self, train_data, test_data, regressors=None, test_name=""
    ):
        """
        å®‰å…¨çš„Propheté æ¸¬ - ç‰¹åˆ¥æ³¨æ„é¿å…æ•¸æ“šæ´©æ¼
        """
        try:
            # æº–å‚™æ•¸æ“š
            train_prophet = train_data[["ds", "y"]].copy()
            test_prophet = test_data[["ds"]].copy()

            # æª¢æŸ¥æ•¸æ“šæœ‰æ•ˆæ€§
            if len(train_prophet) < 10 or len(test_prophet) < 3:
                return None, []

            # å»ºç«‹æ¨¡å‹
            model = Prophet(**self.prophet_params)
            added_regressors = []

            # æ·»åŠ å›æ­¸è®Šæ•¸
            if regressors:
                for reg in regressors:
                    if reg in train_data.columns:
                        try:
                            train_feature = train_data[reg].copy()
                            test_feature = test_data[reg].copy()

                            # âš ï¸ é‡è¦ï¼šåªä½¿ç”¨è¨“ç·´æ•¸æ“šè¨ˆç®—çµ±è¨ˆé‡
                            train_median = train_feature.median()
                            if pd.isna(train_median):
                                train_median = 0

                            # å¡«å……ç¼ºå¤±å€¼
                            train_feature = train_feature.fillna(train_median)
                            test_feature = test_feature.fillna(train_median)

                            # æª¢æŸ¥è®Šç•°æ€§
                            if train_feature.std() > 1e-8:
                                train_prophet[reg] = train_feature
                                test_prophet[reg] = test_feature

                                model.add_regressor(
                                    reg,
                                    prior_scale=1.0,
                                    standardize=True,
                                    mode="additive",
                                )
                                added_regressors.append(reg)
                                print(f"    âœ… æ·»åŠ å›æ­¸è®Šæ•¸: {reg}")

                        except Exception as e:
                            print(f"    âš ï¸ å›æ­¸è®Šæ•¸ {reg} æ·»åŠ å¤±æ•—: {e}")
                            continue

            # è¨“ç·´æ¨¡å‹
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                model.fit(train_prophet)

            # é æ¸¬
            forecast = model.predict(test_prophet)
            y_pred = forecast["yhat"].values

            # å¾Œè™•ç†é æ¸¬çµæœ
            y_pred = np.where(np.isfinite(y_pred), y_pred, train_data["y"].mean())
            y_pred = np.maximum(y_pred, 0.01)  # ç¢ºä¿åƒ¹æ ¼ç‚ºæ­£æ•¸

            return y_pred, added_regressors

        except Exception as e:
            print(f"    âŒ {test_name} é æ¸¬å¤±æ•—: {e}")
            return None, []

    def evaluate_r2_safe(self, y_true, y_pred):
        """å®‰å…¨çš„RÂ²è¨ˆç®—"""
        try:
            # ç§»é™¤NaNå€¼
            mask = np.isfinite(y_true) & np.isfinite(y_pred)
            if mask.sum() < 3:
                return -999.0

            y_true_clean = y_true[mask]
            y_pred_clean = y_pred[mask]

            r2 = r2_score(y_true_clean, y_pred_clean)
            return float(r2) if np.isfinite(r2) else -999.0

        except:
            return -999.0

    def test_single_vegetable(self, df_veg, veg_id):
        """æ¸¬è©¦å–®ä¸€è”¬èœ"""

        min_samples = 50
        if len(df_veg) < min_samples:
            print(f"   âš ï¸ è”¬èœ {veg_id}: æ•¸æ“šé‡éå°‘ ({len(df_veg)} < {min_samples})")
            return None

        print(f"\nğŸ¥¬ æ¸¬è©¦è”¬èœID: {veg_id} (æ•¸æ“šé‡: {len(df_veg)})")

        # å‰µå»ºå®‰å…¨ç‰¹å¾µ
        df_veg, created_features = self.create_safe_features(df_veg)

        if len(created_features) < 2:
            print(f"   âŒ è”¬èœ {veg_id}: æœ‰æ•ˆç‰¹å¾µå¤ªå°‘ ({len(created_features)})")
            return None

        # åš´æ ¼çš„æ™‚é–“åºåˆ—åˆ†å‰²
        if len(df_veg) >= 100:
            split_ratio = 0.8
        elif len(df_veg) >= 60:
            split_ratio = 0.75
        else:
            split_ratio = 0.7

        split_idx = int(len(df_veg) * split_ratio)
        train_data = df_veg.iloc[:split_idx].copy()
        test_data = df_veg.iloc[split_idx:].copy()

        if len(test_data) < 3:
            print(f"   âš ï¸ è”¬èœ {veg_id}: æ¸¬è©¦æ•¸æ“šå¤ªå°‘ ({len(test_data)})")
            return None

        print(f"   ğŸ“Š è¨“ç·´: {len(train_data)}, æ¸¬è©¦: {len(test_data)}")

        # ğŸ” é¡å¤–æª¢æŸ¥ï¼šç¢ºä¿ç‰¹å¾µæ²’æœ‰æœªä¾†ä¿¡æ¯
        print("   ğŸ” æª¢æŸ¥ç‰¹å¾µå®‰å…¨æ€§...")
        for feature in created_features:
            if feature in train_data.columns:
                # æª¢æŸ¥è¨“ç·´é›†æœ€å¾Œä¸€å¤©çš„ç‰¹å¾µæ˜¯å¦ä½¿ç”¨äº†æ¸¬è©¦é›†ä¿¡æ¯
                last_train_feature = train_data[feature].iloc[-1]
                first_test_y = test_data["y"].iloc[0] if len(test_data) > 0 else None

                # å¦‚æœç‰¹å¾µå€¼ç­‰æ–¼æ¸¬è©¦é›†ç¬¬ä¸€å¤©çš„yå€¼ï¼Œèªªæ˜æœ‰æ´©æ¼
                if (
                    first_test_y is not None
                    and abs(last_train_feature - first_test_y) < 1e-6
                ):
                    print(f"      ğŸš¨ è­¦å‘Š: {feature} å¯èƒ½ä½¿ç”¨äº†æ¸¬è©¦æœŸé–“çš„æ•¸æ“šï¼")

        y_true = test_data["y"].values
        results = {}

        # ğŸ¯ æ¸¬è©¦é…ç½®
        test_configs = [
            {
                "name": "åŸºæœ¬Prophet",
                "regressors": None,
                "description": "ç„¡å›æ­¸è®Šæ•¸çš„åŸºæº–æ¨¡å‹",
            },
            {
                "name": "æ ¸å¿ƒ3ç‰¹å¾µ",
                "regressors": [
                    r
                    for r in ["price_change_1", "price_lag_1", "price_ma_7"]
                    if r in created_features
                ],
                "description": "ä¿®å¾©å¾Œçš„3å€‹æ ¸å¿ƒç‰¹å¾µ",
            },
            {
                "name": "åƒ…price_lag_1",
                "regressors": (
                    ["price_lag_1"] if "price_lag_1" in created_features else None
                ),
                "description": "åƒ…ä½¿ç”¨æ˜¨æ—¥åƒ¹æ ¼",
            },
        ]

        for config in test_configs:
            config_name = config["name"]
            regressors = config["regressors"]

            print(f"   ğŸ”„ æ¸¬è©¦é…ç½®: {config_name}")

            try:
                y_pred, used_regressors = self.safe_prophet_predict(
                    train_data, test_data, regressors, config_name
                )

                if y_pred is not None and len(y_pred) == len(y_true):
                    r2 = self.evaluate_r2_safe(y_true, y_pred)

                    if r2 != -999.0:
                        mae = float(mean_absolute_error(y_true, y_pred))

                        results[config_name] = {
                            "r2": r2,
                            "mae": mae,
                            "used_regressors": used_regressors,
                            "description": config["description"],
                        }

                        # ğŸš¨ ç•°å¸¸æª¢æ¸¬
                        if r2 > 0.95:
                            print(
                                f"   ğŸš¨ ç•°å¸¸é«˜RÂ²è­¦å‘Š: {config_name} RÂ²={r2:.4f} (å¯èƒ½ä»æœ‰æ•¸æ“šæ´©æ¼)"
                            )
                        elif r2 > 0.8:
                            print(
                                f"   ğŸ“ˆ {config_name}: RÂ²={r2:.4f}, MAE={mae:.4f} âœ… å„ªç§€çµæœ"
                            )
                        elif r2 > 0.5:
                            print(
                                f"   ğŸ“Š {config_name}: RÂ²={r2:.4f}, MAE={mae:.4f} âœ… è‰¯å¥½çµæœ"
                            )
                        elif r2 > 0.0:
                            print(
                                f"   ğŸ“‰ {config_name}: RÂ²={r2:.4f}, MAE={mae:.4f} âš ï¸ ä¸€èˆ¬çµæœ"
                            )
                        else:
                            print(
                                f"   âŒ {config_name}: RÂ²={r2:.4f}, MAE={mae:.4f} âŒ å·®çµæœ"
                            )
                    else:
                        print(f"   âš ï¸ {config_name}: RÂ²è¨ˆç®—å¤±æ•—")
                else:
                    print(f"   âŒ {config_name}: é æ¸¬å¤±æ•—")

            except Exception as e:
                print(f"   âŒ {config_name} æ¸¬è©¦å¤±æ•—: {e}")

        # æ”¹å–„åˆ†æ
        improvement_analysis = self.analyze_improvement(results)
        if improvement_analysis:
            print(f"   ğŸ¯ {improvement_analysis}")

        # ä¿å­˜çµæœ
        if results:
            result_summary = {
                "veg_id": veg_id,
                "data_samples": len(df_veg),
                "train_samples": len(train_data),
                "test_samples": len(test_data),
                "created_features": created_features,
                "test_results": results,
                "improvement_analysis": improvement_analysis,
            }
            return result_summary
        else:
            print(f"   âŒ è”¬èœ {veg_id}: æ‰€æœ‰é…ç½®éƒ½å¤±æ•—")
            return None

    def analyze_improvement(self, results):
        """åˆ†ææ”¹å–„æ•ˆæœ"""
        if "åŸºæœ¬Prophet" in results and "æ ¸å¿ƒ3ç‰¹å¾µ" in results:
            basic_r2 = results["åŸºæœ¬Prophet"]["r2"]
            enhanced_r2 = results["æ ¸å¿ƒ3ç‰¹å¾µ"]["r2"]
            improvement = enhanced_r2 - basic_r2

            if basic_r2 < 0 and enhanced_r2 >= 0:
                return f"ğŸ‰ è² è½‰æ­£: {basic_r2:.4f} â†’ {enhanced_r2:.4f} (+{improvement:.4f})"
            elif improvement > 0.1:
                return f"ğŸš€ é¡¯è‘—æ”¹å–„: {basic_r2:.4f} â†’ {enhanced_r2:.4f} (+{improvement:.4f})"
            elif improvement > 0.01:
                return f"ğŸ“ˆ æœ‰æ”¹å–„: {basic_r2:.4f} â†’ {enhanced_r2:.4f} (+{improvement:.4f})"
            elif improvement > 0:
                return f"ğŸ“Š è¼•å¾®æ”¹å–„: {basic_r2:.4f} â†’ {enhanced_r2:.4f} (+{improvement:.4f})"
            else:
                return (
                    f"â¡ï¸ ç„¡æ”¹å–„: {basic_r2:.4f} â†’ {enhanced_r2:.4f} ({improvement:.4f})"
                )

        return None

    def run_fixed_test(self, df_all):
        """é‹è¡Œä¿®å¾©å¾Œçš„æ¸¬è©¦"""

        # ç²å–æ‰€æœ‰è”¬èœID
        veg_counts = df_all.groupby("vege_id").size().sort_values(ascending=False)
        all_veg_ids = veg_counts.index.tolist()

        print(f"\nğŸ”„ é–‹å§‹ä¿®å¾©å¾Œçš„æ¸¬è©¦ - {len(all_veg_ids)} ç¨®è”¬èœ")
        print(f"ğŸ“Š é æœŸçµæœ: RÂ²åœ¨0.3-0.8ç‚ºå„ªç§€ï¼Œ0.8+éœ€è¦æª¢æŸ¥æ˜¯å¦æœ‰æ´©æ¼")

        all_results = []
        improvement_stats = {
            "negative_to_positive": 0,
            "significant_improve": 0,
            "moderate_improve": 0,
            "slight_improve": 0,
            "no_improve": 0,
            "failed": 0,
            "suspicious_high_r2": 0,  # æ–°å¢ï¼šå¯ç–‘çš„é«˜RÂ²
        }

        start_time = time.time()

        # åªæ¸¬è©¦å‰5ç¨®è”¬èœï¼Œå…ˆé©—è­‰ä¿®å¾©æ•ˆæœ
        test_veg_ids = all_veg_ids[:5]
        print(f"ğŸ§ª é¦–æ¬¡é©—è­‰ï¼šæ¸¬è©¦å‰{len(test_veg_ids)}ç¨®è”¬èœ")

        for i, veg_id in enumerate(test_veg_ids, 1):
            print(f"\n[{i}/{len(test_veg_ids)}] " + "=" * 50)

            try:
                veg_data = df_all[df_all["vege_id"] == veg_id].copy()
                veg_data = veg_data.sort_values("ds").reset_index(drop=True)

                result = self.test_single_vegetable(veg_data, veg_id)

                if result:
                    all_results.append(result)
                    self.success_vegetables.append(veg_id)

                    # çµ±è¨ˆæ”¹å–„æ•ˆæœ
                    test_results = result["test_results"]
                    if "åŸºæœ¬Prophet" in test_results and "æ ¸å¿ƒ3ç‰¹å¾µ" in test_results:
                        basic_r2 = test_results["åŸºæœ¬Prophet"]["r2"]
                        enhanced_r2 = test_results["æ ¸å¿ƒ3ç‰¹å¾µ"]["r2"]
                        improvement = enhanced_r2 - basic_r2

                        # æª¢æŸ¥æ˜¯å¦ä»æœ‰å¯ç–‘çš„é«˜RÂ²
                        if enhanced_r2 > 0.95:
                            improvement_stats["suspicious_high_r2"] += 1
                            print(
                                f"   ğŸš¨ è”¬èœ{veg_id}: RÂ²ä»ç„¶ç•°å¸¸é«˜ ({enhanced_r2:.4f})ï¼Œéœ€è¦é€²ä¸€æ­¥æª¢æŸ¥"
                            )

                        if basic_r2 < 0 and enhanced_r2 >= 0:
                            improvement_stats["negative_to_positive"] += 1
                        elif improvement > 0.1:
                            improvement_stats["significant_improve"] += 1
                        elif improvement > 0.01:
                            improvement_stats["moderate_improve"] += 1
                        elif improvement > 0:
                            improvement_stats["slight_improve"] += 1
                        else:
                            improvement_stats["no_improve"] += 1

                else:
                    self.failed_vegetables.append(veg_id)
                    improvement_stats["failed"] += 1

            except Exception as e:
                print(f"   âŒ è”¬èœ {veg_id} æ¸¬è©¦å¤±æ•—: {e}")
                self.failed_vegetables.append(veg_id)
                improvement_stats["failed"] += 1

        elapsed_time = time.time() - start_time

        print(f"\nâ±ï¸ æ¸¬è©¦æ™‚é–“: {elapsed_time:.1f} ç§’")
        print(f"âœ… æˆåŠŸæ¸¬è©¦: {len(all_results)}/{len(test_veg_ids)} ç¨®è”¬èœ")

        if improvement_stats["suspicious_high_r2"] > 0:
            print(
                f"ğŸš¨ ä»æœ‰ {improvement_stats['suspicious_high_r2']} ç¨®è”¬èœRÂ²ç•°å¸¸é«˜ï¼Œéœ€è¦é€²ä¸€æ­¥èª¿æŸ¥"
            )

        return all_results, improvement_stats

    def print_diagnostic_summary(self, all_results, improvement_stats):
        """æ‰“å°è¨ºæ–·ç¸½çµ"""
        print("\n" + "=" * 80)
        print("ğŸ”§ ä¿®å¾©å¾Œæ¸¬è©¦çµæœè¨ºæ–·")
        print("=" * 80)

        if not all_results:
            print("âŒ ç„¡æ¸¬è©¦çµæœ")
            return

        total_tested = len(all_results)

        print(f"\nğŸ“Š æ¸¬è©¦æ¦‚æ³:")
        print(f"  æ¸¬è©¦è”¬èœæ•¸: {total_tested}")
        print(f"  å¯ç–‘é«˜RÂ²: {improvement_stats['suspicious_high_r2']} ç¨®")

        # åˆ†æRÂ²åˆ†ä½ˆ
        r2_values = []
        for result in all_results:
            if "æ ¸å¿ƒ3ç‰¹å¾µ" in result["test_results"]:
                r2 = result["test_results"]["æ ¸å¿ƒ3ç‰¹å¾µ"]["r2"]
                if r2 != -999:
                    r2_values.append(r2)

        if r2_values:
            print(f"\nğŸ“Š æ ¸å¿ƒ3ç‰¹å¾µRÂ²åˆ†ä½ˆ:")
            print(f"  å¹³å‡RÂ²: {np.mean(r2_values):.4f}")
            print(f"  RÂ²ç¯„åœ: [{np.min(r2_values):.4f}, {np.max(r2_values):.4f}]")
            print(
                f"  è¶…é0.9çš„æ¯”ä¾‹: {sum(1 for r2 in r2_values if r2 > 0.9) / len(r2_values) * 100:.1f}%"
            )
            print(
                f"  è¶…é0.95çš„æ¯”ä¾‹: {sum(1 for r2 in r2_values if r2 > 0.95) / len(r2_values) * 100:.1f}%"
            )

        print(f"\nğŸ’¡ è¨ºæ–·çµè«–:")
        if improvement_stats["suspicious_high_r2"] == 0:
            print(f"  âœ… ä¿®å¾©æˆåŠŸï¼æ²’æœ‰ç•°å¸¸é«˜çš„RÂ²å€¼")
        elif improvement_stats["suspicious_high_r2"] < total_tested * 0.3:
            print(f"  âš ï¸ éƒ¨åˆ†ä¿®å¾©æˆåŠŸï¼Œä»æœ‰å°‘æ•¸ç•°å¸¸å€¼éœ€è¦èª¿æŸ¥")
        else:
            print(f"  âŒ ä¿®å¾©ä¸å®Œå…¨ï¼Œä»æœ‰å¤§é‡ç•°å¸¸é«˜RÂ²ï¼Œéœ€è¦é€²ä¸€æ­¥æª¢æŸ¥ç‰¹å¾µå‰µå»ºé‚è¼¯")

        # åˆç†æ€§æª¢æŸ¥å»ºè­°
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè­°:")
        if improvement_stats["suspicious_high_r2"] > 0:
            print(f"  1. æ‰‹å‹•æª¢æŸ¥ç•°å¸¸é«˜RÂ²çš„è”¬èœæ•¸æ“š")
            print(f"  2. é©—è­‰ç‰¹å¾µè¨ˆç®—æ˜¯å¦çœŸçš„é¿å…äº†æœªä¾†ä¿¡æ¯")
            print(f"  3. æª¢æŸ¥Prophetæ¨¡å‹åƒæ•¸æ˜¯å¦åˆé©")
        else:
            print(f"  1. å¯ä»¥æ“´å±•æ¸¬è©¦åˆ°æ‰€æœ‰29ç¨®è”¬èœ")
            print(f"  2. çµæœçœ‹èµ·ä¾†åˆç†ï¼Œå¯ä»¥é€²å…¥ç”Ÿç”¢éšæ®µ")


def main():
    """ä¸»ç¨‹å¼"""

    if not PROPHET_AVAILABLE or not SKLEARN_AVAILABLE:
        print("âŒ ç¼ºå°‘å¿…è¦çš„åº«")
        return

    # è¼‰å…¥æ•¸æ“š
    print("\nğŸ“Š è¼‰å…¥æ•¸æ“š...")

    if not os.path.exists(CSV_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°æ•¸æ“šæ–‡ä»¶: {CSV_FILE}")
        return

    try:
        df_all = pd.read_csv(CSV_FILE)
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(df_all):,} ç­†åŸå§‹æ•¸æ“š")

        # æ•¸æ“šé è™•ç†
        df_all["ds"] = pd.to_datetime(df_all["ObsTime"], errors="coerce")
        df_all["y"] = pd.to_numeric(df_all["avg_price_per_kg"], errors="coerce")
        df_all["vege_id"] = df_all["vege_id"].astype(str)

        # ç§»é™¤ç„¡æ•ˆæ•¸æ“š
        initial_count = len(df_all)
        df_all = df_all.dropna(subset=["ds", "y", "vege_id"])
        print(f"âœ… æ¸…ç†å¾Œå‰©é¤˜ {len(df_all):,} ç­†æœ‰æ•ˆæ•¸æ“š")

        # è”¬èœçµ±è¨ˆ
        veg_counts = df_all.groupby("vege_id").size().sort_values(ascending=False)
        print(f"ğŸ¥¬ ç¸½è”¬èœç¨®é¡: {len(veg_counts)}")

    except Exception as e:
        print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return

    # é‹è¡Œä¿®å¾©å¾Œçš„æ¸¬è©¦
    print(f"\nğŸš€ é–‹å§‹é‹è¡Œä¿®å¾©å¾Œçš„æ¸¬è©¦...")
    try:
        tester = FixedProphetTester()
        all_results, improvement_stats = tester.run_fixed_test(df_all)

        # è¨ºæ–·çµæœ
        tester.print_diagnostic_summary(all_results, improvement_stats)

        print(f"\nğŸ“ å¦‚æœçµæœåˆç†ï¼Œå¯ä»¥æ“´å±•åˆ°æ‰€æœ‰29ç¨®è”¬èœ")

    except Exception as e:
        print(f"âŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    print("=" * 80)
    print("ğŸ”§ ä¿®å¾©æ•¸æ“šæ´©æ¼çš„Prophetæ¸¬è©¦ç³»çµ±")
    print("=" * 80)
    print("ğŸ“… åŸ·è¡Œæ™‚é–“:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print()

    main()

    print("\n" + "=" * 80)
    print("ğŸ è¨ºæ–·æ¸¬è©¦å®Œæˆ")
    print("=" * 80)
